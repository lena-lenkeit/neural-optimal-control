{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import functools\n",
    "import math\n",
    "from functools import partial\n",
    "from typing import Any, Callable, List, Optional, Tuple, Type, Union\n",
    "\n",
    "import diffrax\n",
    "import equinox as eqx\n",
    "import matplotlib.animation\n",
    "import matplotlib.lines\n",
    "import matplotlib.patches\n",
    "import matplotlib.pyplot as plt\n",
    "import optax\n",
    "from jaxtyping import Array, ArrayLike, PRNGKeyArray, PyTree, Scalar\n",
    "from tqdm.auto import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartpole_ode(t: Scalar, y: Array, u: Array, args: PyTree) -> PyTree:\n",
    "    f = 10 * u[0]\n",
    "\n",
    "    g = 9.81\n",
    "    mass_cart = 1.0\n",
    "    mass_pole = 0.1\n",
    "    length_pole = 0.5\n",
    "\n",
    "    x = y[0]\n",
    "    theta = y[1]\n",
    "    dot_x = y[2]\n",
    "    dot_theta = y[3]\n",
    "\n",
    "    ddot_theta = (\n",
    "        g * jnp.sin(theta)\n",
    "        + jnp.cos(theta)\n",
    "        * (\n",
    "            (-f - mass_pole * length_pole * jnp.square(dot_theta) * jnp.sin(theta))\n",
    "            / (mass_cart + mass_pole)\n",
    "        )\n",
    "    ) / (\n",
    "        length_pole\n",
    "        * (4 / 3 - (mass_pole * jnp.square(jnp.cos(theta)) / (mass_cart + mass_pole)))\n",
    "    )\n",
    "\n",
    "    ddot_x = (\n",
    "        f\n",
    "        + mass_pole\n",
    "        * length_pole\n",
    "        * (jnp.square(dot_theta) * jnp.sin(theta) - ddot_theta * jnp.cos(theta))\n",
    "    ) / (mass_cart + mass_pole)\n",
    "\n",
    "    dy = jnp.stack((dot_x, dot_theta, ddot_x, ddot_theta), axis=-1)\n",
    "    return dy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control function decorators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_control(\n",
    "    f: Callable[[Scalar, PyTree, PyTree, PyTree], PyTree]\n",
    ") -> Callable[[Scalar, PyTree, PyTree], PyTree]:\n",
    "    @functools.wraps(f)\n",
    "    def wrapper(t: Scalar, y: PyTree, args: PyTree) -> PyTree:\n",
    "        control, f_args = args\n",
    "        u = control(y)\n",
    "\n",
    "        dy = f(t, y, u, f_args)\n",
    "        return dy\n",
    "\n",
    "    def modify_initial_state(control: PyTree, t0: Scalar, y0: Array) -> Array:\n",
    "        return y0\n",
    "\n",
    "    wrapper_fn = wrapper\n",
    "    wrapper_fn._modify_initial_state = modify_initial_state\n",
    "\n",
    "    return wrapper_fn\n",
    "\n",
    "\n",
    "def with_derivative_control(\n",
    "    f: Callable[[Scalar, PyTree, PyTree, PyTree], PyTree], num_controls: int\n",
    ") -> Callable[[Scalar, PyTree, PyTree], PyTree]:\n",
    "    @functools.wraps(f)\n",
    "    def wrapper(t: Scalar, y: PyTree, args: PyTree) -> PyTree:\n",
    "        control, f_args = args\n",
    "        c_u, f_y = y[..., :num_controls], y[..., num_controls:]\n",
    "\n",
    "        f_dy = f(t, f_y, c_u, f_args)\n",
    "        c_du = control(y)\n",
    "\n",
    "        dy = jnp.concatenate((c_du, f_dy), axis=-1)\n",
    "        return dy\n",
    "\n",
    "    def modify_initial_state(control: PyTree, t0: Scalar, y0: Array) -> Array:\n",
    "        X0 = jnp.concatenate((t0, y0), axis=-1)\n",
    "        c0 = control.encode_controls(X0)\n",
    "\n",
    "        # c0 = jnp.zeros(num_controls)\n",
    "\n",
    "        y0 = jnp.concatenate((c0, y0), axis=-1)\n",
    "        return y0\n",
    "\n",
    "    wrapper_fn = wrapper\n",
    "    wrapper_fn._modify_initial_state = modify_initial_state\n",
    "\n",
    "    return wrapper_fn\n",
    "\n",
    "\n",
    "# This needs stepping support, since ODE RNNs are discontinuous over state changes\n",
    "# def with_ode_rnn_control(f: Callable[[Scalar, PyTree, PyTree, PyTree], PyTree], num_controls: int, num_memory: int):\n",
    "\n",
    "\n",
    "def with_cde_rnn_control(\n",
    "    f: Callable[[Scalar, PyTree, PyTree, PyTree], PyTree], num_latents: int\n",
    "):\n",
    "    @functools.wraps(f)\n",
    "    def wrapper(t: Scalar, y: PyTree, args: PyTree) -> PyTree:\n",
    "        control, f_args = args\n",
    "        f_y, c_z = y[..., :-num_latents], y[..., -num_latents:]\n",
    "\n",
    "        c_u = control.decode_latents(c_z)\n",
    "        f_dy = f(t, f_y, c_u, f_args)\n",
    "\n",
    "        dt = jnp.ones(1)\n",
    "        dX = jnp.concatenate((dt, f_dy), axis=-1)\n",
    "\n",
    "        c_dzdX = control(c_z)\n",
    "        c_dz = c_dzdX @ dX\n",
    "\n",
    "        dy = jnp.concatenate((f_dy, c_dz), axis=-1)\n",
    "        return dy\n",
    "\n",
    "    def modify_initial_state(control: PyTree, t0: Scalar, y0: Array) -> Array:\n",
    "        X0 = jnp.concatenate((t0, y0), axis=-1)\n",
    "        z0 = control.encode_latents(X0)\n",
    "\n",
    "        y0 = jnp.concatenate((z0, y0), axis=-1)\n",
    "        return y0\n",
    "\n",
    "    wrapper_fn = wrapper\n",
    "    wrapper_fn._modify_initial_state = modify_initial_state\n",
    "\n",
    "    return wrapper_fn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Control Test (with generic interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(eqx.Module):\n",
    "    in_proj: eqx.nn.Linear\n",
    "    out_proj: eqx.nn.Linear\n",
    "    cells: eqx.Module\n",
    "    cell_type: str\n",
    "    initial_state: PyTree\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_width: int,\n",
    "        out_width: int,\n",
    "        rnn_width: int,\n",
    "        rnn_layers: int,\n",
    "        cell_type: str,\n",
    "        key: PRNGKeyArray,\n",
    "    ):\n",
    "        key, key1, key2 = jax.random.split(key, num=3)\n",
    "        self.in_proj = eqx.nn.Linear(in_width, rnn_width, key=key1)\n",
    "        self.out_proj = eqx.nn.Linear(rnn_width, out_width, use_bias=False, key=key2)\n",
    "\n",
    "        self.cell_type = cell_type\n",
    "        cell_cls = {\"gru\": eqx.nn.GRUCell, \"lstm\": eqx.nn.LSTMCell}[cell_type]\n",
    "\n",
    "        keys = jax.random.split(key, num=rnn_layers)\n",
    "        make_cells = lambda k: cell_cls(\n",
    "            input_size=rnn_width, hidden_size=rnn_width, key=k\n",
    "        )\n",
    "        self.cells = eqx.filter_vmap(make_cells)(keys)\n",
    "\n",
    "        if cell_type == \"lstm\":\n",
    "            self.initial_state = (\n",
    "                jnp.zeros((rnn_layers, rnn_width)),\n",
    "                jnp.zeros((rnn_layers, rnn_width)),\n",
    "            )\n",
    "        elif cell_type == \"gru\":\n",
    "            self.initial_state = jnp.zeros((rnn_layers, rnn_width))\n",
    "\n",
    "    def __call__(self, inputs: Array, states: PyTree) -> Tuple[Array, PyTree]:\n",
    "        x = self.in_proj(inputs)\n",
    "\n",
    "        # Scan over stack of RNN cells\n",
    "        cells_jaxtypes, cell_pytypes = eqx.partition(self.cells, eqx.is_array)\n",
    "\n",
    "        def f(carry: Array, x: Tuple[eqx.Module, PyTree]) -> Tuple[Array, PyTree]:\n",
    "            input = carry\n",
    "            cell_jaxtypes, state = x\n",
    "\n",
    "            cell = eqx.combine(cell_jaxtypes, cell_pytypes)\n",
    "            next_state = cell(input, state)\n",
    "\n",
    "            if self.cell_type == \"lstm\":\n",
    "                output, _ = next_state  # LSTM-like\n",
    "            elif self.cell_type == \"gru\":\n",
    "                output = next_state  # GRU-like\n",
    "\n",
    "            return output, next_state\n",
    "\n",
    "        x, next_states = jax.lax.scan(f, init=x, xs=(cells_jaxtypes, states))\n",
    "\n",
    "        x = self.out_proj(x)\n",
    "        return x, next_states\n",
    "\n",
    "\n",
    "class ModularControl(eqx.Module):\n",
    "    main: eqx.Module\n",
    "    encoder: Optional[eqx.Module] = None\n",
    "    decoder: Optional[eqx.Module] = None\n",
    "    num_controls: int\n",
    "    num_latents: Optional[int] = None\n",
    "    num_states: Optional[int] = None\n",
    "    mode: str\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_width: int,\n",
    "        hidden_layers: int,\n",
    "        num_controls: int,\n",
    "        num_latents: Optional[int],\n",
    "        num_states: Optional[int],\n",
    "        rnn_cell_type: Optional[str],\n",
    "        mode: str = \"cde-rnn\",\n",
    "        *,\n",
    "        key: PRNGKeyArray\n",
    "    ):\n",
    "        self.num_controls = num_controls\n",
    "        self.num_latents = num_latents\n",
    "        self.num_states = num_states\n",
    "        self.mode = mode\n",
    "\n",
    "        if mode == \"cde-rnn\":\n",
    "            keys = jax.random.split(key, num=3)\n",
    "            self.main = eqx.nn.MLP(\n",
    "                in_size=num_latents,\n",
    "                out_size=(num_latents * (1 + num_states)),\n",
    "                width_size=hidden_width,\n",
    "                depth=hidden_layers,\n",
    "                activation=jax.nn.silu,\n",
    "                final_activation=jax.nn.tanh,\n",
    "                use_final_bias=False,\n",
    "                key=keys[0],\n",
    "            )\n",
    "            self.encoder = eqx.nn.MLP(\n",
    "                in_size=(1 + num_states),\n",
    "                out_size=num_latents,\n",
    "                width_size=hidden_width,\n",
    "                depth=hidden_layers,\n",
    "                activation=jax.nn.silu,\n",
    "                use_final_bias=False,\n",
    "                key=keys[1],\n",
    "            )\n",
    "            self.decoder = eqx.nn.MLP(\n",
    "                in_size=num_latents,\n",
    "                out_size=num_controls,\n",
    "                width_size=hidden_width,\n",
    "                depth=hidden_layers,\n",
    "                activation=jax.nn.silu,\n",
    "                final_activation=jax.nn.tanh,\n",
    "                use_final_bias=False,\n",
    "                key=keys[2],\n",
    "            )\n",
    "        if mode == \"step-rnn\":\n",
    "            self.main = RNN(\n",
    "                in_width=num_states,\n",
    "                out_width=num_controls,\n",
    "                rnn_width=hidden_width,\n",
    "                rnn_layers=hidden_layers,\n",
    "                cell_type=rnn_cell_type,\n",
    "                key=key,\n",
    "            )\n",
    "\n",
    "        elif mode == \"derivative\":\n",
    "            keys = jax.random.split(key, num=2)\n",
    "            self.main = eqx.nn.MLP(\n",
    "                in_size=num_states,\n",
    "                out_size=num_controls,\n",
    "                width_size=hidden_width,\n",
    "                depth=hidden_layers,\n",
    "                activation=jax.nn.silu,\n",
    "                use_final_bias=False,\n",
    "                key=keys[0],\n",
    "            )\n",
    "            self.encoder = eqx.nn.MLP(\n",
    "                in_size=(1 + num_states),\n",
    "                out_size=num_controls,\n",
    "                width_size=hidden_width,\n",
    "                depth=hidden_layers,\n",
    "                activation=jax.nn.silu,\n",
    "                use_final_bias=False,\n",
    "                key=keys[1],\n",
    "            )\n",
    "\n",
    "    def __call__(\n",
    "        self, inputs: Array, states: Optional[PyTree] = None\n",
    "    ) -> Union[Array, Tuple[Array, PyTree]]:\n",
    "        if self.mode == \"cde-rnn\":\n",
    "            dzdX: Array = self.main(inputs)\n",
    "            dzdX = dzdX.reshape(self.num_latents, 1 + self.num_states)\n",
    "\n",
    "            return dzdX\n",
    "        elif self.mode == \"step-rnn\":\n",
    "            return self.main(inputs, states)\n",
    "        else:\n",
    "            return self.main(inputs)\n",
    "\n",
    "    def encode_controls(self, X0: Array) -> Array:\n",
    "        return self.encoder(X0)\n",
    "\n",
    "    def encode_latents(self, z0: Array) -> Array:\n",
    "        return self.encoder(z0)\n",
    "\n",
    "    def decode_latents(self, z: Array) -> Array:\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "control = ModularControl(\n",
    "    hidden_width=64,\n",
    "    hidden_layers=2,\n",
    "    num_controls=1,\n",
    "    num_latents=64,\n",
    "    num_states=4,\n",
    "    rnn_cell_type=\"gru\",\n",
    "    mode=\"step-rnn\",\n",
    "    key=subkey,\n",
    ")\n",
    "\n",
    "optimizer = optax.adam(learning_rate=1e-3)\n",
    "opt_state = optimizer.init(params=eqx.filter(control, eqx.is_array))\n",
    "\n",
    "#env_ode = with_cde_rnn_control(cartpole_ode, num_latents=64)\n",
    "# env_ode = with_control(cartpole_ode)\n",
    "env_ode = cartpole_ode\n",
    "\n",
    "\n",
    "def reward_fn(ys: Array) -> float:\n",
    "    x_thresh = 2.0\n",
    "    theta_thresh = 0.2\n",
    "\n",
    "    x = ys[..., 0]\n",
    "    theta = ys[..., 1]\n",
    "\n",
    "    # Mark invalid states\n",
    "    # invalid_state = (jnp.abs(x) > x_thresh) | (jnp.abs(theta) > theta_thresh)\n",
    "\n",
    "    # Propagate invalid states to the right\n",
    "    # _, invalid_state = jax.lax.scan(\n",
    "    #    lambda carry, scan: (carry | scan, carry | scan), False, invalid_state\n",
    "    # )\n",
    "\n",
    "    # Aggregate reward over valid states\n",
    "    reward = jnp.square(x) + jnp.square(theta)\n",
    "    # reward = jnp.where(invalid_state, 0.0, reward)\n",
    "    reward = jnp.sum(reward)\n",
    "\n",
    "    return -reward\n",
    "\n",
    "    # return -jnp.mean(jnp.square(ys[..., 1]))\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def eval_traj(\n",
    "    control: eqx.Module,\n",
    "    key: jax.random.KeyArray,\n",
    "    trajectory_t1: float,\n",
    "    step_dt: Optional[float] = None,\n",
    "):\n",
    "    init_y0 = jax.random.uniform(\n",
    "        key,\n",
    "        shape=(4,),\n",
    "        minval=-0.05,\n",
    "        maxval=0.05,\n",
    "    )\n",
    "\n",
    "    if step_dt is None:\n",
    "        sol = diffrax.diffeqsolve(\n",
    "            terms=diffrax.ODETerm(env_ode),\n",
    "            solver=diffrax.Kvaerno5(),\n",
    "            t0=0.0,\n",
    "            t1=trajectory_t1,\n",
    "            dt0=0.01,\n",
    "            y0=env_ode._modify_initial_state(control, jnp.asarray([0.0]), init_y0),\n",
    "            args=(control, None),\n",
    "            saveat=diffrax.SaveAt(ts=jnp.linspace(0.0, trajectory_t1, 1024)),\n",
    "            stepsize_controller=diffrax.PIDController(\n",
    "                rtol=1e-5, atol=1e-5, pcoeff=0.3, icoeff=0.3\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return sol\n",
    "    else:\n",
    "        valid_seq, time_seq, solution_seq, control_seq = eval_traj_stepping(\n",
    "            control, trajectory_t1, init_y0, step_dt\n",
    "        )\n",
    "\n",
    "        # ts = jnp.arange(valid_seq.shape[0]) * step_dt\n",
    "        ts = time_seq\n",
    "\n",
    "        sol = diffrax.Solution(\n",
    "            t0=ts[0],\n",
    "            t1=ts[-1],\n",
    "            ts=ts,\n",
    "            ys=solution_seq,\n",
    "            interpolation=None,\n",
    "            stats=dict(),\n",
    "            result=diffrax.RESULTS.successful,\n",
    "            solver_state=None,\n",
    "            controller_state=None,\n",
    "            made_jump=None,\n",
    "        )\n",
    "\n",
    "        return sol\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def eval_traj_stepping(\n",
    "    control: eqx.Module,\n",
    "    trajectory_t1: float,\n",
    "    init_y0: PyTree,\n",
    "    step_dt: float,\n",
    ") -> Tuple[Array, Array, Array, Array]:\n",
    "    # This technique (essentially interrupting the solve at each control update)\n",
    "    # doesn't seem that great, and gives issues on the backward pass\n",
    "    # Manual stepping is probably more appropiate\n",
    "\n",
    "    \"\"\"\n",
    "    # num_steps = jnp.ceil(t1 / step_dt).astype(jnp.int_)\n",
    "    num_steps = int(math.ceil(t1 / step_dt))\n",
    "\n",
    "    def step_fn(\n",
    "        diffeq_solver_state: Optional[PyTree],\n",
    "        diffeq_controller_state: Optional[PyTree],\n",
    "        diffeq_made_jump: Optional[Any],\n",
    "        control_state: PyTree,\n",
    "        y0: PyTree,\n",
    "        t0: float,\n",
    "        t1: float,\n",
    "    ) -> Tuple[diffrax.Solution, PyTree, PyTree]:\n",
    "        control_values, next_control_state = control(y0, control_state)\n",
    "\n",
    "        next_diffeq_state = diffrax.diffeqsolve(\n",
    "            terms=diffrax.ODETerm(\n",
    "                lambda t, y, args: env_ode(t, y, control_values, args)\n",
    "            ),\n",
    "            solver=diffrax.Kvaerno5(),\n",
    "            t0=t0,\n",
    "            t1=t1,\n",
    "            dt0=0.01,\n",
    "            y0=y0,\n",
    "            args=None,\n",
    "            saveat=diffrax.SaveAt(\n",
    "                t1=True, solver_state=True, controller_state=True, made_jump=True\n",
    "            ),\n",
    "            stepsize_controller=diffrax.PIDController(\n",
    "                rtol=1e-5, atol=1e-5, pcoeff=0.3, icoeff=0.3\n",
    "            ),\n",
    "            solver_state=diffeq_solver_state,\n",
    "            controller_state=diffeq_controller_state,\n",
    "            made_jump=diffeq_made_jump,\n",
    "        )\n",
    "\n",
    "        return next_diffeq_state, next_control_state, control_values\n",
    "\n",
    "    # For scanning over a bounded array, see\n",
    "    # https://github.com/google/jax/issues/5642\n",
    "    # https://github.com/google/jax/issues/5642\n",
    "\n",
    "    def scan_fn(\n",
    "        carry: Tuple[diffrax.Solution, PyTree], x: float\n",
    "    ) -> Tuple[Tuple[diffrax.Solution, PyTree], Tuple[PyTree, PyTree]]:\n",
    "        diffeq_state, control_state = carry\n",
    "        t1 = x\n",
    "\n",
    "        next_diffeq_state, next_control_state, control_output = step_fn(\n",
    "            diffeq_solver_state=diffeq_state.solver_state,\n",
    "            diffeq_controller_state=diffeq_state.controller_state,\n",
    "            diffeq_made_jump=diffeq_state.made_jump,\n",
    "            control_state=control_state,\n",
    "            y0=diffeq_state.ys[-1],\n",
    "            t0=diffeq_state.ts[-1],\n",
    "            t1=t1,\n",
    "        )\n",
    "\n",
    "        yt1 = next_diffeq_state.ys[-1]\n",
    "        return (next_diffeq_state, next_control_state), (yt1, control_output)\n",
    "\n",
    "    # Manually do first step\n",
    "    # This can't be moved into scan, since the diffeq states are None, but scan\n",
    "    # expects identical shapes during all iterations\n",
    "    ts = jnp.linspace(0.0, t1, num=num_steps)\n",
    "\n",
    "    init_diffeq_state, init_control_state, init_control_values = step_fn(\n",
    "        diffeq_solver_state=None,\n",
    "        diffeq_controller_state=None,\n",
    "        diffeq_made_jump=None,\n",
    "        control_state=control.main.initial_state,\n",
    "        y0=y0,\n",
    "        t0=ts[0],\n",
    "        t1=ts[1],\n",
    "    )\n",
    "\n",
    "    # Scan over remaining steps\n",
    "    _, (scan_ys, scan_cs) = jax.lax.scan(\n",
    "        scan_fn, init=(init_diffeq_state, init_control_state), xs=ts[2:]\n",
    "    )\n",
    "\n",
    "    # Assemble solution\n",
    "    y01 = jnp.stack((y0, init_diffeq_state.ys[-1]), axis=0)\n",
    "    ys = jnp.concatenate((y01, scan_ys), axis=0)\n",
    "\n",
    "    full_diffeq_solution = diffrax.Solution(\n",
    "        t0=ts[0],\n",
    "        t1=ts[-1],\n",
    "        ts=ts,\n",
    "        ys=ys,\n",
    "        interpolation=None,\n",
    "        stats=dict(),\n",
    "        result=diffrax.RESULTS.successful,\n",
    "        solver_state=None,\n",
    "        controller_state=None,\n",
    "        made_jump=None,\n",
    "    )\n",
    "\n",
    "    return full_diffeq_solution\n",
    "    \"\"\"\n",
    "\n",
    "    ## New version with manual stepping\n",
    "\n",
    "    # Params\n",
    "    max_steps = 4096\n",
    "    control_steps = max_steps\n",
    "    #control_steps = int(math.ceil(trajectory_t1 / step_dt))\n",
    "\n",
    "    init_t0 = 0.0\n",
    "    init_dt0 = 0.01\n",
    "\n",
    "    term = diffrax.ODETerm(lambda t, y, args: env_ode(t, y, args[0], args[1]))\n",
    "    solver = diffrax.Kvaerno5(\n",
    "        nonlinear_solver=diffrax.NewtonNonlinearSolver(rtol=1e-5, atol=1e-5)\n",
    "    )\n",
    "    stepsize_controller: diffrax.PIDController = diffrax.PIDController(\n",
    "        rtol=1e-5, atol=1e-5, pcoeff=0.3, icoeff=0.3\n",
    "    )\n",
    "\n",
    "    # Initialize solver components\n",
    "    init_control_state = control.main.initial_state\n",
    "    init_control_value, _ = control(init_y0, init_control_state)\n",
    "\n",
    "    init_t1, init_stepsize_controller_state = stepsize_controller.init(\n",
    "        terms=term,\n",
    "        t0=init_t0,\n",
    "        t1=init_t0 + init_dt0,\n",
    "        y0=init_y0,\n",
    "        dt0=init_dt0,\n",
    "        args=(init_control_value, None),\n",
    "        func=solver.func(term, init_t0, init_y0, (init_control_value, None)),\n",
    "        error_order=solver.error_order(term),\n",
    "    )\n",
    "\n",
    "    init_solver_state = solver.init(\n",
    "        term, init_t1, trajectory_t1, init_y0, (init_control_value, None)\n",
    "    )\n",
    "\n",
    "    valid_buffer = jnp.zeros((control_steps, 1))\n",
    "    time_buffer = jnp.zeros((control_steps, 1))\n",
    "    solution_buffer = jnp.zeros((control_steps, init_y0.shape[-1]))\n",
    "    control_buffer = jnp.zeros((control_steps, init_control_value.shape[-1]))\n",
    "\n",
    "    valid_buffer = valid_buffer.at[0].set(True)\n",
    "    time_buffer = time_buffer.at[0].set(init_t0)\n",
    "    solution_buffer = solution_buffer.at[0].set(init_y0)\n",
    "    control_buffer = control_buffer.at[0].set(init_control_value)\n",
    "\n",
    "    # Integrate ODE\n",
    "    _Carry = Tuple[\n",
    "        float, float, PyTree, float, PyTree, int, PyTree, PyTree, PyTree, bool\n",
    "    ]\n",
    "\n",
    "    class Carry(eqx.Module):\n",
    "        t0: float\n",
    "        t1: float\n",
    "        y0: float\n",
    "        c0: float\n",
    "        control_steps: int\n",
    "        solver_state: PyTree\n",
    "        stepsize_controller_state: PyTree\n",
    "        control_state: PyTree\n",
    "        made_jump: Any\n",
    "        valid_buffer: Array\n",
    "        time_buffer: Array\n",
    "        solution_buffer: Array\n",
    "        control_buffer: Array\n",
    "\n",
    "    def step_fn(carry: Carry) -> Carry:\n",
    "        # Stepping algorithm overview\n",
    "        # We are guaranteed to start the first iteration with t0 inside of the\n",
    "        # controller step boundary, and a valid c0\n",
    "        # At every iteration, we check if the current upper border of the integration\n",
    "        # interval t1 goes past the controller step boundary. If so, we clamp it to the\n",
    "        # boundary. Then, at the next step, t0 will either be the previous t1 or\n",
    "        # nextafter(t1). Hence, we can always simply check if t0 is past the step\n",
    "        # boundary, to decide if we need to step the controller. If so, we update\n",
    "        # the control values and calculate new controller step boundaries.\n",
    "\n",
    "        # Get controller step boundary\n",
    "        ct1 = init_t0 + step_dt * (carry.control_steps + 1)\n",
    "\n",
    "        # Is the start of the current integration interval at the controller step\n",
    "        # boundary?\n",
    "        # Note: Here, >= is used, because t0 could also be nextafter(ct1), so == could\n",
    "        # fail in certain edge cases.\n",
    "        crossed_boundary = carry.t0 >= ct1\n",
    "\n",
    "        # If so, we increase the number of controller steps...\n",
    "        next_control_steps = jnp.where(\n",
    "            crossed_boundary, carry.control_steps + 1, carry.control_steps\n",
    "        )\n",
    "\n",
    "        # ... and recalculate the controller step boundary\n",
    "        ct0 = init_t0 + step_dt * next_control_steps\n",
    "        ct1 = init_t0 + step_dt * (next_control_steps + 1)\n",
    "\n",
    "        # Then, with the correct step boundary, we clamp the upper border of the\n",
    "        # integration interval to not go past the new boundary\n",
    "        t1 = jnp.where(carry.t1 > ct1, ct1, carry.t1)\n",
    "\n",
    "        # Get the current control values, either from the controller if the boundary\n",
    "        # was crossed or the previous values if we are still in the same controller step\n",
    "        c0, next_control_state = jax.lax.cond(\n",
    "            crossed_boundary,\n",
    "            lambda y0, c0, state: control(y0, state),\n",
    "            lambda y0, c0, state: (c0, state),\n",
    "            carry.y0,\n",
    "            carry.c0,\n",
    "            carry.control_state,\n",
    "        )\n",
    "\n",
    "        # Write solution state into buffers, if boundary was crossed\n",
    "        buffer_idx = next_control_steps\n",
    "        valid_buffer, time_buffer, solution_buffer, control_buffer = jax.lax.cond(\n",
    "            crossed_boundary,\n",
    "            lambda buffer_idx, time_values, solution_values, control_values, valid_buffer, time_buffer, solution_buffer, control_buffer: (\n",
    "                valid_buffer.at[buffer_idx].set(True),\n",
    "                time_buffer.at[buffer_idx].set(time_values),\n",
    "                solution_buffer.at[buffer_idx].set(solution_values),\n",
    "                control_buffer.at[buffer_idx].set(control_values),\n",
    "            ),\n",
    "            lambda buffer_idx, time_values, solution_values, control_values, valid_buffer, time_buffer, solution_buffer, control_buffer: (\n",
    "                valid_buffer,\n",
    "                time_buffer,\n",
    "                solution_buffer,\n",
    "                control_buffer,\n",
    "            ),\n",
    "            buffer_idx,\n",
    "            carry.t0,\n",
    "            carry.y0,\n",
    "            c0,\n",
    "            carry.valid_buffer,\n",
    "            carry.time_buffer,\n",
    "            carry.solution_buffer,\n",
    "            carry.control_buffer,\n",
    "        )\n",
    "\n",
    "        # Attempt a step\n",
    "        y1, local_error_est, dense, next_solver_state, result = solver.step(\n",
    "            terms=term,\n",
    "            t0=carry.t0,\n",
    "            t1=t1,\n",
    "            y0=carry.y0,\n",
    "            args=(c0, None),\n",
    "            solver_state=carry.solver_state,\n",
    "            made_jump=jnp.logical_or(crossed_boundary, carry.made_jump),\n",
    "        )\n",
    "\n",
    "        (\n",
    "            step_accepted,\n",
    "            next_t0,\n",
    "            next_t1,\n",
    "            made_jump,\n",
    "            next_stepsize_controller_state,\n",
    "            result,\n",
    "        ) = stepsize_controller.adapt_step_size(\n",
    "            t0=carry.t0,\n",
    "            t1=t1,\n",
    "            y0=carry.y0,\n",
    "            y1_candidate=y1,\n",
    "            args=(c0, None),\n",
    "            y_error=local_error_est,\n",
    "            error_order=solver.order(term),\n",
    "            controller_state=carry.stepsize_controller_state,\n",
    "        )\n",
    "\n",
    "        return Carry(\n",
    "            t0=next_t0,\n",
    "            t1=next_t1,\n",
    "            y0=y1,\n",
    "            c0=c0,\n",
    "            control_steps=next_control_steps,\n",
    "            solver_state=next_solver_state,\n",
    "            stepsize_controller_state=next_stepsize_controller_state,\n",
    "            control_state=next_control_state,\n",
    "            made_jump=made_jump,\n",
    "            valid_buffer=valid_buffer,\n",
    "            time_buffer=time_buffer,\n",
    "            solution_buffer=solution_buffer,\n",
    "            control_buffer=control_buffer,\n",
    "        )\n",
    "\n",
    "    def cond_fn(carry: Carry) -> bool:\n",
    "        return carry.t0 < trajectory_t1\n",
    "\n",
    "    last = eqx.internal.while_loop(\n",
    "        cond_fun=cond_fn,\n",
    "        body_fun=step_fn,\n",
    "        init_val=Carry(\n",
    "            t0=init_t0,\n",
    "            t1=init_t1,\n",
    "            y0=init_y0,\n",
    "            c0=init_control_value,\n",
    "            control_steps=jnp.int_(0),\n",
    "            solver_state=init_solver_state,\n",
    "            stepsize_controller_state=init_stepsize_controller_state,\n",
    "            control_state=init_control_state,\n",
    "            made_jump=jnp.bool_(False),\n",
    "            valid_buffer=valid_buffer,\n",
    "            time_buffer=time_buffer,\n",
    "            solution_buffer=solution_buffer,\n",
    "            control_buffer=control_buffer,\n",
    "        ),\n",
    "        max_steps=4096,\n",
    "        buffers=lambda carry: (\n",
    "            carry.valid_buffer,\n",
    "            carry.time_buffer,\n",
    "            carry.solution_buffer,\n",
    "            carry.control_buffer,\n",
    "        ),\n",
    "        kind=\"checkpointed\",\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        last.valid_buffer,\n",
    "        last.time_buffer,\n",
    "        last.solution_buffer,\n",
    "        last.control_buffer,\n",
    "    )\n",
    "\n",
    "\n",
    "@eqx.filter_value_and_grad\n",
    "def eval_reward(\n",
    "    control: eqx.Module,\n",
    "    key: jax.random.KeyArray,\n",
    "    batch_size: int,\n",
    "    t1: float,\n",
    "    step_dt: Optional[float] = None,\n",
    ") -> float:\n",
    "    # keys = jax.random.split(key, batch_size)\n",
    "    # sol = jax.vmap(eval_traj, in_axes=(None, 0), out_axes=0)(control, keys)\n",
    "    sol = eval_traj(control, key, t1, step_dt)\n",
    "\n",
    "    reward = reward_fn(sol.ys)\n",
    "    return reward\n",
    "\n",
    "\n",
    "# @eqx.filter_jit\n",
    "def update_step(\n",
    "    control: eqx.Module,\n",
    "    opt_state: optax.OptState,\n",
    "    key: jax.random.KeyArray,\n",
    "    t1: float,\n",
    "    step_dt: Optional[float] = None,\n",
    "):\n",
    "    reward, grads = eval_reward(control, key, 16, t1, step_dt)\n",
    "    grads = jax.tree_map(lambda x: -x, grads)\n",
    "\n",
    "    control_params, control_static = eqx.partition(control, eqx.is_array)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state, params=control_params)\n",
    "    control_params = optax.apply_updates(control_params, updates)\n",
    "\n",
    "    control = eqx.combine(control_params, control_static)\n",
    "\n",
    "    return control, opt_state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 1024\n",
    "max_t1 = 10.0\n",
    "step_dt = 0.01\n",
    "#step_dt = None\n",
    "\n",
    "t1_schedule = jnp.geomspace(1e-2, 1e2, num=num_steps)\n",
    "\n",
    "pbar = trange(num_steps)\n",
    "for i in pbar:\n",
    "    #trajectory_t1 = jnp.float64(max_t1 * (i + 1) / num_steps) # This will jit t1\n",
    "    trajectory_t1 = t1_schedule[i]\n",
    "    #trajectory_t1 = 10.0\n",
    "\n",
    "    key, subkey = jax.random.split(key)\n",
    "    control, opt_state, reward = update_step(control, opt_state, subkey, trajectory_t1, step_dt)\n",
    "\n",
    "    if i % 16 == 0:\n",
    "        pbar.set_postfix({\"reward\": reward.item(), \"t1\": trajectory_t1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "#sol = eval_traj(control, subkey, jnp.float64(max_t1), step_dt=step_dt)\n",
    "sol = eval_traj(control, subkey, 100.0, step_dt=step_dt)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(sol.ts, sol.ys[:, :2])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(sol.ts, sol.ys[:, -64:])\n",
    "plt.show()\n",
    "\n",
    "#plt.figure()\n",
    "#plt.plot(sol.ts, jax.vmap(control)(sol.ys))\n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Control Test\n",
    "Train a control with the current system state as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "control = eqx.nn.MLP(\n",
    "    in_size=4,\n",
    "    out_size=1,\n",
    "    width_size=64,\n",
    "    depth=2,\n",
    "    use_final_bias=False,\n",
    "    # activation=jax.nn.tanh,\n",
    "    final_activation=jax.nn.tanh,\n",
    "    key=subkey,\n",
    ")\n",
    "\n",
    "optimizer = optax.adam(learning_rate=1e-3)\n",
    "opt_state = optimizer.init(params=eqx.filter(control, eqx.is_array))\n",
    "\n",
    "\n",
    "def reward_fn(ys: Array) -> float:\n",
    "    x_thresh = 2.0\n",
    "    theta_thresh = 0.2\n",
    "\n",
    "    x = ys[..., 0]\n",
    "    theta = ys[..., 1]\n",
    "\n",
    "    # Mark invalid states\n",
    "    # invalid_state = (jnp.abs(x) > x_thresh) | (jnp.abs(theta) > theta_thresh)\n",
    "\n",
    "    # Propagate invalid states to the right\n",
    "    # _, invalid_state = jax.lax.scan(\n",
    "    #    lambda carry, scan: (carry | scan, carry | scan), False, invalid_state\n",
    "    # )\n",
    "\n",
    "    # Aggregate reward over valid states\n",
    "    reward = jnp.square(x) + jnp.square(theta)\n",
    "    # reward = jnp.where(invalid_state, 0.0, reward)\n",
    "    reward = jnp.sum(reward)\n",
    "\n",
    "    return -reward\n",
    "\n",
    "    # return -jnp.mean(jnp.square(ys[..., 1]))\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def eval_traj(control: eqx.Module, key: jax.random.KeyArray, t1: float):\n",
    "    y0 = jax.random.uniform(\n",
    "        key,\n",
    "        shape=(4,),\n",
    "        minval=-0.05,\n",
    "        maxval=0.05,\n",
    "        # minval=jnp.asarray([-0.5, -0.1, -5.0, -1.0]),\n",
    "        # maxval=jnp.asarray([0.5, 0.1, 5.0, 1.0]),\n",
    "    )\n",
    "\n",
    "    sol = diffrax.diffeqsolve(\n",
    "        terms=diffrax.ODETerm(with_control(cartpole_ode)),\n",
    "        solver=diffrax.Dopri5(),\n",
    "        t0=0.0,\n",
    "        t1=t1,\n",
    "        dt0=0.01,\n",
    "        y0=y0,\n",
    "        args=(control, None),\n",
    "        saveat=diffrax.SaveAt(ts=jnp.linspace(0.0, t1, 1024)),\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-5, atol=1e-5, pcoeff=0.3, icoeff=0.3\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return sol\n",
    "\n",
    "@eqx.filter_value_and_grad\n",
    "def eval_reward(\n",
    "    control: eqx.Module, key: jax.random.KeyArray, batch_size: int, t1: float\n",
    ") -> float:\n",
    "    # keys = jax.random.split(key, batch_size)\n",
    "    # sol = jax.vmap(eval_traj, in_axes=(None, 0), out_axes=0)(control, keys)\n",
    "    sol = eval_traj(control, key, t1)\n",
    "\n",
    "    reward = reward_fn(sol.ys)\n",
    "    return reward\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def update_step(\n",
    "    control: eqx.Module, opt_state: optax.OptState, key: jax.random.KeyArray, t1: float\n",
    "):\n",
    "    reward, grads = eval_reward(control, key, 16, t1)\n",
    "    grads = jax.tree_map(lambda x: -x, grads)\n",
    "\n",
    "    control_params, control_static = eqx.partition(control, eqx.is_array)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state, params=control_params)\n",
    "    control_params = optax.apply_updates(control_params, updates)\n",
    "\n",
    "    control = eqx.combine(control_params, control_static)\n",
    "\n",
    "    return control, opt_state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = trange(1024 * 16)\n",
    "for i in pbar:\n",
    "    t1 = jnp.float64(10 * (i + 1) / (1024 * 16))\n",
    "\n",
    "    key, subkey = jax.random.split(key)\n",
    "    control, opt_state, reward = update_step(control, opt_state, subkey, t1)\n",
    "\n",
    "    if i % 16 == 0:\n",
    "        pbar.set_postfix({\"reward\": reward.item(), \"t1\": t1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "sol = eval_traj(control, subkey, jnp.float64(10.0))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(sol.ts, sol.ys[:, :2])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(sol.ts, jax.vmap(control)(sol.ys))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active control parameterizing the derivative of the control signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "control = eqx.nn.MLP(\n",
    "    in_size=5,\n",
    "    out_size=1,\n",
    "    width_size=64,\n",
    "    depth=2,\n",
    "    use_final_bias=False,\n",
    "    # activation=jax.nn.tanh,\n",
    "    # final_activation=jax.nn.tanh,\n",
    "    key=subkey,\n",
    ")\n",
    "\n",
    "optimizer = optax.adam(learning_rate=1e-3)\n",
    "opt_state = optimizer.init(params=eqx.filter(control, eqx.is_array))\n",
    "\n",
    "\n",
    "def reward_fn(ys: Array) -> float:\n",
    "    x_thresh = 2.0\n",
    "    theta_thresh = 0.2\n",
    "\n",
    "    x = ys[..., 0]\n",
    "    theta = ys[..., 1]\n",
    "\n",
    "    # Mark invalid states\n",
    "    # invalid_state = (jnp.abs(x) > x_thresh) | (jnp.abs(theta) > theta_thresh)\n",
    "\n",
    "    # Propagate invalid states to the right\n",
    "    # _, invalid_state = jax.lax.scan(\n",
    "    #    lambda carry, scan: (carry | scan, carry | scan), False, invalid_state\n",
    "    # )\n",
    "\n",
    "    # Aggregate reward over valid states\n",
    "    reward = jnp.square(x) + jnp.square(theta)\n",
    "    # reward = jnp.where(invalid_state, 0.0, reward)\n",
    "    reward = jnp.sum(reward)\n",
    "\n",
    "    return -reward\n",
    "\n",
    "    # return -jnp.mean(jnp.square(ys[..., 1]))\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def eval_traj(control: eqx.Module, key: jax.random.KeyArray, t1: float):\n",
    "    y0 = jax.random.uniform(\n",
    "        key,\n",
    "        shape=(4,),\n",
    "        minval=-0.05,\n",
    "        maxval=0.05,\n",
    "        # minval=jnp.asarray([-0.5, -0.1, -5.0, -1.0]),\n",
    "        # maxval=jnp.asarray([0.5, 0.1, 5.0, 1.0]),\n",
    "    )\n",
    "\n",
    "    sol = diffrax.diffeqsolve(\n",
    "        terms=diffrax.ODETerm(with_derivative_control(cartpole_ode, num_controls=1)),\n",
    "        solver=diffrax.Dopri5(),\n",
    "        t0=0.0,\n",
    "        t1=t1,\n",
    "        dt0=0.01,\n",
    "        y0=jnp.concatenate((jnp.zeros(1), y0)),\n",
    "        args=(control, None),\n",
    "        saveat=diffrax.SaveAt(ts=jnp.linspace(0.0, t1, 1024)),\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-5, atol=1e-5, pcoeff=0.3, icoeff=0.3\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return sol\n",
    "\n",
    "\n",
    "@eqx.filter_value_and_grad\n",
    "def eval_reward(\n",
    "    control: eqx.Module, key: jax.random.KeyArray, batch_size: int, t1: float\n",
    ") -> float:\n",
    "    # keys = jax.random.split(key, batch_size)\n",
    "    # sol = jax.vmap(eval_traj, in_axes=(None, 0), out_axes=0)(control, keys)\n",
    "    sol = eval_traj(control, key, t1)\n",
    "\n",
    "    reward = reward_fn(sol.ys)\n",
    "    return reward\n",
    "\n",
    "\n",
    "#@eqx.filter_jit\n",
    "def update_step(\n",
    "    control: eqx.Module, opt_state: optax.OptState, key: jax.random.KeyArray, t1: float\n",
    "):\n",
    "    reward, grads = eval_reward(control, key, 16, t1)\n",
    "    grads = jax.tree_map(lambda x: -x, grads)\n",
    "\n",
    "    control_params, control_static = eqx.partition(control, eqx.is_array)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state, params=control_params)\n",
    "    control_params = optax.apply_updates(control_params, updates)\n",
    "\n",
    "    control = eqx.combine(control_params, control_static)\n",
    "\n",
    "    return control, opt_state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = trange(1024 * 16)\n",
    "for i in pbar:\n",
    "    t1 = jnp.float64(10 * (i + 1) / (1024 * 16))\n",
    "\n",
    "    key, subkey = jax.random.split(key)\n",
    "    control, opt_state, reward = update_step(control, opt_state, subkey, t1)\n",
    "\n",
    "    if i % 16 == 0:\n",
    "        pbar.set_postfix({\"reward\": reward.item(), \"t1\": t1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "sol = eval_traj(control, subkey, jnp.float64(100.0))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(sol.ts, sol.ys[:, :2])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(sol.ts, jax.vmap(control)(sol.ys))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.axhline()\n",
    "\n",
    "cart_width = 0.5\n",
    "cart_height = 0.25\n",
    "cart = ax.add_patch(\n",
    "    matplotlib.patches.Rectangle(\n",
    "        [sol.ys[0, 0] - cart_width / 2, 0], cart_width, cart_height\n",
    "    )\n",
    ")\n",
    "\n",
    "pole_width = 2.5\n",
    "pole_length = 0.5\n",
    "\n",
    "\n",
    "def get_pole_data(cart_x, pole_angle):\n",
    "    pole_base_x = cart_x\n",
    "    pole_base_y = cart_height\n",
    "    pole_end_x = pole_base_x + math.cos(pole_angle)\n",
    "    pole_end_y = pole_base_y + math.sin(pole_angle)\n",
    "\n",
    "    return [pole_base_x, pole_end_x], [pole_base_y, pole_end_y]\n",
    "\n",
    "\n",
    "pole = ax.add_line(\n",
    "    matplotlib.lines.Line2D(\n",
    "        *get_pole_data(sol.ys[0, 0], sol.ys[0, 1]), linewidth=pole_width\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def init():\n",
    "    ax.set_xlim([-10.0, 10.0])\n",
    "    ax.set_ylim([-0.5, 2.0])\n",
    "\n",
    "    return cart, pole\n",
    "\n",
    "\n",
    "def update(frame):\n",
    "    y = sol.ys[frame]\n",
    "\n",
    "    cart.set(x=y[0])\n",
    "    pole.set_data(*get_pole_data(y[0], y[1]))\n",
    "\n",
    "    return cart, pole\n",
    "\n",
    "animation = matplotlib.animation.FuncAnimation(fig=fig, func=update, frames=range(len(sol.ts)), init_func=init)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-optimal-control-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
