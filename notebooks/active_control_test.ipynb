{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import functools\n",
    "import math\n",
    "from functools import partial\n",
    "from typing import Callable, List, Optional, Tuple, Type\n",
    "\n",
    "import diffrax\n",
    "import equinox as eqx\n",
    "import matplotlib.animation\n",
    "import matplotlib.lines\n",
    "import matplotlib.patches\n",
    "import matplotlib.pyplot as plt\n",
    "import optax\n",
    "from jaxtyping import Array, ArrayLike, PRNGKeyArray, PyTree, Scalar\n",
    "from tqdm.auto import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartpole_ode(t: Scalar, y: Array, u: Array, args: PyTree) -> PyTree:\n",
    "    f = 10 * u[0]\n",
    "\n",
    "    g = 9.81\n",
    "    mass_cart = 1.0\n",
    "    mass_pole = 0.1\n",
    "    length_pole = 0.5\n",
    "\n",
    "    x = y[0]\n",
    "    theta = y[1]\n",
    "    dot_x = y[2]\n",
    "    dot_theta = y[3]\n",
    "\n",
    "    ddot_theta = (\n",
    "        g * jnp.sin(theta)\n",
    "        + jnp.cos(theta)\n",
    "        * (\n",
    "            (-f - mass_pole * length_pole * jnp.square(dot_theta) * jnp.sin(theta))\n",
    "            / (mass_cart + mass_pole)\n",
    "        )\n",
    "    ) / (\n",
    "        length_pole\n",
    "        * (4 / 3 - (mass_pole * jnp.square(jnp.cos(theta)) / (mass_cart + mass_pole)))\n",
    "    )\n",
    "\n",
    "    ddot_x = (\n",
    "        f\n",
    "        + mass_pole\n",
    "        * length_pole\n",
    "        * (jnp.square(dot_theta) * jnp.sin(theta) - ddot_theta * jnp.cos(theta))\n",
    "    ) / (mass_cart + mass_pole)\n",
    "\n",
    "    dy = jnp.stack((dot_x, dot_theta, ddot_x, ddot_theta), axis=-1)\n",
    "    return dy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control function decorators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_control(\n",
    "    f: Callable[[Scalar, PyTree, PyTree, PyTree], PyTree]\n",
    ") -> Callable[[Scalar, PyTree, PyTree], PyTree]:\n",
    "    @functools.wraps(f)\n",
    "    def wrapper(t: Scalar, y: PyTree, args: PyTree) -> PyTree:\n",
    "        control, f_args = args\n",
    "        u = control(y)\n",
    "\n",
    "        dy = f(t, y, u, f_args)\n",
    "        return dy\n",
    "\n",
    "    def modify_initial_state(control: PyTree, t0: Scalar, y0: Array) -> Array:\n",
    "        return y0\n",
    "\n",
    "    wrapper_fn = wrapper\n",
    "    wrapper_fn._modify_initial_state = modify_initial_state\n",
    "\n",
    "    return wrapper_fn\n",
    "\n",
    "\n",
    "def with_derivative_control(\n",
    "    f: Callable[[Scalar, PyTree, PyTree, PyTree], PyTree], num_controls: int\n",
    ") -> Callable[[Scalar, PyTree, PyTree], PyTree]:\n",
    "    @functools.wraps(f)\n",
    "    def wrapper(t: Scalar, y: PyTree, args: PyTree) -> PyTree:\n",
    "        control, f_args = args\n",
    "        c_u, f_y = y[..., :num_controls], y[..., num_controls:]\n",
    "\n",
    "        f_dy = f(t, f_y, c_u, f_args)\n",
    "        c_du = control(y)\n",
    "\n",
    "        dy = jnp.concatenate((c_du, f_dy), axis=-1)\n",
    "        return dy\n",
    "\n",
    "    def modify_initial_state(control: PyTree, t0: Scalar, y0: Array) -> Array:\n",
    "        X0 = jnp.concatenate((t0, y0), axis=-1)\n",
    "        c0 = control.encode_controls(X0)\n",
    "\n",
    "        # c0 = jnp.zeros(num_controls)\n",
    "\n",
    "        y0 = jnp.concatenate((c0, y0), axis=-1)\n",
    "        return y0\n",
    "\n",
    "    wrapper_fn = wrapper\n",
    "    wrapper_fn._modify_initial_state = modify_initial_state\n",
    "\n",
    "    return wrapper_fn\n",
    "\n",
    "\n",
    "# This needs stepping support, since ODE RNNs are discontinuous over state changes\n",
    "# def with_ode_rnn_control(f: Callable[[Scalar, PyTree, PyTree, PyTree], PyTree], num_controls: int, num_memory: int):\n",
    "\n",
    "\n",
    "def with_cde_rnn_control(\n",
    "    f: Callable[[Scalar, PyTree, PyTree, PyTree], PyTree], num_latents: int\n",
    "):\n",
    "    @functools.wraps(f)\n",
    "    def wrapper(t: Scalar, y: PyTree, args: PyTree) -> PyTree:\n",
    "        control, f_args = args\n",
    "        f_y, c_z = y[..., :-num_latents], y[..., -num_latents:]\n",
    "\n",
    "        c_u = control.decode_latents(c_z)\n",
    "        f_dy = f(t, f_y, c_u, f_args)\n",
    "\n",
    "        dt = jnp.ones(1)\n",
    "        dX = jnp.concatenate((dt, f_dy), axis=-1)\n",
    "\n",
    "        c_dzdX = control(c_z)\n",
    "        c_dz = c_dzdX @ dX\n",
    "\n",
    "        dy = jnp.concatenate((f_dy, c_dz), axis=-1)\n",
    "        return dy\n",
    "\n",
    "    def modify_initial_state(control: PyTree, t0: Scalar, y0: Array) -> Array:\n",
    "        X0 = jnp.concatenate((t0, y0), axis=-1)\n",
    "        z0 = control.encode_latents(X0)\n",
    "\n",
    "        y0 = jnp.concatenate((z0, y0), axis=-1)\n",
    "        return y0\n",
    "\n",
    "    wrapper_fn = wrapper\n",
    "    wrapper_fn._modify_initial_state = modify_initial_state\n",
    "\n",
    "    return wrapper_fn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Control Test (with generic interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(eqx.Module):\n",
    "    in_proj: eqx.nn.Linear\n",
    "    out_proj: eqx.nn.Linear\n",
    "    cells: eqx.Module\n",
    "\n",
    "    def __init__(self, in_width: int, out_width: int, rnn_width: int, rnn_layers: int, cell_cls: Type[eqx.Module], key: PRNGKeyArray):\n",
    "        key, key1, key2 = jax.random.split(key, num=3)\n",
    "        self.in_proj = eqx.nn.Linear(in_width, rnn_width, key=key1)\n",
    "        self.out_proj = eqx.nn.Linear(rnn_width, out_width, use_bias=False, key=key2)\n",
    "\n",
    "        keys = jax.random.split(key, num=rnn_layers)\n",
    "        make_cells = lambda k: cell_cls(input_size=rnn_width, hidden_size=rnn_width, key=k)\n",
    "        self.cells = jax.vmap(make_cells)(keys)\n",
    "\n",
    "    def __call__(self, inputs: Array, states: PyTree) -> Tuple[Array, PyTree]:\n",
    "        x = self.in_proj(inputs)\n",
    "\n",
    "        # Scan over stack of RNN cells\n",
    "        def f(carry: Array, x: Tuple[eqx.Module, PyTree]) -> Tuple[Array, PyTree]:\n",
    "            input = carry\n",
    "            cell, state = x\n",
    "\n",
    "            next_state = cell(input, state)\n",
    "\n",
    "            if isinstance(next_state, Tuple[Array, Array]):\n",
    "                output, _ = next_state\n",
    "            elif isinstance(next_state, Array):\n",
    "                output = next_state\n",
    "\n",
    "            return output, next_state\n",
    "\n",
    "        x, next_states = jax.lax.scan(f, init=x, xs=(self.cells, states))\n",
    "\n",
    "        x = self.out_proj(x)\n",
    "        return x, next_states\n",
    "\n",
    "class ModularControl(eqx.Module):\n",
    "    main: eqx.Module\n",
    "    encoder: Optional[eqx.Module]\n",
    "    decoder: Optional[eqx.Module]\n",
    "    num_controls: int\n",
    "    num_latents: Optional[int]\n",
    "    num_states: Optional[int]\n",
    "    mode: str\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_width: int,\n",
    "        hidden_layers: int,\n",
    "        num_controls: int,\n",
    "        num_latents: Optional[int],\n",
    "        num_states: Optional[int],\n",
    "        rnn_cell_cls: Optional[Type[eqx.Module]],\n",
    "        mode: str = \"cde-rnn\",\n",
    "        *,\n",
    "        key: PRNGKeyArray\n",
    "    ):\n",
    "        self.num_controls = num_controls\n",
    "        self.num_latents = num_latents\n",
    "        self.num_states = num_states\n",
    "        self.mode = mode\n",
    "\n",
    "        if mode == \"cde-rnn\":\n",
    "            keys = jax.random.split(key, num=3)\n",
    "            self.main = eqx.nn.MLP(\n",
    "                in_size=num_latents,\n",
    "                out_size=(num_latents * (1 + num_states)),\n",
    "                width_size=hidden_width,\n",
    "                depth=hidden_layers,\n",
    "                activation=jax.nn.silu,\n",
    "                final_activation=jax.nn.tanh,\n",
    "                use_final_bias=False,\n",
    "                key=keys[0],\n",
    "            )\n",
    "            self.encoder = eqx.nn.MLP(\n",
    "                in_size=(1 + num_states),\n",
    "                out_size=num_latents,\n",
    "                width_size=hidden_width,\n",
    "                depth=hidden_layers,\n",
    "                activation=jax.nn.silu,\n",
    "                use_final_bias=False,\n",
    "                key=keys[1],\n",
    "            )\n",
    "            self.decoder = eqx.nn.MLP(\n",
    "                in_size=num_latents,\n",
    "                out_size=num_controls,\n",
    "                width_size=hidden_width,\n",
    "                depth=hidden_layers,\n",
    "                activation=jax.nn.silu,\n",
    "                final_activation=jax.nn.tanh,\n",
    "                use_final_bias=False,\n",
    "                key=keys[2],\n",
    "            )\n",
    "        if mode == \"step-rnn\":\n",
    "            \n",
    "        elif mode == \"derivative\":\n",
    "            keys = jax.random.split(key, num=2)\n",
    "            self.main = eqx.nn.MLP(\n",
    "                in_size=num_states,\n",
    "                out_size=num_controls,\n",
    "                width_size=hidden_width,\n",
    "                depth=hidden_layers,\n",
    "                activation=jax.nn.silu,\n",
    "                use_final_bias=False,\n",
    "                key=keys[0],\n",
    "            )\n",
    "            self.encoder = eqx.nn.MLP(\n",
    "                in_size=(1 + num_states),\n",
    "                out_size=num_controls,\n",
    "                width_size=hidden_width,\n",
    "                depth=hidden_layers,\n",
    "                activation=jax.nn.silu,\n",
    "                use_final_bias=False,\n",
    "                key=keys[1],\n",
    "            )\n",
    "\n",
    "    def __call__(self, inputs: Array) -> Array:\n",
    "        if self.mode == \"cde-rnn\":\n",
    "            dzdX: Array = self.main(inputs)\n",
    "            dzdX = dzdX.reshape(self.num_latents, 1 + self.num_states)\n",
    "\n",
    "            return dzdX\n",
    "        else:\n",
    "            return self.main(inputs)\n",
    "\n",
    "    def encode_controls(self, X0: Array) -> Array:\n",
    "        return self.encoder(X0)\n",
    "\n",
    "    def encode_latents(self, z0: Array) -> Array:\n",
    "        return self.encoder(z0)\n",
    "\n",
    "    def decode_latents(self, z: Array) -> Array:\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "control = ModularControl(\n",
    "    hidden_width=64,\n",
    "    hidden_layers=2,\n",
    "    num_controls=1,\n",
    "    num_latents=16,\n",
    "    num_states=4,\n",
    "    mode=\"cde-rnn\",\n",
    "    key=subkey,\n",
    ")\n",
    "\n",
    "optimizer = optax.adam(learning_rate=1e-3)\n",
    "opt_state = optimizer.init(params=eqx.filter(control, eqx.is_array))\n",
    "env_ode = with_cde_rnn_control(cartpole_ode, num_latents=16)\n",
    "\n",
    "\n",
    "def reward_fn(ys: Array) -> float:\n",
    "    x_thresh = 2.0\n",
    "    theta_thresh = 0.2\n",
    "\n",
    "    x = ys[..., 0]\n",
    "    theta = ys[..., 1]\n",
    "\n",
    "    # Mark invalid states\n",
    "    # invalid_state = (jnp.abs(x) > x_thresh) | (jnp.abs(theta) > theta_thresh)\n",
    "\n",
    "    # Propagate invalid states to the right\n",
    "    # _, invalid_state = jax.lax.scan(\n",
    "    #    lambda carry, scan: (carry | scan, carry | scan), False, invalid_state\n",
    "    # )\n",
    "\n",
    "    # Aggregate reward over valid states\n",
    "    reward = jnp.square(x) + jnp.square(theta)\n",
    "    # reward = jnp.where(invalid_state, 0.0, reward)\n",
    "    reward = jnp.sum(reward)\n",
    "\n",
    "    return -reward\n",
    "\n",
    "    # return -jnp.mean(jnp.square(ys[..., 1]))\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def eval_traj(control: eqx.Module, key: jax.random.KeyArray, t1: float):\n",
    "    y0 = jax.random.uniform(\n",
    "        key,\n",
    "        shape=(4,),\n",
    "        minval=-0.05,\n",
    "        maxval=0.05,\n",
    "    )\n",
    "\n",
    "    sol = diffrax.diffeqsolve(\n",
    "        terms=diffrax.ODETerm(env_ode),\n",
    "        solver=diffrax.Kvaerno5(),\n",
    "        t0=0.0,\n",
    "        t1=t1,\n",
    "        dt0=0.01,\n",
    "        y0=env_ode._modify_initial_state(control, jnp.asarray([0.0]), y0),\n",
    "        args=(control, None),\n",
    "        saveat=diffrax.SaveAt(ts=jnp.linspace(0.0, t1, 1024)),\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-5, atol=1e-5, pcoeff=0.3, icoeff=0.3\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return sol\n",
    "\n",
    "\n",
    "@eqx.filter_value_and_grad\n",
    "def eval_reward(\n",
    "    control: eqx.Module, key: jax.random.KeyArray, batch_size: int, t1: float\n",
    ") -> float:\n",
    "    # keys = jax.random.split(key, batch_size)\n",
    "    # sol = jax.vmap(eval_traj, in_axes=(None, 0), out_axes=0)(control, keys)\n",
    "    sol = eval_traj(control, key, t1)\n",
    "\n",
    "    reward = reward_fn(sol.ys)\n",
    "    return reward\n",
    "\n",
    "\n",
    "# @eqx.filter_jit\n",
    "def update_step(\n",
    "    control: eqx.Module, opt_state: optax.OptState, key: jax.random.KeyArray, t1: float\n",
    "):\n",
    "    reward, grads = eval_reward(control, key, 16, t1)\n",
    "    grads = jax.tree_map(lambda x: -x, grads)\n",
    "\n",
    "    control_params, control_static = eqx.partition(control, eqx.is_array)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state, params=control_params)\n",
    "    control_params = optax.apply_updates(control_params, updates)\n",
    "\n",
    "    control = eqx.combine(control_params, control_static)\n",
    "\n",
    "    return control, opt_state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 1024\n",
    "max_t1 = 100.0\n",
    "\n",
    "pbar = trange(num_steps)\n",
    "for i in pbar:\n",
    "    t1 = jnp.float64(max_t1 * (i + 1) / num_steps)\n",
    "\n",
    "    key, subkey = jax.random.split(key)\n",
    "    control, opt_state, reward = update_step(control, opt_state, subkey, t1)\n",
    "\n",
    "    if i % 16 == 0:\n",
    "        pbar.set_postfix({\"reward\": reward.item(), \"t1\": t1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "sol = eval_traj(control, subkey, jnp.float64(max_t1))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(sol.ts, sol.ys[:, :2])\n",
    "plt.show()\n",
    "\n",
    "#plt.figure()\n",
    "#plt.plot(sol.ts, jax.vmap(control)(sol.ys))\n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Control Test\n",
    "Train a control with the current system state as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "control = eqx.nn.MLP(\n",
    "    in_size=4,\n",
    "    out_size=1,\n",
    "    width_size=64,\n",
    "    depth=2,\n",
    "    use_final_bias=False,\n",
    "    # activation=jax.nn.tanh,\n",
    "    final_activation=jax.nn.tanh,\n",
    "    key=subkey,\n",
    ")\n",
    "\n",
    "optimizer = optax.adam(learning_rate=1e-3)\n",
    "opt_state = optimizer.init(params=eqx.filter(control, eqx.is_array))\n",
    "\n",
    "\n",
    "def reward_fn(ys: Array) -> float:\n",
    "    x_thresh = 2.0\n",
    "    theta_thresh = 0.2\n",
    "\n",
    "    x = ys[..., 0]\n",
    "    theta = ys[..., 1]\n",
    "\n",
    "    # Mark invalid states\n",
    "    # invalid_state = (jnp.abs(x) > x_thresh) | (jnp.abs(theta) > theta_thresh)\n",
    "\n",
    "    # Propagate invalid states to the right\n",
    "    # _, invalid_state = jax.lax.scan(\n",
    "    #    lambda carry, scan: (carry | scan, carry | scan), False, invalid_state\n",
    "    # )\n",
    "\n",
    "    # Aggregate reward over valid states\n",
    "    reward = jnp.square(x) + jnp.square(theta)\n",
    "    # reward = jnp.where(invalid_state, 0.0, reward)\n",
    "    reward = jnp.sum(reward)\n",
    "\n",
    "    return -reward\n",
    "\n",
    "    # return -jnp.mean(jnp.square(ys[..., 1]))\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def eval_traj(control: eqx.Module, key: jax.random.KeyArray, t1: float):\n",
    "    y0 = jax.random.uniform(\n",
    "        key,\n",
    "        shape=(4,),\n",
    "        minval=-0.05,\n",
    "        maxval=0.05,\n",
    "        # minval=jnp.asarray([-0.5, -0.1, -5.0, -1.0]),\n",
    "        # maxval=jnp.asarray([0.5, 0.1, 5.0, 1.0]),\n",
    "    )\n",
    "\n",
    "    sol = diffrax.diffeqsolve(\n",
    "        terms=diffrax.ODETerm(with_control(cartpole_ode)),\n",
    "        solver=diffrax.Dopri5(),\n",
    "        t0=0.0,\n",
    "        t1=t1,\n",
    "        dt0=0.01,\n",
    "        y0=y0,\n",
    "        args=(control, None),\n",
    "        saveat=diffrax.SaveAt(ts=jnp.linspace(0.0, t1, 1024)),\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-5, atol=1e-5, pcoeff=0.3, icoeff=0.3\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return sol\n",
    "\n",
    "\n",
    "@eqx.filter_value_and_grad\n",
    "def eval_reward(\n",
    "    control: eqx.Module, key: jax.random.KeyArray, batch_size: int, t1: float\n",
    ") -> float:\n",
    "    # keys = jax.random.split(key, batch_size)\n",
    "    # sol = jax.vmap(eval_traj, in_axes=(None, 0), out_axes=0)(control, keys)\n",
    "    sol = eval_traj(control, key, t1)\n",
    "\n",
    "    reward = reward_fn(sol.ys)\n",
    "    return reward\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def update_step(\n",
    "    control: eqx.Module, opt_state: optax.OptState, key: jax.random.KeyArray, t1: float\n",
    "):\n",
    "    reward, grads = eval_reward(control, key, 16, t1)\n",
    "    grads = jax.tree_map(lambda x: -x, grads)\n",
    "\n",
    "    control_params, control_static = eqx.partition(control, eqx.is_array)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state, params=control_params)\n",
    "    control_params = optax.apply_updates(control_params, updates)\n",
    "\n",
    "    control = eqx.combine(control_params, control_static)\n",
    "\n",
    "    return control, opt_state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = trange(1024 * 16)\n",
    "for i in pbar:\n",
    "    t1 = jnp.float64(10 * (i + 1) / (1024 * 16))\n",
    "\n",
    "    key, subkey = jax.random.split(key)\n",
    "    control, opt_state, reward = update_step(control, opt_state, subkey, t1)\n",
    "\n",
    "    if i % 16 == 0:\n",
    "        pbar.set_postfix({\"reward\": reward.item(), \"t1\": t1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "sol = eval_traj(control, subkey, jnp.float64(10.0))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(sol.ts, sol.ys[:, :2])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(sol.ts, jax.vmap(control)(sol.ys))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active control parameterizing the derivative of the control signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "control = eqx.nn.MLP(\n",
    "    in_size=5,\n",
    "    out_size=1,\n",
    "    width_size=64,\n",
    "    depth=2,\n",
    "    use_final_bias=False,\n",
    "    # activation=jax.nn.tanh,\n",
    "    # final_activation=jax.nn.tanh,\n",
    "    key=subkey,\n",
    ")\n",
    "\n",
    "optimizer = optax.adam(learning_rate=1e-3)\n",
    "opt_state = optimizer.init(params=eqx.filter(control, eqx.is_array))\n",
    "\n",
    "\n",
    "def reward_fn(ys: Array) -> float:\n",
    "    x_thresh = 2.0\n",
    "    theta_thresh = 0.2\n",
    "\n",
    "    x = ys[..., 0]\n",
    "    theta = ys[..., 1]\n",
    "\n",
    "    # Mark invalid states\n",
    "    # invalid_state = (jnp.abs(x) > x_thresh) | (jnp.abs(theta) > theta_thresh)\n",
    "\n",
    "    # Propagate invalid states to the right\n",
    "    # _, invalid_state = jax.lax.scan(\n",
    "    #    lambda carry, scan: (carry | scan, carry | scan), False, invalid_state\n",
    "    # )\n",
    "\n",
    "    # Aggregate reward over valid states\n",
    "    reward = jnp.square(x) + jnp.square(theta)\n",
    "    # reward = jnp.where(invalid_state, 0.0, reward)\n",
    "    reward = jnp.sum(reward)\n",
    "\n",
    "    return -reward\n",
    "\n",
    "    # return -jnp.mean(jnp.square(ys[..., 1]))\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def eval_traj(control: eqx.Module, key: jax.random.KeyArray, t1: float):\n",
    "    y0 = jax.random.uniform(\n",
    "        key,\n",
    "        shape=(4,),\n",
    "        minval=-0.05,\n",
    "        maxval=0.05,\n",
    "        # minval=jnp.asarray([-0.5, -0.1, -5.0, -1.0]),\n",
    "        # maxval=jnp.asarray([0.5, 0.1, 5.0, 1.0]),\n",
    "    )\n",
    "\n",
    "    sol = diffrax.diffeqsolve(\n",
    "        terms=diffrax.ODETerm(with_derivative_control(cartpole_ode, num_controls=1)),\n",
    "        solver=diffrax.Dopri5(),\n",
    "        t0=0.0,\n",
    "        t1=t1,\n",
    "        dt0=0.01,\n",
    "        y0=jnp.concatenate((jnp.zeros(1), y0)),\n",
    "        args=(control, None),\n",
    "        saveat=diffrax.SaveAt(ts=jnp.linspace(0.0, t1, 1024)),\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-5, atol=1e-5, pcoeff=0.3, icoeff=0.3\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return sol\n",
    "\n",
    "\n",
    "@eqx.filter_value_and_grad\n",
    "def eval_reward(\n",
    "    control: eqx.Module, key: jax.random.KeyArray, batch_size: int, t1: float\n",
    ") -> float:\n",
    "    # keys = jax.random.split(key, batch_size)\n",
    "    # sol = jax.vmap(eval_traj, in_axes=(None, 0), out_axes=0)(control, keys)\n",
    "    sol = eval_traj(control, key, t1)\n",
    "\n",
    "    reward = reward_fn(sol.ys)\n",
    "    return reward\n",
    "\n",
    "\n",
    "#@eqx.filter_jit\n",
    "def update_step(\n",
    "    control: eqx.Module, opt_state: optax.OptState, key: jax.random.KeyArray, t1: float\n",
    "):\n",
    "    reward, grads = eval_reward(control, key, 16, t1)\n",
    "    grads = jax.tree_map(lambda x: -x, grads)\n",
    "\n",
    "    control_params, control_static = eqx.partition(control, eqx.is_array)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state, params=control_params)\n",
    "    control_params = optax.apply_updates(control_params, updates)\n",
    "\n",
    "    control = eqx.combine(control_params, control_static)\n",
    "\n",
    "    return control, opt_state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = trange(1024 * 16)\n",
    "for i in pbar:\n",
    "    t1 = jnp.float64(10 * (i + 1) / (1024 * 16))\n",
    "\n",
    "    key, subkey = jax.random.split(key)\n",
    "    control, opt_state, reward = update_step(control, opt_state, subkey, t1)\n",
    "\n",
    "    if i % 16 == 0:\n",
    "        pbar.set_postfix({\"reward\": reward.item(), \"t1\": t1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "sol = eval_traj(control, subkey, jnp.float64(100.0))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(sol.ts, sol.ys[:, :2])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(sol.ts, jax.vmap(control)(sol.ys))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.axhline()\n",
    "\n",
    "cart_width = 0.5\n",
    "cart_height = 0.25\n",
    "cart = ax.add_patch(\n",
    "    matplotlib.patches.Rectangle(\n",
    "        [sol.ys[0, 0] - cart_width / 2, 0], cart_width, cart_height\n",
    "    )\n",
    ")\n",
    "\n",
    "pole_width = 2.5\n",
    "pole_length = 0.5\n",
    "\n",
    "\n",
    "def get_pole_data(cart_x, pole_angle):\n",
    "    pole_base_x = cart_x\n",
    "    pole_base_y = cart_height\n",
    "    pole_end_x = pole_base_x + math.cos(pole_angle)\n",
    "    pole_end_y = pole_base_y + math.sin(pole_angle)\n",
    "\n",
    "    return [pole_base_x, pole_end_x], [pole_base_y, pole_end_y]\n",
    "\n",
    "\n",
    "pole = ax.add_line(\n",
    "    matplotlib.lines.Line2D(\n",
    "        *get_pole_data(sol.ys[0, 0], sol.ys[0, 1]), linewidth=pole_width\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def init():\n",
    "    ax.set_xlim([-10.0, 10.0])\n",
    "    ax.set_ylim([-0.5, 2.0])\n",
    "\n",
    "    return cart, pole\n",
    "\n",
    "\n",
    "def update(frame):\n",
    "    y = sol.ys[frame]\n",
    "\n",
    "    cart.set(x=y[0])\n",
    "    pole.set_data(*get_pole_data(y[0], y[1]))\n",
    "\n",
    "    return cart, pole\n",
    "\n",
    "animation = matplotlib.animation.FuncAnimation(fig=fig, func=update, frames=range(len(sol.ts)), init_func=init)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-optimal-control-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
