{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ[\"XLA_FLAGS\"] = \"--xla_force_host_platform_device_count=8\"\n",
    "\n",
    "import jax\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import diffrax\n",
    "import equinox as eqx\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from jaxtyping import Array, ArrayLike\n",
    "\n",
    "import optimal_control.constraints as constraints\n",
    "import optimal_control.controls as controls\n",
    "import optimal_control.environments.examples as examples\n",
    "import optimal_control.solvers as solvers\n",
    "import optimal_control.trainers as trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = examples.ApoptosisEnvironment(\n",
    "    \"../data/Initial_concentrations_CD95H_wtH.mat\", [0, 500], 50\n",
    ")\n",
    "state = environment.init()\n",
    "control = controls.LambdaControl(lambda x: jnp.ones((2,)))\n",
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "for i in range(5):\n",
    "    seq = environment.integrate(control, state, key)\n",
    "\n",
    "jit_integrate = eqx.filter_jit(environment.integrate)\n",
    "for i in range(5):\n",
    "    seq = jit_integrate(control, state, key)\n",
    "\n",
    "with jax.profiler.trace(\"/tmp/jax-trace\", create_perfetto_trace=True):\n",
    "    seq = environment.integrate(control, state, key)\n",
    "    jit_integrate(control, state, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "control = controls.ImplicitControl(controls.Siren(1, 1, 32, 2, subkey), 0.0, 180.0)\n",
    "\n",
    "solver = solvers.DirectSolver()\n",
    "environment = examples.ApoptosisEnvironment(\n",
    "    \"../data/Initial_concentrations_CD95H_wtH.mat\", [0, 500], 50\n",
    ")\n",
    "\n",
    "\n",
    "def reward_fn(args: Tuple[Array, Array]):\n",
    "    ys, thresh = args\n",
    "    reward = jnp.mean(\n",
    "        jnp.clip(\n",
    "            ys[..., 12] / (ys[..., 3] + ys[..., 12]),\n",
    "            a_min=None,\n",
    "            a_max=thresh.reshape(-1, 1),\n",
    "        )\n",
    "    )\n",
    "    return reward\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_with_integral(\n",
    "    integral: ArrayLike,\n",
    ") -> Tuple[ArrayLike, controls.AbstractControl]:\n",
    "    constraint = constraints.NonNegativeConstantIntegralConstraint(integral)\n",
    "    return trainers.solve_optimal_control_problem(\n",
    "        environment, reward_fn, [constraint], solver, control, 256, key\n",
    "    )\n",
    "\n",
    "\n",
    "reward, control = train_with_integral(jnp.asarray([10.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint = constraints.NonNegativeConstantIntegralConstraint(jnp.asarray([10.0]))\n",
    "\n",
    "t = jnp.linspace(0.0, 100.0, 1024).reshape(-1, 1)\n",
    "signal = jax.vmap(control)(t)\n",
    "constrained_signal = constraint.transform(signal)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, sharex=True)\n",
    "ax.plot(t, signal)\n",
    "ax.plot(t, constrained_signal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = environment.init()\n",
    "\n",
    "# Evaluate control\n",
    "full_control = jax.vmap(control)(\n",
    "    jnp.linspace(control.t_start, control.t_end, 1024).reshape(1024, 1)\n",
    ")\n",
    "\n",
    "# Transform control\n",
    "full_control = constraint.transform(full_control)\n",
    "\n",
    "# Package control\n",
    "cached_control = controls.InterpolationControl(\n",
    "    full_control.shape[1],\n",
    "    full_control.shape[0],\n",
    "    control.t_start,\n",
    "    control.t_end,\n",
    "    method=\"step\",\n",
    "    control=full_control,\n",
    ")\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "# @eqx.filter_grad\n",
    "def integrate(params, static) -> Tuple[Array, Array]:\n",
    "    cached_control = eqx.combine(params, static)\n",
    "    ys, thresh = environment.integrate(cached_control, state, key)\n",
    "\n",
    "    return jnp.mean(ys)\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "# @eqx.filter_grad\n",
    "def _integrate(params, static, y0: Array) -> Array:\n",
    "    cached_control = eqx.combine(params, static)\n",
    "    terms = diffrax.ODETerm(examples.apoptosis_ode)\n",
    "    solver = diffrax.Dopri5()\n",
    "\n",
    "    sol = diffrax.diffeqsolve(\n",
    "        terms=terms,\n",
    "        solver=solver,\n",
    "        t0=0.0,\n",
    "        t1=180.0,  # Minutes\n",
    "        dt0=1.0,\n",
    "        y0=y0,\n",
    "        args=cached_control,\n",
    "        saveat=diffrax.SaveAt(ts=jnp.linspace(0.0, 180.0, 181)),\n",
    "        max_steps=181,\n",
    "        adjoint=diffrax.RecursiveCheckpointAdjoint(checkpoints=181),\n",
    "    )\n",
    "\n",
    "    return jnp.mean(sol.ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, _ = environment._sample_x0(state, key)\n",
    "params, static = eqx.partition(cached_control, eqx.is_array)\n",
    "\n",
    "integrate(params, static)\n",
    "_integrate(params, static, x0[0])\n",
    "\n",
    "%timeit integrate(params, static)\n",
    "%timeit _integrate(params, static, x0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.x0[..., -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = ys[..., 12] / (ys[..., 3] + ys[..., 12])\n",
    "# thresh = state.x0[..., -1] * 1.4897\n",
    "\n",
    "plt.figure()\n",
    "for t in thresh:\n",
    "    plt.axhline(t, c=\"black\")\n",
    "plt.plot(frac.T)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(control.control)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptively sampling over integrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import time\n",
    "from functools import partial\n",
    "from typing import Callable, Tuple\n",
    "\n",
    "import diffrax\n",
    "import equinox as eqx\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from adaptive import Learner1D, notebook_extension\n",
    "from IPython.display import clear_output\n",
    "from jaxtyping import Array, ArrayLike\n",
    "from tqdm.auto import tqdm as tq\n",
    "from tqdm.auto import trange\n",
    "\n",
    "import optimal_control.constraints as constraints\n",
    "import optimal_control.controls as controls\n",
    "import optimal_control.environments as environments\n",
    "import optimal_control.environments.examples as examples\n",
    "import optimal_control.solvers as solvers\n",
    "import optimal_control.trainers as trainers\n",
    "\n",
    "notebook_extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "control = controls.ImplicitControl(controls.Siren(1, 1, 32, 2, subkey), 0.0, 180.0)\n",
    "solver = solvers.DirectSolver()\n",
    "\n",
    "mat_path = \"../data/Initial_concentrations_CD95H_wtH.mat\"\n",
    "train_environment = examples.ApoptosisEnvironment(mat_path, [0, 500], 50)\n",
    "val_environment = examples.ApoptosisEnvironment(mat_path, [500, 1000], 500, True)\n",
    "val_env_state = val_environment.init()\n",
    "\n",
    "\n",
    "def reward_fn(args: Tuple[Array, Array]):\n",
    "    ys, thresh = args\n",
    "    reward = jnp.mean(\n",
    "        jnp.clip(\n",
    "            ys[..., 12] / (ys[..., 3] + ys[..., 12]),\n",
    "            a_min=None,\n",
    "            a_max=thresh.reshape(-1, 1),\n",
    "        )\n",
    "    )\n",
    "    return reward\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def train_with_integral(\n",
    "    integral: ArrayLike, environment: examples.ApoptosisEnvironment\n",
    ") -> Tuple[ArrayLike, controls.AbstractControl]:\n",
    "    constraint = constraints.NonNegativeConstantIntegralConstraint(integral)\n",
    "    return trainers.solve_optimal_control_problem(\n",
    "        environment, reward_fn, [constraint], solver, control, 256, key\n",
    "    )\n",
    "\n",
    "\n",
    "def build_control(\n",
    "    integral: ArrayLike,\n",
    "    control: controls.AbstractControl,\n",
    ") -> controls.AbstractControl:\n",
    "    constraint = constraints.NonNegativeConstantIntegralConstraint(integral)\n",
    "\n",
    "    # Evaluate control\n",
    "    num_points = 10\n",
    "    points = jnp.linspace(\n",
    "        control.t_start, control.t_end, num=num_points, endpoint=False\n",
    "    )\n",
    "    spacing = (control.t_end - control.t_start) / num_points\n",
    "    points += spacing / 2\n",
    "\n",
    "    # Transform control\n",
    "    full_control = jax.vmap(control)(points.reshape(num_points, 1))\n",
    "    full_control = constraint.transform(full_control)\n",
    "\n",
    "    # Package control\n",
    "    control = controls.InterpolationControl(\n",
    "        full_control.shape[1],\n",
    "        full_control.shape[0],\n",
    "        control.t_start,\n",
    "        control.t_end,\n",
    "        method=\"step\",\n",
    "        control=full_control,\n",
    "    )\n",
    "\n",
    "    return control, points\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def evaluate(\n",
    "    integral: ArrayLike,\n",
    "    control: controls.AbstractControl,\n",
    "    environment: examples.ApoptosisEnvironment,\n",
    ") -> ArrayLike:\n",
    "    control, _ = build_control(integral, control)\n",
    "\n",
    "    environment_state = environment.init()\n",
    "    env_seq = environment.integrate(control, environment_state, key)\n",
    "    reward = reward_fn(env_seq)\n",
    "\n",
    "    return reward\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def integrate(\n",
    "    control: controls.AbstractControl,\n",
    "    environment: examples.ApoptosisEnvironment,\n",
    "    environment_state: examples.ApoptosisState,\n",
    ") -> ArrayLike:\n",
    "    env_seq = environment.integrate(control, environment_state, key)\n",
    "\n",
    "    return env_seq\n",
    "\n",
    "\n",
    "# reward, control = train_with_integral(jnp.asarray([10.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner1D(lambda x: 0, bounds=(-5, 5))\n",
    "\n",
    "plot_timer = time.time()\n",
    "plot_interval = 15\n",
    "results = []\n",
    "while True:\n",
    "    x, _ = learner.ask(1)\n",
    "    x = x[0]\n",
    "\n",
    "    integral = jnp.asarray([x], dtype=jnp.float64)\n",
    "    integral = 10**integral\n",
    "\n",
    "    optimized_reward, optimized_control = train_with_integral(\n",
    "        integral, train_environment\n",
    "    )\n",
    "    val_reward = evaluate(integral, optimized_control, val_environment)\n",
    "\n",
    "    learner.tell(x, float(val_reward))\n",
    "    results.append(\n",
    "        {\n",
    "            \"x\": x,\n",
    "            \"integral\": integral,\n",
    "            \"optimized_reward\": optimized_reward,\n",
    "            \"optimized_control\": optimized_control,\n",
    "            \"val_reward\": val_reward,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if time.time() - plot_timer >= plot_interval:\n",
    "        plot_timer = time.time()\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(learner.plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle_results = {\"learner\": learner, \"results\": results}\n",
    "with open(\"../results/apoptosis/piecewise_constant_optim.pickle\", mode=\"wb\") as f:\n",
    "    pickle.dump(pickle_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\n",
    "    \"../results/apoptosis/piecewise_implicit/piecewise_constant_optim.pickle\", mode=\"rb\"\n",
    ") as f:\n",
    "    pickle_results = pickle.load(f)\n",
    "\n",
    "learner, results = pickle_results[\"learner\"], pickle_results[\"results\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive with constant integrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "def evaluate(\n",
    "    control: controls.AbstractControl,\n",
    "    environment: examples.ApoptosisEnvironment,\n",
    "    environment_state: examples.ApoptosisState,\n",
    ") -> ArrayLike:\n",
    "    env_seq = environment.integrate(control, environment_state, key)\n",
    "    reward = reward_fn(env_seq)\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_learner = Learner1D(lambda x: 0, bounds=(-5, 5))\n",
    "\n",
    "\n",
    "def copy_data(t, c):\n",
    "    return c\n",
    "\n",
    "\n",
    "plot_timer = time.time()\n",
    "plot_interval = 15\n",
    "constant_results = []\n",
    "while True:\n",
    "    x, _ = constant_learner.ask(1)\n",
    "    x = x[0]\n",
    "\n",
    "    integral = jnp.asarray([x], dtype=jnp.float64)\n",
    "    integral = 10**integral\n",
    "\n",
    "    constant_control = controls.LambdaControl(copy_data, data=integral)\n",
    "    val_reward = evaluate(constant_control, val_environment, val_env_state)\n",
    "\n",
    "    constant_learner.tell(x, float(val_reward))\n",
    "    constant_results.append(\n",
    "        {\n",
    "            \"x\": x,\n",
    "            \"integral\": integral,\n",
    "            \"val_reward\": val_reward,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if time.time() - plot_timer >= plot_interval:\n",
    "        plot_timer = time.time()\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(constant_learner.plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle_results = {\"learner\": constant_learner, \"results\": constant_results}\n",
    "with open(\"../results/apoptosis/piecewise_constant_fixed.pickle\", mode=\"wb\") as f:\n",
    "    pickle.dump(pickle_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\n",
    "    \"../results/apoptosis/piecewise_implicit/piecewise_constant_fixed.pickle\", mode=\"rb\"\n",
    ") as f:\n",
    "    pickle_results = pickle.load(f)\n",
    "\n",
    "constant_learner, constant_results = (\n",
    "    pickle_results[\"learner\"],\n",
    "    pickle_results[\"results\"],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaction_volume = 0.8  # ml\n",
    "concentration_to_moles = 16.6 / 500  # 16.6nM = 500ng/ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward vs. Integral of optimized and constant controls\n",
    "\n",
    "opt_xy = np.asarray([(r[\"x\"], r[\"val_reward\"]) for r in results])\n",
    "opt_xy = opt_xy[np.argsort(opt_xy[:, 0])]\n",
    "\n",
    "const_xy = np.asarray([(r[\"x\"], r[\"val_reward\"]) for r in constant_results])\n",
    "const_xy = const_xy[np.argsort(const_xy[:, 0])]\n",
    "\n",
    "with plt.style.context(\"seaborn-paper\"):\n",
    "    plt.figure()\n",
    "    # plt.xlabel(r\"$\\log_{10} \\int_{t_0}^{t_1} c(t)dt$\")\n",
    "    plt.xlabel(\"Mean CD95L [ng/ml]\")\n",
    "    plt.ylabel(\"Validation Reward\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.plot(\n",
    "        10 ** opt_xy[:, 0] * reaction_volume / concentration_to_moles,\n",
    "        opt_xy[:, 1],\n",
    "        label=\"Optimized Control\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        10 ** const_xy[:, 0] * reaction_volume / concentration_to_moles,\n",
    "        const_xy[:, 1],\n",
    "        label=\"Constant Control\",\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.savefig(\n",
    "        \"../results/apoptosis/piecewise_implicit/reward_vs_integral_comparison.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.savefig(\n",
    "        \"../results/apoptosis/piecewise_implicit/reward_vs_integral_comparison.svg\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual optimized controls at relevant points on the reward curve\n",
    "\n",
    "with plt.style.context(\"seaborn-paper\"):\n",
    "    plt.figure()\n",
    "    plt.yscale(\"log\")\n",
    "    for r in results:\n",
    "        control, _ = build_control(1.0, r[\"optimized_control\"])\n",
    "        time = np.linspace(control.t_start, control.t_end, num=10, endpoint=False)\n",
    "        plt.step(time, control.control, c=\"black\", where=\"mid\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All controls on a 2D plot\n",
    "\n",
    "from matplotlib.colors import LogNorm, SymLogNorm\n",
    "\n",
    "with plt.style.context(\"seaborn-paper\"):\n",
    "    time = np.linspace(control.t_start, control.t_end, num=10, endpoint=False)\n",
    "\n",
    "    opt_integrals = np.asarray([r[\"x\"] for r in results])\n",
    "    opt_argsort = np.argsort(opt_integrals)\n",
    "\n",
    "    opt_integrals = opt_integrals[opt_argsort]\n",
    "    opt_norm_controls = np.asarray(\n",
    "        [build_control(1.0, r[\"optimized_control\"])[0].control for r in results]\n",
    "    )\n",
    "    opt_norm_controls = opt_norm_controls[opt_argsort, :, 0]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Time [min]\")\n",
    "    # plt.ylabel(r\"$\\log_{10} \\int_{t_0}^{t_1} c(t)dt$\")\n",
    "    plt.ylabel(\"Mean CD95L [ng/ml]\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.pcolormesh(\n",
    "        time,\n",
    "        10**opt_integrals * reaction_volume / concentration_to_moles,\n",
    "        opt_norm_controls,\n",
    "        cmap=\"inferno\",\n",
    "        norm=LogNorm(),\n",
    "    )\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label(\"Normalized Instantaneous CD95L\")\n",
    "    plt.savefig(\n",
    "        \"../results/apoptosis/piecewise_implicit/integral_vs_optimalcontrol.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.savefig(\n",
    "        \"../results/apoptosis/piecewise_implicit/integral_vs_optimalcontrol.svg\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"seaborn-paper\"):\n",
    "    fig, ax = plt.subplots(1, 2, sharey=True)\n",
    "    ax[0].set_xlabel(\"Validation Reward\")\n",
    "    # ax[0].set_ylabel(r\"$\\log_{10} \\int_{t_0}^{t_1} c(t)dt$\")\n",
    "    ax[0].set_ylabel(\"Mean CD95L [ng/ml]\")\n",
    "    ax[0].set_yscale(\"log\")\n",
    "    ax[0].plot(\n",
    "        opt_xy[:, 1], 10 ** opt_xy[:, 0] * reaction_volume / concentration_to_moles\n",
    "    )\n",
    "\n",
    "    ax[1].set_xlabel(\"Time [min]\")\n",
    "    im = ax[1].pcolormesh(\n",
    "        time,\n",
    "        10**opt_integrals * reaction_volume / concentration_to_moles,\n",
    "        opt_norm_controls,\n",
    "        cmap=\"inferno\",\n",
    "        norm=LogNorm(),\n",
    "    )\n",
    "    cbar = plt.colorbar(im, ax=ax[1])\n",
    "    cbar.set_label(\"Normalized Instantaneous CD95L\")\n",
    "    plt.savefig(\n",
    "        \"../results/apoptosis/piecewise_implicit/integral_vs_optimalcontrol_merge.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.savefig(\n",
    "        \"../results/apoptosis/piecewise_implicit/integral_vs_optimalcontrol_merge.svg\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CD95 response curve\n",
    "\n",
    "\n",
    "def CD95act(CD95L, x):\n",
    "    k = [None] * 11\n",
    "\n",
    "    k[0] = 8.12e-4  # kon,FADD\n",
    "    k[1] = 0.00567  # koff,FADD\n",
    "    k[2] = 0.000492  # kon,p55\n",
    "    k[3] = 0.0114  # kcl,D216\n",
    "    k[4] = 4.47e-4  # kcl,D374,trans,p55\n",
    "    k[5] = 0.00344  # kcl,D374,trans,p43\n",
    "    k[6] = 0.0950  # kp18,inactive\n",
    "    k[7] = 0.000529  # kcl,BID\n",
    "    k[8] = 0.00152  # kcl,probe\n",
    "    k[9] = 8.98  # KD,R\n",
    "    k[10] = 15.4  # KD,L\n",
    "\n",
    "    # Active CD95 receptors, steady state solution (in response to CD95L / control)\n",
    "    CD95act = (\n",
    "        x[0] ** 3\n",
    "        * k[10] ** 2\n",
    "        * CD95L\n",
    "        / (\n",
    "            (CD95L + k[10])\n",
    "            * (\n",
    "                x[0] ** 2 * k[10] ** 2\n",
    "                + k[9] * CD95L**2\n",
    "                + 2 * k[9] * k[10] * CD95L\n",
    "                + k[9] * k[10] ** 2\n",
    "            )\n",
    "        )\n",
    "    )  # CD95act\n",
    "\n",
    "    return CD95act\n",
    "\n",
    "\n",
    "reaction_volume = 0.8  # ml\n",
    "concentration_to_moles = 16.6 / 500  # 16.6nM = 500ng/ml\n",
    "\n",
    "ligand_moles = 10 ** np.linspace(-1, 4, 1024)\n",
    "ligand_concentration = ligand_moles * reaction_volume / concentration_to_moles\n",
    "\n",
    "act = 0\n",
    "for r in val_env_state.x0[:, 0]:\n",
    "    receptor = r\n",
    "    act = act + CD95act(ligand_moles, [receptor]) / receptor\n",
    "\n",
    "act = act / val_env_state.x0.shape[0]\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Ligand [ng/ml]\")\n",
    "plt.ylabel(\"Average Normalized Activation\")\n",
    "plt.xscale(\"log\")\n",
    "plt.plot(ligand_concentration, act)\n",
    "plt.savefig(\"../results/apoptosis/receptor_activation.png\", bbox_inches=\"tight\")\n",
    "plt.savefig(\"../results/apoptosis/receptor_activation.svg\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual controls and system states\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "def build_control(\n",
    "    integral: ArrayLike,\n",
    "    control: controls.AbstractControl,\n",
    ") -> controls.AbstractControl:\n",
    "    constraint = constraints.NonNegativeConstantIntegralConstraint(integral)\n",
    "\n",
    "    # Evaluate control\n",
    "    num_points = 10\n",
    "    points = jnp.linspace(\n",
    "        control.t_start, control.t_end, num=num_points, endpoint=False\n",
    "    )\n",
    "    spacing = (control.t_end - control.t_start) / num_points\n",
    "    points += spacing / 2\n",
    "\n",
    "    # Transform control\n",
    "    sampled_control = jax.vmap(control)(points.reshape(num_points, 1))\n",
    "    transformed_control = constraint.transform(sampled_control)\n",
    "\n",
    "    # Package control\n",
    "    control = controls.InterpolationControl(\n",
    "        transformed_control.shape[1],\n",
    "        transformed_control.shape[0],\n",
    "        control.t_start,\n",
    "        control.t_end,\n",
    "        method=\"step\",\n",
    "        control=transformed_control,\n",
    "    )\n",
    "\n",
    "    return control, points, sampled_control, transformed_control\n",
    "\n",
    "\n",
    "def copy_data(t, c):\n",
    "    return c\n",
    "\n",
    "\n",
    "def argfind_closest(values, target):\n",
    "    return np.argmin(np.abs(values - target))\n",
    "\n",
    "\n",
    "def tbid_fraction(ys):\n",
    "    return ys[..., 12] / (ys[..., 3] + ys[..., 12])\n",
    "\n",
    "\n",
    "def above_threshold(ys, thresh):\n",
    "    return tbid_fraction(ys) > thresh\n",
    "\n",
    "\n",
    "with plt.style.context(\"seaborn-paper\"):\n",
    "    system_time = np.linspace(control.t_start, control.t_end, num=181, endpoint=True)\n",
    "    control_time = np.linspace(control.t_start, control.t_end, num=10, endpoint=False)\n",
    "\n",
    "    target_concs = [1e-1, 1e-0, 1e1, 1e2, 1e3, 2e3, 3e3, 1e4, 1e5]\n",
    "    opt_integrals = np.asarray([r[\"x\"] for r in results])\n",
    "\n",
    "    for target_conc in target_concs:\n",
    "        target_int = np.log10(target_conc / reaction_volume * concentration_to_moles)\n",
    "        target_idx = argfind_closest(opt_integrals, target_int)\n",
    "\n",
    "        (\n",
    "            opt_control,\n",
    "            opt_points,\n",
    "            opt_sampled_control,\n",
    "            opt_transformed_control,\n",
    "        ) = build_control(\n",
    "            10 ** opt_integrals[target_idx], results[target_idx][\"optimized_control\"]\n",
    "        )\n",
    "\n",
    "        system_traj, thresh = integrate(opt_control, val_environment, val_env_state)\n",
    "\n",
    "        relative_fractions = tbid_fraction(system_traj)\n",
    "        frac_mean = np.mean(relative_fractions, axis=0)\n",
    "        frac_std = np.std(relative_fractions, axis=0)\n",
    "\n",
    "        cells_above_thresh = np.sum(\n",
    "            above_threshold(system_traj, thresh.reshape(-1, 1)), axis=0\n",
    "        )\n",
    "\n",
    "        fig, ax = plt.subplots(3, 1, sharex=True)\n",
    "\n",
    "        # tBID\n",
    "        ax[0].set_ylabel(\"Rel. tBID\")\n",
    "        ax[0].fill_between(\n",
    "            system_time,\n",
    "            frac_mean - frac_std,\n",
    "            frac_mean + frac_std,\n",
    "            color=\"tab:blue\",\n",
    "            alpha=0.25,\n",
    "        )\n",
    "        ax[0].plot(system_time, np.mean(relative_fractions, axis=0), c=\"tab:blue\")\n",
    "\n",
    "        # Number of Cells\n",
    "        ax[1].set_ylabel(\"Num. Cells\")\n",
    "        ax[1].set_ylim([-10, 510])\n",
    "        ax[1].plot(system_time, cells_above_thresh, c=\"tab:blue\")\n",
    "\n",
    "        # Control\n",
    "        ax[2].set_xlabel(\"Time [min]\")\n",
    "        ax[2].set_ylabel(\"Inst. CD95L [ng/ml]\")\n",
    "        ax[2].plot(\n",
    "            system_time[:-1],\n",
    "            opt_control(system_time[:-1]) / reaction_volume * concentration_to_moles,\n",
    "        )\n",
    "\n",
    "        ax[2].text(\n",
    "            0.95,\n",
    "            0.95,\n",
    "            f\"Mean CD95L = {10 ** opt_integrals[target_idx] / reaction_volume * concentration_to_moles:.1f} ng/ml\",\n",
    "            horizontalalignment=\"right\",\n",
    "            verticalalignment=\"top\",\n",
    "            transform=ax[2].transAxes,\n",
    "        )\n",
    "\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-optimal-control-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
