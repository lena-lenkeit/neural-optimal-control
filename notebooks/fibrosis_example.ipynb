{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from functools import partial\n",
    "from typing import Callable, Tuple\n",
    "\n",
    "import diffrax\n",
    "import equinox as eqx\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from jaxtyping import Array, ArrayLike\n",
    "from tqdm.auto import tqdm as tq\n",
    "from tqdm.auto import trange\n",
    "\n",
    "import optimal_control.constraints as constraints\n",
    "import optimal_control.controls as controls\n",
    "import optimal_control.environments as environments\n",
    "import optimal_control.environments.examples as examples\n",
    "import optimal_control.solvers as solvers\n",
    "import optimal_control.trainers as trainers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward integration benchmark\n",
    "\n",
    "environment = examples.FibrosisEnvironment()\n",
    "state = environment.init()\n",
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "@jax.vmap\n",
    "def integrate_benchmark(control_value: Array) -> Array:\n",
    "    control = controls.LambdaControl(lambda t, args: args, control_value)\n",
    "    seq = environment._integrate(\n",
    "        t0=0.0,\n",
    "        t1=300.0,\n",
    "        y0=jnp.asarray([1e6, 1e6, 0.0, 0.0]),\n",
    "        control=control,\n",
    "        inflammation_pulse=False,\n",
    "        saveat=diffrax.SaveAt(ts=jnp.linspace(0.0, 300.0, 301)),\n",
    "        early_stopping=False,\n",
    "    )\n",
    "\n",
    "    return seq\n",
    "\n",
    "\n",
    "integrate_benchmark(jnp.zeros((4, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrate_benchmark(jnp.zeros((2**16, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_fn(x: Array):\n",
    "    x = jnp.where(jnp.isposinf(x), 0.0, x)\n",
    "    x = jnp.clip(x[..., :2], a_min=1e2, a_max=None)\n",
    "    x = -jnp.mean(jnp.log(x))\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "concentrations = [10 ** jnp.linspace(-2, 1, 10), 10 ** jnp.linspace(-2, 1, 10)]\n",
    "integrals = jnp.stack(jnp.meshgrid(*concentrations), axis=-1).reshape(-1, 2) * 101\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = examples.FibrosisEnvironment()\n",
    "solver = solvers.DirectSolver()\n",
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "# reward_fn = lambda x: -jnp.mean(jnp.log(jnp.clip(x[..., :2], a_min=1e2, a_max=None)))\n",
    "\n",
    "control = controls.InterpolationControl(2, 101, 0.0, 100.0, method=\"linear\")\n",
    "\n",
    "\n",
    "def train_with_integral(\n",
    "    integral: ArrayLike,\n",
    "    environment: environments.AbstractEnvironment,\n",
    "    solver: solvers.AbstractSolver,\n",
    "    reward_fn: Callable[[ArrayLike], Array],\n",
    "    control: controls.AbstractControl,\n",
    "    key: jax.random.KeyArray,\n",
    ") -> Tuple[ArrayLike, Array]:\n",
    "    _constraints = [constraints.NonNegativeConstantIntegralConstraint(integral)]\n",
    "\n",
    "    reward, control = trainers.solve_optimal_control_problem(\n",
    "        environment, reward_fn, _constraints, solver, control, 1024, key\n",
    "    )\n",
    "\n",
    "    return reward, control.control\n",
    "\n",
    "\n",
    "batched_train_with_integral = jax.jit(\n",
    "    jax.vmap(\n",
    "        partial(\n",
    "            train_with_integral,\n",
    "            environment=environment,\n",
    "            solver=solver,\n",
    "            reward_fn=reward_fn,\n",
    "            control=control,\n",
    "            key=key,\n",
    "        ),\n",
    "        in_axes=(0,),\n",
    "        out_axes=(0, 0),\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards, _controls = batched_train_with_integral(integrals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.savez(\"../data/fibrosis.npz\", reward_array=rewards, control_array=_controls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = jnp.load(\"../data/fibrosis.npz\")\n",
    "rewards = jnp.asarray(data_dict[\"reward_array\"])\n",
    "_controls = jnp.asarray(data_dict[\"control_array\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectory(\n",
    "    environment: environments.AbstractEnvironment,\n",
    "    state: environments.EnvironmentState,\n",
    "    control: controls.AbstractControl,\n",
    "    key: jax.random.KeyArray,\n",
    ") -> Array:\n",
    "    trajectory = environment.integrate(control, state, key)\n",
    "    return trajectory\n",
    "\n",
    "\n",
    "def is_treatment_successfull(final_state: Array) -> ArrayLike:\n",
    "    return jnp.where(jnp.sum(jnp.abs(final_state[..., :2]), axis=-1) < 1e-1, 1.0, 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trajectories of optimized controls\n",
    "\n",
    "environment = examples.FibrosisEnvironment()\n",
    "state = environment.init()\n",
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "\n",
    "optimal_trajectories = []\n",
    "optimal_rewards = []\n",
    "for i in trange(_controls.shape[0]):\n",
    "    control = controls.InterpolationControl(2, 101, 0.0, 100.0, control=_controls[i])\n",
    "\n",
    "    trajectory = get_trajectory(environment, state, control, key)\n",
    "    reward = reward_fn(trajectory)\n",
    "\n",
    "    optimal_trajectories.append(trajectory)\n",
    "    optimal_rewards.append(reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trajectories of constant controls\n",
    "\n",
    "environment = examples.FibrosisEnvironment()\n",
    "state = environment.init()\n",
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "\n",
    "constant_trajectories = []\n",
    "constant_rewards = []\n",
    "for i in trange(_controls.shape[0]):\n",
    "    constraint = constraints.NonNegativeConstantIntegralConstraint(integrals[i])\n",
    "    control_signal = constraint.project(jnp.ones((101, 2)))\n",
    "    control = controls.InterpolationControl(2, 101, 0.0, 100.0, control=control_signal)\n",
    "\n",
    "    trajectory = get_trajectory(environment, state, control, key)\n",
    "    reward = reward_fn(trajectory)\n",
    "\n",
    "    constant_trajectories.append(trajectory)\n",
    "    constant_rewards.append(reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperatrix trajectories\n",
    "\n",
    "control = controls.LambdaControl(lambda _: jnp.zeros((2,)))\n",
    "environment = examples.FibrosisEnvironment()\n",
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "y0s = 10 ** jnp.linspace(0, 7, 100)\n",
    "\n",
    "lambda1 = 0.9\n",
    "lambda2 = 0.8\n",
    "mu1 = 0.3\n",
    "mu2 = 0.3\n",
    "K = 1e6\n",
    "gamma = 2\n",
    "beta3 = 240 * 1440\n",
    "beta1 = 470 * 1440\n",
    "beta2 = 70 * 1440\n",
    "alpha1 = 940 * 1440\n",
    "alpha2 = 510 * 1440\n",
    "k1 = 6 * 1e8\n",
    "k2 = 6 * 1e8\n",
    "\n",
    "seperatrix_trajectories = []\n",
    "for i in trange(100):\n",
    "    for j in range(100):\n",
    "        M = y0s[i]\n",
    "        F = y0s[j]\n",
    "\n",
    "        C = -0.5 * (alpha1 / gamma * M + k2 - beta1 / gamma * F) + jnp.sqrt(\n",
    "            0.25 * (alpha1 / gamma * M + k2 - beta1 / gamma * F) ** 2\n",
    "            + beta1 * k2 / gamma * F\n",
    "        )\n",
    "        P = 0.5 * (beta2 / gamma * M + (beta3 - alpha2) / gamma * F - k1) + jnp.sqrt(\n",
    "            0.25 * (k1 - beta2 / gamma * M - (beta3 - alpha2) / gamma * F) ** 2\n",
    "            + (beta2 * M + beta3 * F) * k1 / gamma\n",
    "        )\n",
    "\n",
    "        y0 = jnp.stack((F, M, C, P), axis=-1)\n",
    "\n",
    "        trajectory = environment._integrate(\n",
    "            0.0, 300.0, y0, control, False, diffrax.SaveAt(t1=True)\n",
    "        ).ys[-1]\n",
    "\n",
    "        seperatrix_trajectories.append(trajectory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just load it\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "seperatrix_array = scipy.io.loadmat(\"../data/Separatrix_array_F06_M07.mat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_reward_grid(plt_rewards, x=10, y=10):\n",
    "    with plt.style.context(\"seaborn-paper\"):\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.xlabel(\"aPDGF int.\")\n",
    "        plt.ylabel(\"aCSF1 int.\")\n",
    "        plt.imshow(\n",
    "            plt_rewards.reshape(x, y),\n",
    "            extent=(0.1, 2.0, 0.1, 2.0),\n",
    "            origin=\"lower\",\n",
    "            aspect=\"equal\",\n",
    "            cmap=\"inferno\",\n",
    "        )\n",
    "        plt.colorbar(fraction=0.0457, pad=0.04, label=\"Reward\")\n",
    "        # plt.savefig(\"../figures/fibrosis_opt_reward.png\", bbox_inches=\"tight\")\n",
    "        # plt.savefig(\"../figures/fibrosis_opt_reward.svg\", bbox_inches=\"tight\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot optimal reward grid\n",
    "\n",
    "plt_reward_grid(jnp.stack(optimal_rewards, axis=0))\n",
    "plt_reward_grid(\n",
    "    is_treatment_successfull(jnp.stack(optimal_trajectories, axis=0)[:, -1])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot constant reward grid\n",
    "\n",
    "plt_reward_grid(jnp.stack(constant_rewards, axis=0))\n",
    "plt_reward_grid(\n",
    "    is_treatment_successfull(jnp.stack(constant_trajectories, axis=0)[:, -1])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot difference reward grid\n",
    "\n",
    "plt_reward_grid(\n",
    "    jnp.stack(optimal_rewards, axis=0) - jnp.stack(constant_rewards, axis=0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot seperatrix\n",
    "\n",
    "with plt.style.context(\"seaborn-paper\"):\n",
    "    x = np.logspace(\n",
    "        seperatrix_array[\"lims_F\"][0, 0],\n",
    "        seperatrix_array[\"lims_F\"][0, 1],\n",
    "        seperatrix_array[\"tsteps\"][0, 0],\n",
    "    )\n",
    "    y = np.logspace(\n",
    "        seperatrix_array[\"lims_M\"][0, 0],\n",
    "        seperatrix_array[\"lims_M\"][0, 1],\n",
    "        seperatrix_array[\"tsteps\"][0, 0],\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.xlabel(\"F\")\n",
    "    plt.ylabel(\"M\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.pcolor(x, y, 1 - seperatrix_array[\"S\"], cmap=\"Greys\", vmin=0.0, vmax=3.0)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seperatrix_trajectories[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_treatment_successfull(jnp.stack(seperatrix_trajectories, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dosage curve grid\n",
    "\n",
    "with plt.style.context(\"seaborn-paper\"):\n",
    "    fig, ax = plt.subplots(10, 10, figsize=(10, 10), sharex=True, sharey=True)\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            ax[i, j].set_yscale(\"log\")\n",
    "            ax[i, j].plot(np.clip(_controls[(9 - i) * 10 + j], a_min=1e-2, a_max=None))\n",
    "    # ax_outer = plt.axes([0.1,0.1,2.0,2.0], facecolor=(1,1,1,0))\n",
    "\n",
    "    # plt.savefig(\"../figures/fibrosis_opt_traj.png\", bbox_inches=\"tight\")\n",
    "    # plt.savefig(\"../figures/fibrosis_opt_traj.svg\", bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot MF trajectories\n",
    "\n",
    "with plt.style.context(\"seaborn-paper\"):\n",
    "    x = np.logspace(\n",
    "        seperatrix_array[\"lims_F\"][0, 0],\n",
    "        seperatrix_array[\"lims_F\"][0, 1],\n",
    "        seperatrix_array[\"tsteps\"][0, 0],\n",
    "    )\n",
    "    y = np.logspace(\n",
    "        seperatrix_array[\"lims_M\"][0, 0],\n",
    "        seperatrix_array[\"lims_M\"][0, 1],\n",
    "        seperatrix_array[\"tsteps\"][0, 0],\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(10, 10, figsize=(10, 10), sharex=True, sharey=True)\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            ax[i, j].set_xscale(\"log\")\n",
    "            ax[i, j].set_yscale(\"log\")\n",
    "            # ax[i, j].set_xlabel(\"F\")\n",
    "            # ax[i, j].set_ylabel(\"M\")\n",
    "            ax[i, j].pcolor(\n",
    "                x, y, 1 - seperatrix_array[\"S\"], cmap=\"Greys\", vmin=0.0, vmax=3.0\n",
    "            )\n",
    "            ax[i, j].plot(\n",
    "                optimal_trajectories[(9 - i) * 10 + j][..., 0],\n",
    "                optimal_trajectories[(9 - i) * 10 + j][..., 1],\n",
    "            )\n",
    "\n",
    "    # ax_outer = plt.axes([0.1,0.1,2.0,2.0], facecolor=(1,1,1,0))\n",
    "\n",
    "    # plt.savefig(\"../figures/fibrosis_opt_traj.png\", bbox_inches=\"tight\")\n",
    "    # plt.savefig(\"../figures/fibrosis_opt_traj.svg\", bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot MF trajectories\n",
    "\n",
    "with plt.style.context(\"seaborn-paper\"):\n",
    "    x = np.logspace(\n",
    "        seperatrix_array[\"lims_F\"][0, 0],\n",
    "        seperatrix_array[\"lims_F\"][0, 1],\n",
    "        seperatrix_array[\"tsteps\"][0, 0],\n",
    "    )\n",
    "    y = np.logspace(\n",
    "        seperatrix_array[\"lims_M\"][0, 0],\n",
    "        seperatrix_array[\"lims_M\"][0, 1],\n",
    "        seperatrix_array[\"tsteps\"][0, 0],\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(10, 10, figsize=(10, 10), sharex=True, sharey=True)\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            ax[i, j].set_xscale(\"log\")\n",
    "            ax[i, j].set_yscale(\"log\")\n",
    "            # ax[i, j].set_xlabel(\"F\")\n",
    "            # ax[i, j].set_ylabel(\"M\")\n",
    "            ax[i, j].pcolor(\n",
    "                x, y, 1 - seperatrix_array[\"S\"], cmap=\"Greys\", vmin=0.0, vmax=3.0\n",
    "            )\n",
    "            ax[i, j].plot(\n",
    "                constant_trajectories[(9 - i) * 10 + j][..., 0],\n",
    "                constant_trajectories[(9 - i) * 10 + j][..., 1],\n",
    "            )\n",
    "\n",
    "    # ax_outer = plt.axes([0.1,0.1,2.0,2.0], facecolor=(1,1,1,0))\n",
    "\n",
    "    # plt.savefig(\"../figures/fibrosis_opt_traj.png\", bbox_inches=\"tight\")\n",
    "    # plt.savefig(\"../figures/fibrosis_opt_traj.svg\", bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal control with adaptively sampled total drug dosages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import time\n",
    "from functools import partial\n",
    "from typing import Callable, Tuple\n",
    "\n",
    "import diffrax\n",
    "import equinox as eqx\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from adaptive import DataSaver, Learner2D, notebook_extension\n",
    "from IPython.display import clear_output\n",
    "from jaxtyping import Array, ArrayLike\n",
    "from tqdm.auto import tqdm as tq\n",
    "from tqdm.auto import trange\n",
    "\n",
    "import optimal_control.constraints as constraints\n",
    "import optimal_control.controls as controls\n",
    "import optimal_control.environments as environments\n",
    "import optimal_control.environments.examples as examples\n",
    "import optimal_control.solvers as solvers\n",
    "import optimal_control.trainers as trainers\n",
    "\n",
    "notebook_extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "environment = examples.FibrosisEnvironment()\n",
    "state = environment.init()\n",
    "solver = solvers.DirectSolver()\n",
    "\n",
    "\n",
    "#control = controls.InterpolationControl(2, 101, 0.0, 100.0, method=\"linear\")\n",
    "key, subkey = jax.random.split(key)\n",
    "control = controls.ImplicitControl(controls.Siren(1, 2, 32, 2, subkey), 0.0, 100.0)\n",
    "\n",
    "#def reward_fn(x: Array):\n",
    "#    x = jnp.where(jnp.isposinf(x), 0.0, x)\n",
    "#    x = jnp.clip(x[..., :2], a_min=1e2, a_max=None)\n",
    "#    x = -jnp.mean(jnp.log(x))\n",
    "#\n",
    "#    return x\n",
    "\n",
    "def reward_fn(x: Array):\n",
    "    return x[-1, -1]\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_with_integral(\n",
    "    integral: ArrayLike,\n",
    ") -> Tuple[ArrayLike, Array]:\n",
    "    _constraints = [constraints.NonNegativeConstantIntegralConstraint(integral)]\n",
    "\n",
    "    reward, _control = trainers.solve_optimal_control_problem(\n",
    "        environment, reward_fn, _constraints, solver, control, 512, key\n",
    "    )\n",
    "\n",
    "    #return reward, _control.control\n",
    "    return reward, jnp.zeros(1)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def evaluate_constant_dosage(\n",
    "    integral: ArrayLike,\n",
    ") -> ArrayLike:\n",
    "    control = controls.LambdaControl(lambda t, args: args, data=integral)\n",
    "    seq = environment.integrate(control, state, key)\n",
    "    reward = reward_fn(seq)\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_constant_dosage(jnp.asarray([0.001, 0.001]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward, control = train_with_integral(jnp.asarray([1.0, 1.0])*101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(constraints.NonNegativeConstantIntegralConstraint(jnp.asarray([1.0, 1.0])*101).transform(control))\n",
    "#plt.plot(control)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner2D(lambda x: 0, bounds=((-3, 3), (-3, 3)))\n",
    "\n",
    "plot_timer = time.time()\n",
    "plot_interval = 15\n",
    "results = []\n",
    "while True:\n",
    "    x, _ = learner.ask(1)\n",
    "    x = x[0]\n",
    "\n",
    "    integral = jnp.asarray(x, dtype=jnp.float64)\n",
    "    integral = 10**integral\n",
    "\n",
    "    optimized_reward, control_points = train_with_integral(integral)\n",
    "    constant_reward = evaluate_constant_dosage(integral)\n",
    "    advantage = optimized_reward - constant_reward\n",
    "\n",
    "    # learner.tell(x, float(reward))\n",
    "    learner.tell(x, float(advantage))\n",
    "    results.append(\n",
    "        {\n",
    "            \"x\": x,\n",
    "            \"integral\": integral,\n",
    "            \"optimized_reward\": optimized_reward,\n",
    "            \"constant_reward\": constant_reward,\n",
    "            \"advantage\": advantage,\n",
    "            \"control_points\": control_points,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if time.time() - plot_timer >= plot_interval:\n",
    "        plot_timer = time.time()\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(learner.plot(tri_alpha=0.25))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of adaptively sampled constant total drug dosages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = examples.FibrosisEnvironment()\n",
    "state = environment.init()\n",
    "solver = solvers.DirectSolver()\n",
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "\n",
    "#def reward_fn(x: Array):\n",
    "#    x = jnp.where(jnp.isposinf(x), 0.0, x)\n",
    "#    x = jnp.clip(x[..., :2], a_min=1e2, a_max=None)\n",
    "#    x = -jnp.mean(jnp.log(x))\n",
    "#\n",
    "#    return x\n",
    "\n",
    "#def reward_fn(x: Array):\n",
    "#    return x[-1, -1]\n",
    "\n",
    "def reward_fn(x: Array):\n",
    "    return jnp.where((x[-1, 0] < 1e2) | (x[-1, 1] < 1e2), 1.0, 0.0)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def evaluate_constant_dosage(\n",
    "    integral: ArrayLike,\n",
    ") -> ArrayLike:\n",
    "    control = controls.LambdaControl(lambda t, args: args, data=integral)\n",
    "    seq = environment.integrate(control, state, key)\n",
    "    reward = reward_fn(seq)\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_constant_dosage(jnp.asarray([1e-2, 1e-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_dosage_learner = Learner2D(lambda x: 0, bounds=((-3, 3), (-3, 3)))\n",
    "\n",
    "plot_timer = time.time()\n",
    "plot_interval = 15\n",
    "constant_dosage_results = []\n",
    "for i in range(2500):\n",
    "    x, _ = constant_dosage_learner.ask(1)\n",
    "    x = x[0]\n",
    "\n",
    "    integral = jnp.asarray(x, dtype=jnp.float64)\n",
    "    integral = 10**integral\n",
    "    reward = evaluate_constant_dosage(integral)\n",
    "\n",
    "    constant_dosage_learner.tell(x, float(reward))\n",
    "    constant_dosage_results.append(\n",
    "        {\n",
    "            \"x\": x,\n",
    "            \"integral\": integral,\n",
    "            \"reward\": reward,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if time.time() - plot_timer >= plot_interval:\n",
    "        plot_timer = time.time()\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(constant_dosage_learner.plot(tri_alpha=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(constant_dosage_learner.plot(tri_alpha=0.1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-optimal-control-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
