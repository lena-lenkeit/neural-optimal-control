{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import Tuple\n",
    "\n",
    "import diffrax\n",
    "import equinox as eqx\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optax\n",
    "from jaxtyping import Array, PyTree, Scalar\n",
    "from tqdm.auto import tqdm as tq\n",
    "\n",
    "import optimal_control.constraints as constraints\n",
    "import optimal_control.controls as controls\n",
    "import optimal_control.environments.examples as examples\n",
    "import optimal_control.nn as nn\n",
    "import optimal_control.solvers as solvers\n",
    "import optimal_control.trainers as trainers\n",
    "from optimal_control.environments.examples.fibrosis2 import (\n",
    "    FibrosisEnvironment,\n",
    "    FibrosisState,\n",
    ")\n",
    "from optimal_control.solvers.base import build_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a4_inches = (8.3, 11.7)\n",
    "plot_full_width = a4_inches[0]\n",
    "plot_half_width = a4_inches[0] / 2\n",
    "plot_third_width = a4_inches[0] / 3\n",
    "plot_quarter_width = a4_inches[0] / 4\n",
    "\n",
    "result_base_dir = \"../thesis-results/fibrosis\"\n",
    "plot_style = \"seaborn-paper\"\n",
    "\n",
    "plot_shrink_factor = 0.9\n",
    "\n",
    "plt.style.use(plot_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(path: str, **kwargs):\n",
    "    with open(result_base_dir + path, mode=\"wb\") as f:\n",
    "        pickle.dump(kwargs, f)\n",
    "\n",
    "\n",
    "def load(path: str):\n",
    "    with open(result_base_dir + path, mode=\"rb\") as f:\n",
    "        return pickle.load(f).values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find optimal PI settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = FibrosisEnvironment()\n",
    "state = environment.init()\n",
    "\n",
    "constraint_chain = constraints.ConstraintChain(\n",
    "    transformations=[\n",
    "        constraints.NonNegativeConstantIntegralConstraint(\n",
    "            target=jnp.asarray([0.01, 0.01])\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "control = controls.InterpolationCurveControl(\n",
    "    nn.InterpolationCurve(\n",
    "        method=\"linear\",\n",
    "        nodes=(jax.random.uniform(jax.random.PRNGKey(1234), (16, 2)) + 1) * 0.01,\n",
    "        t_start=0.0 - 1,\n",
    "        t_end=200.0 + 1,\n",
    "        steps=16,\n",
    "        channels=2,\n",
    "    )\n",
    ")\n",
    "\n",
    "constrained_control = build_control(control, constraint_chain)[0]\n",
    "\"\"\"\n",
    "\n",
    "constrained_control = controls.LambdaControl(lambda _: jnp.full(2, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def with_coeff(\n",
    "    pcoeff: Scalar, icoeff: Scalar, rtol: Scalar, atol: Scalar, dtmax: Scalar\n",
    ") -> int:\n",
    "    solution: diffrax.Solution = environment.integrate(\n",
    "        constrained_control,\n",
    "        state,\n",
    "        None,\n",
    "        throw=False,\n",
    "        max_steps=10000,\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=rtol, atol=atol, pcoeff=pcoeff, icoeff=icoeff, dtmax=dtmax\n",
    "        ),\n",
    "    )\n",
    "    return solution.stats, solution.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcoeff = jnp.linspace(0.0, 1.0, 64)\n",
    "icoeff = jnp.linspace(0.0, 1.0, 64)\n",
    "\n",
    "pcoeff, icoeff = jnp.meshgrid(pcoeff, icoeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_stats = []\n",
    "coeff_results = []\n",
    "for p, i in tq(\n",
    "    zip(pcoeff.flatten(), icoeff.flatten()), total=pcoeff.flatten().shape[0]\n",
    "):\n",
    "    stats, adaptive_results = with_coeff(p, i, 1e-4, 1e-4, 1.0)\n",
    "\n",
    "    coeff_stats.append(stats)\n",
    "    coeff_results.append(adaptive_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_nodtmax_stats = []\n",
    "coeff_nodtmax_results = []\n",
    "for p, i in tq(\n",
    "    zip(pcoeff.flatten(), icoeff.flatten()), total=pcoeff.flatten().shape[0]\n",
    "):\n",
    "    stats, adaptive_results = with_coeff(p, i, 1e-4, 1e-4, None)\n",
    "\n",
    "    coeff_nodtmax_stats.append(stats)\n",
    "    coeff_nodtmax_results.append(adaptive_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_min_idx = np.argmin([stats[\"num_steps\"] for stats in coeff_stats])\n",
    "coeff_stats[coeff_min_idx], pcoeff.flatten()[coeff_min_idx], icoeff.flatten()[\n",
    "    coeff_min_idx\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atol = jnp.geomspace(1e-1, 1e-8, 64)\n",
    "rtol = jnp.geomspace(1e-1, 1e-8, 64)\n",
    "\n",
    "atol, rtol = jnp.meshgrid(atol, rtol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol_stats = []\n",
    "tol_results = []\n",
    "for a, r in tq(zip(atol.flatten(), rtol.flatten()), total=atol.flatten().shape[0]):\n",
    "    stats, adaptive_results = with_coeff(1.0, 1.0, r, a, 1.0)\n",
    "\n",
    "    tol_stats.append(stats)\n",
    "    tol_results.append(adaptive_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol_nodtmax_stats = []\n",
    "tol_nodtmax_results = []\n",
    "for a, r in tq(zip(atol.flatten(), rtol.flatten()), total=atol.flatten().shape[0]):\n",
    "    stats, adaptive_results = with_coeff(1.0, 1.0, r, a, None)\n",
    "\n",
    "    tol_nodtmax_stats.append(stats)\n",
    "    tol_nodtmax_results.append(adaptive_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol_min_idx = np.argmin([stats[\"num_steps\"] for stats in tol_stats])\n",
    "tol_stats[tol_min_idx], rtol.flatten()[tol_min_idx], atol.flatten()[tol_min_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(\n",
    "    \"/pid_callibration/pcoeff_icoeff_sweep.pickle\",\n",
    "    coeff_stats=coeff_stats,\n",
    "    coeff_results=coeff_results,\n",
    ")\n",
    "\n",
    "save(\n",
    "    \"/pid_callibration/atol_rtol_sweep.pickle\",\n",
    "    tol_stats=tol_stats,\n",
    "    tol_results=tol_results,\n",
    ")\n",
    "\n",
    "save(\n",
    "    \"/pid_callibration/pcoeff_icoeff_nodtmax_sweep.pickle\",\n",
    "    coeff_nodtmax_stats=coeff_nodtmax_stats,\n",
    "    coeff_nodtmax_results=coeff_results,\n",
    ")\n",
    "\n",
    "save(\n",
    "    \"/pid_callibration/atol_rtol_nodtmax_sweep.pickle\",\n",
    "    tol_nodtmax_stats=tol_nodtmax_stats,\n",
    "    tol_nodtmax_results=tol_nodtmax_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_stats, coeff_results = load(\"/pid_callibration/pcoeff_icoeff_sweep.pickle\")\n",
    "tol_stats, tol_results = load(\"/pid_callibration/atol_rtol_sweep.pickle\")\n",
    "\n",
    "coeff_nodtmax_stats, coeff_nodtmax_results = load(\n",
    "    \"/pid_callibration/pcoeff_icoeff_nodtmax_sweep.pickle\"\n",
    ")\n",
    "tol_nodtmax_stats, tol_nodtmax_results = load(\n",
    "    \"/pid_callibration/atol_rtol_nodtmax_sweep.pickle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fudge_factor = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coeff(coeff_stats: dict, fig_path: str):\n",
    "    plt.figure(figsize=(plot_half_width * fudge_factor, plot_half_width * fudge_factor))\n",
    "\n",
    "    plt.xlabel(\"Proportional Coeff.\")\n",
    "    plt.ylabel(\"Integral Coeff.\")\n",
    "\n",
    "    cmap = matplotlib.colormaps[\"viridis\"]\n",
    "    cmap.set_bad(color=\"red\")\n",
    "\n",
    "    plt.imshow(\n",
    "        np.reshape(\n",
    "            [\n",
    "                stats[\"num_steps\"]\n",
    "                if stats[\"num_steps\"] < stats[\"max_steps\"]\n",
    "                else np.NaN\n",
    "                for stats in coeff_stats\n",
    "            ],\n",
    "            (64, 64),\n",
    "        ),\n",
    "        cmap=cmap,\n",
    "        norm=\"log\",\n",
    "        origin=\"lower\",\n",
    "        interpolation=\"nearest\",\n",
    "        extent=(\n",
    "            pcoeff.flatten()[0],\n",
    "            pcoeff.flatten()[-1],\n",
    "            icoeff.flatten()[0],\n",
    "            icoeff.flatten()[-1],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    cbar = plt.colorbar(label=\"Num. Integration Steps\", fraction=0.04575, pad=0.04)\n",
    "    plt.scatter([0.99], [0.99], c=\"white\", marker=\"X\")\n",
    "\n",
    "    plt.savefig(result_base_dir + fig_path + \".png\", bbox_inches=\"tight\")\n",
    "    plt.savefig(result_base_dir + fig_path + \".svg\", bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_coeff(coeff_stats, \"/pid_callibration/pcoeff_icoeff_sweep\")\n",
    "plot_coeff(coeff_nodtmax_stats, \"/pid_callibration/pcoeff_icoeff_nodtmax_sweep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tol(tol_stats: dict, fig_path: str):\n",
    "    plt.figure(figsize=(plot_half_width * fudge_factor, plot_half_width * fudge_factor))\n",
    "\n",
    "    plt.xlabel(\"Absolute Tolerance\")\n",
    "    plt.ylabel(\"Relative Tolerance\")\n",
    "\n",
    "    cmap = matplotlib.colormaps[\"viridis\"]\n",
    "    cmap.set_bad(color=\"red\")\n",
    "\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "\n",
    "    plt.pcolormesh(\n",
    "        atol,\n",
    "        rtol,\n",
    "        np.reshape(\n",
    "            [\n",
    "                stats[\"num_steps\"]\n",
    "                if stats[\"num_steps\"] < stats[\"max_steps\"]\n",
    "                else np.NaN\n",
    "                for stats in tol_stats\n",
    "            ],\n",
    "            (64, 64),\n",
    "        ),\n",
    "        cmap=cmap,\n",
    "        norm=\"log\",\n",
    "    )\n",
    "\n",
    "    cbar = plt.colorbar(label=\"Num. Integration Steps\", fraction=0.049, pad=0.04)\n",
    "    plt.scatter([1e-4], [1e-4], c=\"white\", marker=\"X\")\n",
    "\n",
    "    plt.savefig(result_base_dir + fig_path + \".png\", bbox_inches=\"tight\")\n",
    "    plt.savefig(result_base_dir + fig_path + \".svg\", bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_tol(tol_stats, \"/pid_callibration/rtol_atol_sweep\")\n",
    "plot_tol(tol_nodtmax_stats, \"/pid_callibration/rtol_atol_nodtmax_sweep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InterpolationCurve Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimal_control.environments.examples.fibrosis2 import (\n",
    "    FibrosisEnvironment,\n",
    "    FibrosisState,\n",
    ")\n",
    "\n",
    "environment = FibrosisEnvironment()\n",
    "environment_state = environment.init()\n",
    "\n",
    "constraint_chain = constraints.ConstraintChain(\n",
    "    transformations=[\n",
    "        constraints.NonNegativeConstantIntegralConstraint(\n",
    "            # target=jnp.asarray([0.01, 0.01])\n",
    "            target=jnp.asarray([0.1]),\n",
    "            constrain_sum=True,\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def reward_fn(solution: diffrax.Solution) -> Scalar:\n",
    "    return solution.ys[-1, -1]\n",
    "    # return -jnp.mean(jnp.log(jnp.clip(solution.ys[..., :2], a_min=1e2)))\n",
    "\n",
    "\n",
    "control = controls.InterpolationCurveControl(\n",
    "    nn.InterpolationCurve(\n",
    "        method=\"linear\",\n",
    "        # nodes=jax.random.normal(jax.random.PRNGKey(1234), (16, 2)),\n",
    "        t_start=0.0,\n",
    "        t_end=200.0,\n",
    "        steps=201,\n",
    "        channels=2,\n",
    "    )\n",
    ")\n",
    "solver = solvers.DirectSolver(\n",
    "    optimizer=optax.adam(learning_rate=1e-2), ignore_nans=False\n",
    ")\n",
    "\n",
    "key = jax.random.PRNGKey(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_reward, optimized_control = trainers.solve_optimal_control_problem(\n",
    "    num_train_steps=1024,\n",
    "    environment=environment,\n",
    "    reward_fn=reward_fn,\n",
    "    constraint_chain=constraint_chain,\n",
    "    solver=solver,\n",
    "    control=control,\n",
    "    key=key,\n",
    "    pbar_interval=8,\n",
    "    integrate_kwargs=dict(\n",
    "        max_steps=1000,\n",
    "        throw=True,\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-4, atol=1e-4, pcoeff=1.0, icoeff=1.0\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constrained_control = build_control(optimized_control, constraint_chain)[0]\n",
    "\n",
    "ts = jnp.linspace(-10.0, 210.0, 1024)\n",
    "ys = jax.vmap(constrained_control)(ts)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ts, ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = jnp.linspace(0.0, 200.0, 1024)\n",
    "\n",
    "constrained_control = build_control(optimized_control, constraint_chain)[0]\n",
    "solution = environment.integrate(\n",
    "    constrained_control, environment.init(), None, saveat=diffrax.SaveAt(ts=ts)\n",
    ")\n",
    "\n",
    "cs = jax.vmap(constrained_control)(ts)\n",
    "ys = solution.ys\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ts, cs)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(ts, ys[..., :4])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ts, ys[..., 5])\n",
    "plt.show()\n",
    "\n",
    "print(ys[-1, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implicit SIREN -> Interpolation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimal_control.environments.examples.fibrosis2 import (\n",
    "    FibrosisEnvironment,\n",
    "    FibrosisState,\n",
    ")\n",
    "\n",
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "environment = FibrosisEnvironment()\n",
    "\n",
    "constraint_chain = constraints.ConstraintChain(\n",
    "    transformations=[\n",
    "        constraints.NonNegativeConstantIntegralConstraint(\n",
    "            # target=jnp.asarray([0.1, 0.1])\n",
    "            target=jnp.asarray([0.1]),\n",
    "            constrain_sum=True,\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def reward_fn(solution: diffrax.Solution) -> Scalar:\n",
    "    return solution.ys[-1, -1]\n",
    "    # return -jnp.mean(jnp.log(jnp.clip(solution.ys[..., :2], a_min=1e2)))\n",
    "\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "control = controls.ImplicitTemporalControl(\n",
    "    implicit_fn=nn.Siren(\n",
    "        in_features=1, out_features=2, hidden_features=64, hidden_layers=2, key=subkey\n",
    "    ),\n",
    "    t_start=0.0,\n",
    "    t_end=200.0,\n",
    "    to_curve=True,\n",
    "    curve_interpolation=\"linear\",\n",
    "    # curve_times=jnp.linspace(0.0, 200.0, 16)\n",
    "    curve_steps=201,\n",
    ")\n",
    "\n",
    "solver = solvers.DirectSolver(\n",
    "    optimizer=optax.adam(learning_rate=1e-4), ignore_nans=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_reward, optimized_control = trainers.solve_optimal_control_problem(\n",
    "    num_train_steps=1024,\n",
    "    environment=environment,\n",
    "    reward_fn=reward_fn,\n",
    "    constraint_chain=constraint_chain,\n",
    "    solver=solver,\n",
    "    control=control,\n",
    "    key=key,\n",
    "    pbar_interval=8,\n",
    "    integrate_kwargs=dict(\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-4, atol=1e-4, pcoeff=1.0, icoeff=1.0\n",
    "        )\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = jnp.linspace(0.0, 200.0, 1024)\n",
    "\n",
    "constrained_control = build_control(optimized_control, constraint_chain)[0]\n",
    "solution = environment.integrate(\n",
    "    constrained_control, environment.init(), None, saveat=diffrax.SaveAt(ts=ts)\n",
    ")\n",
    "\n",
    "cs = jax.vmap(constrained_control)(ts)\n",
    "ys = solution.ys\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ts, cs)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(ts, ys[..., :4])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ts, ys[..., 5])\n",
    "plt.show()\n",
    "\n",
    "print(ys[-1, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison: Clipped vs. non-clipped reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimal_control.environments.examples.fibrosis2 import (\n",
    "    FibrosisEnvironment,\n",
    "    FibrosisState,\n",
    ")\n",
    "\n",
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "constraint_chain = constraints.ConstraintChain(\n",
    "    transformations=[\n",
    "        constraints.NonNegativeConstantIntegralConstraint(\n",
    "            target=jnp.asarray([0.1, 0.1]),\n",
    "            constrain_sum=False,\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def reward_fn(solution: diffrax.Solution) -> Scalar:\n",
    "    return solution.ys[-1, -1]\n",
    "\n",
    "\n",
    "def clipped_inst_reward(t: Scalar, fy: PyTree, gy: PyTree, u: PyTree, args: PyTree):\n",
    "    fibrosis_penalty = jnp.sum(jnp.log(jnp.clip(fy[..., :2], a_min=1e2)), axis=-1)\n",
    "    return -jnp.atleast_1d(fibrosis_penalty)\n",
    "\n",
    "\n",
    "def cont_inst_reward(t: Scalar, fy: PyTree, gy: PyTree, u: PyTree, args: PyTree):\n",
    "    fibrosis_penalty = jnp.sum(jnp.log(fy[..., :2]), axis=-1)\n",
    "    return -jnp.atleast_1d(fibrosis_penalty)\n",
    "\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "control = controls.ImplicitTemporalControl(\n",
    "    implicit_fn=nn.Siren(\n",
    "        in_features=1, out_features=2, hidden_features=64, hidden_layers=2, key=subkey\n",
    "    ),\n",
    "    t_start=0.0,\n",
    "    t_end=200.0,\n",
    "    to_curve=True,\n",
    "    curve_interpolation=\"linear\",\n",
    "    curve_steps=201,\n",
    ")\n",
    "\n",
    "solver = solvers.DirectSolver(\n",
    "    optimizer=optax.adam(learning_rate=3e-4), ignore_nans=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09df74feda1f4b87bce8421c543f92f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clip_environment = FibrosisEnvironment(reward_fn=clipped_inst_reward)\n",
    "clip_opt_reward, clip_opt_control = trainers.solve_optimal_control_problem(\n",
    "    num_train_steps=256,\n",
    "    environment=clip_environment,\n",
    "    reward_fn=reward_fn,\n",
    "    constraint_chain=constraint_chain,\n",
    "    solver=solver,\n",
    "    control=control,\n",
    "    key=key,\n",
    "    pbar_interval=8,\n",
    "    integrate_kwargs=dict(\n",
    "        dt0=0.01,\n",
    "        max_steps=1000,\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-4, atol=1e-4, pcoeff=1.0, icoeff=1.0, dtmax=1.0\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46128724d1674614a31c380c16c5a62f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cont_environment = FibrosisEnvironment(reward_fn=cont_inst_reward)\n",
    "cont_opt_reward, cont_opt_control = trainers.solve_optimal_control_problem(\n",
    "    num_train_steps=256,\n",
    "    environment=cont_environment,\n",
    "    reward_fn=reward_fn,\n",
    "    constraint_chain=constraint_chain,\n",
    "    solver=solver,\n",
    "    control=control,\n",
    "    key=key,\n",
    "    pbar_interval=8,\n",
    "    integrate_kwargs=dict(\n",
    "        dt0=0.01,\n",
    "        max_steps=1000,\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-4, atol=1e-4, pcoeff=1.0, icoeff=1.0, dtmax=1.0\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAF9CAYAAAA5hAOVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABFtUlEQVR4nO3deZwc9X3n/1cdfU3PdM+huTSHBmkQNxKHbIwxGIgXknA4wNreNYvxRqA42bBZvD9s8fOxZGPk/ZGNfz7iRT5CFrPGTsD2ysfasYMDyBgjbGRAXBKSmNE5d/ccfVZ9948ejZDRMa3pUc2M3k896tFXdc+nurq63/rWt75lGWMMIiIiIgGwgy5ARERETl4KIiIiIhIYBREREREJjIKIiIiIBEZBRERERAKjICIiIiKBURARERGRwCiIiIiISGDcoAs4Gt/32bNnDzU1NViWFXQ5IiIiMg3GGEZHR1m8eDG2ffQ2jzkdRPbs2UNHR0fQZYiIiMhx6O3tpb29/ajzzOkgUlNTA5QWJJFIBFyNiIiITEc6naajo2Pqd/xo5nQQObA7JpFIKIiIiIjMM9PpVqHOqiIiIhIYBREREREJjIKIiIiIBEZBRERERAKjICIiIiKBURARERGRwCiIiIiISGAURERERCQwCiIiIiISGAURERERCYyCCIAxQVcgIiJyUprT55qZNZlhePw+GNwKA1th5A2wXQhXQ6wWGrrhyk9Dy9lBVyoiIrKgnZxBxInA03976G3jQWaoNA1th76X4T9sglAsuDpFREQWuJMziISr4PovQ7INGk6FxGKwLCjmYLwfvvVB2LsZfrUeLvmLoKsVERFZsMrqI3LHHXfQ1dWFZVls3rz5iPO98MILvPvd7+aMM87gjDPO4Dvf+c5M66y88z4IS99dCiMHTlPsRiDZDn/430u3N/4NTAwFVqKIiMhCV1YQuemmm9i4cSNLliw54jwTExNcf/31/NVf/RUvv/wyL774Iu9617tmXOgJ1X4hnHEdZFPw1BeCrkZERGTBKiuIXHrppbS3tx91nm9+85tcdNFFXHLJJQA4jkNjY+O0Xj+Xy5FOpw+ZAnPZx0qXL38/uBpEREQWuIofvvvSSy8RiUS45pprWLlyJbfccgv9/f3Teu66detIJpNTU0dHR6XLm77msyDeCIPbYKwvuDpEREQWsIoHkWKxyM9+9jPWr1/Pc889R1tbGx/5yEem9dy1a9eSSqWmpt7e3kqXN32WBW0XlK7vfzG4OkRERBawigeRzs5OLr/8ctra2rAsi5tvvpmnn356Ws+NRCIkEolDpkA1nla67H812DpEREQWqIoHkfe9731s2rRpqn/Hj370I1asWFHpP3NiNJ5euux/Jdg6REREFqiygsiaNWtob29n165dXHXVVXR3dwOwevVqNmzYAJRaRO6++24uvvhizj33XB577DHuv//+yld+IqhFREREZFZZxszdE62k02mSySSpVCqY3TS5UVjXDtFa+NjOg+ONiIiIyBGV8/utk94dTaQGEu2QHSmNuCoiIiIVpSByLNo9IyIiMmsURI5FHVZFRERmjYLIsahFREREZNYoiByLWkRERERmjYLIsTQuL12qRURERKTiFESOJVYH0SSM90EhE3Q1IiIiC4qCyHQkJ0++l94TbB0iIiILjILIdCTbS5epXcHWISIissAoiExHoq10md4dbB0iIiILjILIdMQbS5caXVVERKSiFESmI76odDk+EGwdIiIiC4yCyHRUNZQuJwaDrUNERGSBURCZDrWIiIiIzAoFkemomgwiEwoiIiIilaQgMh1TnVUVRERERCpJQWQ6quoBS31EREREKkxBZDpspzTUe35Mw7yLiIhUkILIdKnDqoiISMUpiEyXOqyKiIhUnILIdMUnxxIZVz8RERGRSnGDLiAIXipF/9/+LYU3esj39FDYvRvj+1i2DY6DZdskb7iBpr/4j9jxeOlJahERERGpuJMyiFjhMMMPfuPgHa6LZdsY34dCAWMMw9/4BuMbN9L+xS8Q6e7WIbwiIiKz4KQMInYsRutn1xFqaSHc2Ynb3IzlOFOP53t62HPXx8hs3szu/3Qnp/zv72HF1SIiIiJSaSdlEAGofe97j/hYuLOTJd94kO3XXU9u61Yyv/41VQfON6MWERERkYpRZ9UjsEIhktddC8Doz3528PBdDWomIiJSMQoiR1Hze78HwOhPf4aJqUVERESk0hREjiLc3U14yRIKe/aQ2z1SulN9RERERCpGQeQoLMui5j2TrSIbf126Uy0iIiIiFVNWELnjjjvo6urCsiw2b9581HmNMVxxxRXU1tbOoLzgTe2eeeznEE1CLg3FXMBViYiILAxlBZGbbrqJjRs3smTJkmPO+7nPfY5ly5Ydd2FzRfTcc7GTSXKvvYbnqsOqiIhIJZUVRC699FLa29uPOd+WLVv43ve+x8c//vGyisnlcqTT6UOmoFm2TeysswDIpmtKd2r3jIiISEVUvI9IoVDgtttuY/369ThvGiRsOtatW0cymZyaOjo6Kl3ecYmccToAuXS4dIc6rIqIiFRExYPIPffcww033MAZZ5xR9nPXrl1LKpWamnp7eytd3nEJd3QCkB+bfLt04jsREZGKqPjIqo8//jg9PT186Utfolgskk6n6erqYtOmTTQ2Nh71uZFIhEgkUumSZizcWWqZKYwUoR21iIiIiFRIxYPIk08+OXV9586drFy5kp07d1b6z5xQoc7JFpGhTOkO9RERERGpiLJ2zaxZs4b29nZ27drFVVddRXd3NwCrV69mw4YNs1LgXBBqaQHXpdCfxhh01IyIiEiFlNUisn79+sPe/7Wvfe2w93d1dTEyMlJ2UXON5bqEFi+m0NNDMWMTygV/NI+IiMhCoJFVpyk8eQRPYcyFbCrgakRERBYGBZFpCk12WM2POZAZCbYYERGRBUJBZJoOHsKrFhEREZFKURCZplBHaUTZwpijICIiIlIhCiLTFD5wCO94SEFERESkQio+jsh84PmG3qEJ9oxk2D2SoW80h2NbxEIO0ZBNIhri3ac1EQsfHKI+3H6gRcQFLweFDIRiQS2CiIjIgnBSBpGRiTzv/ut/Oeo8pzXX8M3b3k5DdWmkVzsex1m0CG9gAC9v4WRTCiIiIiIzdFIGkfp4mHPakjTWRFhcG6W5JooBsgWPTMHjya0DvLp/lJu//gzfuu0iklUhoNQqkhkYID/mEsumoKYl2AURERGZ507KIGJZFt//80uO+HgqU+DffvVptuxJs/a7z/PlD14AlA7hzWzeTGHcKQURERERmRF1Vj2MZCzEg//+bVSFHX784j760lngdw7h1VgiIiIiM6YgcgQN1RHec2YzvoEntpZOchc60GF1XIfwioiIVIKCyFG869RGAJ7c2g+Au2gRAF7WhuxIUGWJiIgsGAoiR/GuU0vBY+PWAXzf4DbUA1DM2WoRERERqQAFkaNoTkRZ3lzN4Hiel/elcRoagAMtIgoiIiIiM6UgcgwHd88M4NbVAVDMOdo1IyIiUgEKIsdwyeTumSe39mOFw9jxGH7exowNB1yZiIjI/KcgcgxvP6Ue17b49RvDFD0fty4JQHFYQURERGSmFESOoSrs0t1UTbbgs3NwHKe+1GHVGx4JtjAREZEF4KQcWfXNxgvj9E/04xsfLLCwcG2X9up2LMsC4MzWBK/sG+WlvaOc31DaVVMcGQ2ybBERkQXhpAwiI9kRbv3xreyf2M9YYeyw8yxNLmX1Oav5g1P+gFMWxQHoGRxnVWMzAF56/ITVKyIislCdlEGkOlzNjvQOfOPTEG2gsaoR13Ixk/8GM4NsT23n7o1388SuJ7i47j8C0DuUwV1UOoqmOJoDY2Cy1URERETKd1IGEdd2+fENP6Yh1kDYCb/lcd/4/Lzn53zqqU/x450/ZuXK3wegd3gCZ3JQMy8L5MchUn0iSxcREVlQTtrOqq3VrYcNIQC2ZXPlkitZc+4aAJ7c/12gFETcyUHNilmNJSIiIjJTJ20QmY4bTr2BeCjOU3sfJxIbZs9IFmpLg5p5GuZdRERkxhREjqI6XM0fdf8RBkOy+Vd4vmE4VOq4WtQw7yIiIjOmIHIM//b0f4uFRT76K8BjjxUFdL4ZERGRSlAQOYaORAdnLzobz8rgxHroLYTAKp2B12RGgi5PRERkXlMQmYZVLasAsGM99KayONVRjGdjRvoDrkxERGR+KyuI3HHHHXR1dWFZFps3bz7sPI899hhve9vbOPPMMznrrLO466678H2/ErUG5vT60wFwovvoHZrATVYBUOzvC7IsERGRea+sIHLTTTexceNGlixZcsR56urq+Na3vsVLL73Er3/9a5566ikefPDBGRcapNPqTgPAjuyldziDk6wBwBscCLIsERGRea+sAc0uvfTSY85z3nnnTV2PRqOsXLmSnTt3ll3YXNKZ6CRsR8hF+ujZncatqwXeoDg0FHRpIiIi89qsjqy6b98+HnnkEX7wgx9Ma/5cLkcul5u6nU6nZ6u0sri2S3fdMl4afInBfC9WXWkskeKwjpoRERGZiVnrrJpOp7n22mu56667uPDCC6f1nHXr1pFMJqemjo6O2SqvbFO7Z6J7yVRPDmqWOvwJ80RERGR6ZiWIjI6OcvXVV3P99ddz5513Tvt5a9euJZVKTU29vb2zUd5xOa2+FEScyD5GqiZbRNITQZYkIiIy71V818zY2BhXX301V199NZ/4xCfKem4kEiESiVS6pIpYXrccKHVY7fPOpwvwxnJHfY6IiIgcXVktImvWrKG9vZ1du3Zx1VVX0d3dDcDq1avZsGEDAJ///Od55pln+M53vsPKlStZuXIln/nMZypf+Qk2FUSi+3jDnWwRGS8GWZKIiMi8ZxljTNBFHEk6nSaZTJJKpUgkEkGXw7u+eQUjhX7+cPxTfOgLnyKSLLD0l6+BrXHhREREDijn91u/oGVYUlNqAXrdHgRKw7yTmxtH9oiIiMxHCiJlOLB7Zo+/C8sFL2djJoYDrkpERGT+UhApw1mNpSNnxsw+3CoHjIXXvzvgqkREROYvBZEynFLbBkDBGsKpDgPg7dsVZEkiIiLzmoJIGVrjraUr7ghWPApAsX9fgBWJiIjMbwoiZWisagRjYYdGMPEYoBPfiYiIzISCSBlc2yVs1WLZBTKTLSLe8GDAVYmIiMxfCiJlituLABiKhgDwhkcCrEZERGR+UxApUzLcBEBfrDQ6vpfSOCIiIiLHS0GkTIuipSCyL2IB4KV1Bl4REZHjpSBSpgNHzuyO+AB4Y5kgyxEREZnXFETK1JFYDMCeSOmEd0WdgVdEROS4KYiUaVldaVCzPdFSS4g3oTPwioiIHC8FkTItb+gEoD82DoCX8YMsR0REZF5TEClTR3IRxg+RD49hh3z8PJiiWkVERESOh4JImRzHxvbqsCwfSmOa4Q1pUDMREZHjoSByHCLUA1CIld4+b39vkOWIiIjMWwoix6HKKY2umok5AHh9u4MsR0REZN5SEDkOteFGAEarSkGkOKAz8IqIiBwPBZHj0BhtBmC4anLXzEBfkOWIiIjMWwoix6G1ujS66kBscph3dVYVERE5Lgoix6G9phRE+mIGAG94KMhyRERE5i0FkePQVdsCQF/V5PlmdAZeERGR46Igchzak/UYP8RAlQeAlxoNuCIREZH5SUHkODQmIphiDamq0m1vdCLYgkREROYpBZHjUF8VxhSrGYuVbntj2WALEhERmacURI6D69i4JBk9EEQmCsEWJCIiMk8piBynmF1L0bXwQwYv4+nEdyIiIsdBQeQ41bil883ko5OH8KZ15IyIiEi5ygoid9xxB11dXViWxebNm48439e//nVOPfVUli1bxm233UahsPB2XSQjDQBkDpyBd2QkuGJERETmqbKCyE033cTGjRtZsmTJEefZsWMHn/zkJ3nyySfZtm0b+/fv5ytf+cqMC51rFsVKJ76b6rA6PBxgNSIiIvNTWUHk0ksvpb29/ajzPPLII1x33XW0tLRgWRZ/8id/wsMPPzyjIuei5qrSie9SOt+MiIjIcXMr/YI9PT2HtJh0dXXR09MzrefmcjlyudzU7fQc7nexuKYJ+mCoygIMXr/OwCsiIlKuOdVZdd26dSSTyampo6Mj6JKOqCPZjDEW/VWTJ74b2B9wRSIiIvNPxYNIZ2cnb7zxxtTtnTt30tnZOa3nrl27llQqNTX19vZWuryKaa6JYbw4w5OjqxaH+oMtSEREZB6qeBC58cYb2bBhA/v27cMYw/33388HPvCBaT03EomQSCQOmeaq+nhpdNXRA8O8D+kMvCIiIuUqK4isWbOG9vZ2du3axVVXXUV3dzcAq1evZsOGDQAsXbqUe+65h3e+8510d3fT2NjImjVrKl95wBqqS+ebmRpdVYfvioiIlM0yxpigiziSdDpNMpkklUrNudYRYwxnffHDLM0+y31/5xE7dTFd3//noMsSEREJXDm/33Oqs+p8YlkWETtJeuoMvOPBFiQiIjIPVfzw3ZNJtVPPWLh03RvNBFuMiIjIPKQWkRlIRuopuBaFkMGbyGM8L+iSRERE5hUFkRloiJaGec9EAaMT34mIiJRLQWQGmiaHeT94vpmR4IoRERGZhxREZmBxTTMAqdjk6Ko6hFdERKQsCiIz0FqTAD/EUPxAENEZeEVERMqhIDIDDdVR/GINae2aEREROS4KIjPQUB3GL9YwemDXzNBgwBWJiIjMLwoiM9AQD2OKiYPnmxnYF2xBIiIi84yCyAyUzjdTPXW+meJAX7AFiYiIzDMKIjMQDzvYfuLgie+GtWtGRESkHAoiM2BZFtVO3cE+IsM6akZERKQcOtfMDCUiDYw6peteSiOrioiIlEMtIjNUH2k4uGtmdCLYYkREROYZBZEZaoo3kg9Z5F2DN5bF+H7QJYmIiMwbCiIz1FrdCIZSPxED/uho0CWJiIjMGwoiM7SoOorjRUkfGEtEHVZFRESmTUFkhhriYaxiNamq0pEzxUEdwisiIjJdCiIz1FAdxismSMVLt4v9A8EWJCIiMo8oiMxQQzxCoVjLcHXpdrG/P9iCRERE5hEFkRk60CIyXD25a2a/zjcjIiIyXQoiM9QQj2CKNYwcaBHZtzvYgkREROYRBZEZioUdQiQPtoj0qUVERERkujTEewUkQvWMhEvX1VlVRERk+hREKqA+uoi+UOl6cWgk0FpERETmE+2aqYCmqkXkwhbZEHjpMUyxGHRJIiIi84KCSAU0VSdwfZuhasBoUDMREZHpUhCpgMaaCOFi9OCRM30aS0RERGQ6yg4iW7du5eKLL2b58uWsWrWKLVu2vGUe3/e58847OfPMMzn33HO5/PLL2bZtW0UKnosaqyM4xaqDR85oUDMREZFpKTuIrFmzhttvv53XXnuNj33sY9x6661vmWfDhg384he/4Le//S3PP/88V155JXfffXcl6p2TGmuieMUEI1PDvCuIiIiITEdZQaSvr49nn32Wm2++GYAbb7yR3t7et7R2WJZFLpcjm81ijCGdTtPe3l65queYxpoI+WIdIwdaRAYURERERKajrMN3e3t7aW1txXVLT7Msi87OTnp6euju7p6a79prr+XnP/85LS0t1NTU0NbWxuOPP37M18/lcuRyuanb6XS6nPIC01gTYaLYoPPNiIiIlGlWOqs+++yzvPjii+zevZs9e/Zw5ZVX8id/8ifHfN66detIJpNTU0dHx2yUV3GLps43U7pd3L832IJERETmibKCSEdHB3v37qU4OU6GMYaenh46OzsPme/BBx/kiiuuoLa2Ftu2+dCHPsTPf/7zY77+2rVrSaVSU1Nvb2855QWmOuISInlw18w+DfMuIiIyHWUFkaamJs4//3weeughAB599FHa29sP2S0DsHTpUh577DHy+TwAP/jBDzj77LOP+fqRSIREInHINB9YlkVtpJ7hA51VBzTMu4iIyHSUPcT7+vXrufXWW7n33ntJJBI88MADAKxevZrrrruO6667jj/7sz/j5ZdfZsWKFYRCIVpaWrj//vsrXvxc0hhtZEcMiraBoRTGGCzLCrosERGROa3sIHLaaafxy1/+8i33f+1rX5u6HolE+OpXvzqzyuaZluoGdvoWqbhFw6iHNzKCW1cXdFkiIiJzmkZWrZCmRIywFy4N846OnBEREZkOBZEKaayO4hbiBzusKoiIiIgck4JIhTTWRDDFpMYSERERKYOCSIU01kTIF+oZiatFREREZLoURCqkNRklU2hUi4iIiEgZFEQqpCUZpVisY2QyiHj7NaiZiIjIsSiIVEh9VRjHq2P4QGdVDfMuIiJyTGWPIyKHZ9sWDbFGhqOl24X9+4MtSEREZB5Qi0gFtVW3MBKHggOFviGM5wVdkoiIyJymIFJBrclqon6I/gTgeRT7+oIuSUREZE5TEKmg1mSUSDFGX22pn0hh9+6AKxIREZnbFEQqqDkRxS7U0J8s3VYQEREROToFkQpqTUYpFmrpT5ZaRPIKIiIiIkelIFJBLZODmvXVlm4XdimIiIiIHI2CSAW1JmOMFlumWkQKu3cFXJGIiMjcpiBSQY01EfDq6DvQR6S3N9iCRERE5jgFkQpybIv6SCOpOBRcQ2F/H6ZYDLosERGROUtBpMJaq1uwsehLWKWxRDTCqoiIyBEpiFTY4mSceCEyNZaIjpwRERE5MgWRCmtJxHALNQf7iezeE2xBIiIic5iCSIW1JqP4+Qb6NbqqiIjIMSmIVFhLMspEvuXg6Kq7dAiviIjIkSiIVFhLMkq6sJi+pFpEREREjkVBpMJKu2YWvWl01Z5A6xEREZnLFEQqrCURxfYaGI1BLkRpLJFCIeiyRERE5iQFkQpzHZvFiXpivsOeesA35HvUKiIiInI4CiKzoLO+iqpCjN0NpX4iuddfD7giERGRuUlBZBZ01Ffh5JNTQSS/fXvAFYmIiMxNCiKzoLO+ikJ+EbsWlW7ntqlFRERE5HDKDiJbt27l4osvZvny5axatYotW7Ycdr4XXniBd7/73ZxxxhmcccYZfOc735lxsfNFZ30VY4XF7Fo0uWtmu4KIiIjI4bjlPmHNmjXcfvvt3HrrrTzyyCPceuutbNq06ZB5JiYmuP7663nwwQe55JJL8DyPoaGhihU913XWV5HOt+E3gW8Z8tt3YHwfy1YDlIiIyJuV9cvY19fHs88+y8033wzAjTfeSG9vL9u2bTtkvm9+85tcdNFFXHLJJQA4jkNjY+MxXz+Xy5FOpw+Z5qOO+hheoQHPsRioBZPNUtijc86IiIj8rrKCSG9vL62trbhuqSHFsiw6Ozvp+Z3DU1966SUikQjXXHMNK1eu5JZbbqG/v/+Yr79u3TqSyeTU1NHRUU55c0YyFqLaacA28EbjZIdVHTkjIiLyFrOyr6BYLPKzn/2M9evX89xzz9HW1sZHPvKRYz5v7dq1pFKpqam3t3c2ypt1lmXRWV9DbSFE74F+Iq/ryBkREZHfVVYfkY6ODvbu3UuxWMR1XYwx9PT00NnZech8nZ2dXH755bS1tQFw8803c9VVVx3z9SORCJFIpJyS5qzO+ireSFWzuyEHGHKvbzvmc0RERE42ZbWINDU1cf755/PQQw8B8Oijj9Le3k53d/ch873vfe9j06ZNU308fvSjH7FixYoKlTw/dNZXQa5x6siZvFpERERE3qLso2bWr1/Prbfeyr333ksikeCBBx4AYPXq1Vx33XVcd911dHZ2cvfdd3PxxRdj2zZtbW185StfqXjxc1lHfRXjuXbGF70KQG77dowxWJYVcGUiIiJzh2WMMUEXcSTpdJpkMkkqlSKRSARdTlmeeK2fj3zzYexTvspX/rZIbRq6n3icUFNT0KWJiIjMqnJ+vzWwxSwptYiUjvrpbSjdp6HeRUREDqUgMkvaamNYhGkoWOxs1MnvREREDkdBZJaEXZvFyRi1+ejBk98piIiIiBxCQWQWddTHCOdqD44l8trWgCsSERGZWxREZlHpLLwt9DSBAbKvvMIc7hssIiJywimIzKLO+ipSuS5yYYvhegt/bIzC7t1BlyUiIjJnKIjMolMWVbMvuxyA7Y2llpDsyy8HWZKIiMicoiAyi5Y2xpnw66gv+rzWUnqrcy+/EnBVIiIic4eCyCw6ZVEcy4KmgsvO5tJ92VcURERERA5QEJlF0ZDD4mSM6lw1O5tLR85kX9GuGRERkQMURGbZ0sY4Vq6BkTjk4g7FPXvxRkaCLktERGROUBCZZcsaq8nk2sGy2Ntceruzr7wacFUiIiJzg4LILFvaGGco2w3Aq40eoN0zIiIiByiIzLKli6rp8ZbQUizyymSH1ZxaRERERAAFkVm3tDFOhihded7UYVVHzoiIiICCyKxrSUSJhRwasjH21oMXcsi9/jomnw+6NBERkcApiMwy27Y4ZVEcN9eAb1sMNYehUCCnM/GKiIgoiJwISxvjZLOdAGw/0GF1y5YgSxIREZkTFEROgKWN1ezLL6PK93m+uQhARkFEREREQeREWNYYZ7vfxvJ8gW2tkx1WX1QQERERURA5AbqbqtlLPd15j55G8F2H3KuvqsOqiIic9BREToBljdXYtkNtLo7nWIy0VWPyeXLbtgVdmoiISKAURE6AaMihq6EKJ9sIwM5mA0DmxReDLEtERCRwCiInyGktNYxnO7CNYXNjBlA/EREREQWRE2R5cw1v+B0sKRR5udkHIKsWEREROckpiJwgp7fUsM20cVo+z65F4IdDZLduxc/lgi5NREQkMAoiJ8jy5hp2mhZOzxfwHIt0Z11phNXXXgu6NBERkcAoiJwgSxriWG6EhmwNADsmO6xq94yIiJzMFEROEMe2OLW5mmJmMZYx/KY+DejIGRERObmVHUS2bt3KxRdfzPLly1m1ahVbjjJUuTGGK664gtra2pnUuGAsb67hDW8JXYUiWyaHes9ueSngqkRERIJTdhBZs2YNt99+O6+99hof+9jHuPXWW4847+c+9zmWLVs2k/oWlNNbanjVdHBWPs/uBvAjYXJbt+Jns0GXJiIiEoiygkhfXx/PPvssN998MwA33ngjvb29bDvMCKFbtmzhe9/7Hh//+Men/fq5XI50On3ItJAsb67hFdPJWbk8xrYYWVILnkfulVeCLk1ERCQQZQWR3t5eWltbcV0XAMuy6OzspKen55D5CoUCt912G+vXr8dxnGm//rp160gmk1NTR0dHOeXNeae11NBrGjk1V+qo+npz6QR4medfCLIsERGRwMxKZ9V77rmHG264gTPOOKOs561du5ZUKjU19fb2zkZ5gWlJRKmLRyHbiGMMzzaMAJB5/vlgCxMREQmIW87MHR0d7N27l2KxiOu6GGPo6emhs7PzkPkef/xxenp6+NKXvkSxWCSdTtPV1cWmTZtobGw84utHIhEikcjxLck8YFkW57Ql2bl9Ccvyr/Bia+n+zObNgdYlIiISlLJaRJqamjj//PN56KGHAHj00Udpb2+nu7v7kPmefPJJ3njjDXbu3MnGjRtJJBLs3LnzqCHkZHFOW3Kqw2p/Eoq11RR27aI4MBB0aSIiIidc2btm1q9fz/r161m+fDmf/exneeCBBwBYvXo1GzZsqHiBC8057UleMR2cncuDZbH/lFpAu2dEROTkVNauGYDTTjuNX/7yl2+5/2tf+9ph5+/q6mJkZKTswhaqc9qSvOZ3cO7kOWa2tORpAzLPbabmiiuCLU5EROQE08iqJ1hrMoqJN1KXi1Hl+/yyfgiAzG9/G3BlIiIiJ56CyAlmWRbntCd51V/CObk821oMxrbJvPgiplgMujwREZETSkEkAOe0JXnBnMK5uRy5sMX4kkWYiQlyhxkYTkREZCFTEAnAOW1JXvRPYWW21E9kR3sI0GG8IiJy8lEQCcA57QdaRPIAPLMoBUBms/qJiIjIyaXso2Zk5loSUbJV7VCM0ZUv8Num0pDv6rAqIiInG7WIBMCyLM5fUscL/imszOXYVwfFmiryO3ZQHBoKujwREZETRkEkIKu66nnRnMKqbA4si93dSQAmntkUcGUiIiInjoJIQC7sKrWIrMpkAXhm8TgAE888E2RZIiIiJ5SCSEDObkvymrOMVs+j3YOnW0pBZPyZXwVcmYiIyImjIBKQkGPT2H4aIybOqokxdjVCMVFFftvrOgGeiIicNBREArTqlHpe9LtYlcliLIveqX4i2j0jIiInBwWRAF3YVc9m013qsAr8arKfyPivFEREROTkoCASoPM6a3nOLKfF8+gkxK9aJzus/kr9RERE5OSgIBKgmmiI8abzAbhgfJzdDVCorSa/cyeF/X0BVyciIjL7FEQCdtayLl7z27h4PA2Wxc5lcQAmdPSMiIicBBREAvauUxfxa385F2cyOFhsbB4BYFy7Z0RE5CSgIBKwt5/SwGZOI+EbVjg1bG4vAjChDqsiInISUBAJWCzsUGxbBcDF6VH21kOmNkaht5fC7t0BVyciIjK7FETmgFPPWMmgqeH3hneDZfH80tJqGXtyY8CViYiIzC4FkTngXcsb+Y2/nKWFIm2ROp7qzAAw9sQTAVcmIiIyuxRE5oAzWhK8HDoDC7iIJM93WRjbYvzpp/Hz+aDLExERmTUKInOAbVuY9rcBsGpoiPGYRW9XHDMxQebZZwOuTkREZPYoiMwRp5z7LnLG5fK+V0mGE2zsmABg7HHtnhERkYVLQWSOuOzMDp4zy6miwJW1Z/PcMguAsccfxxgTcHUiIiKzQ0FkjkhWhdhVeyEAFwz7vNEEw3Uh8jt3ktu6NeDqREREZoeCyBxSfcaVAJzd+wLN8RY2nloa3Gz0xz8JsiwREZFZoyAyh5x30RWMmwidmVf5V+2X88vTS6sn/RMFERERWZgUROaQ5roEr0bOxsXnzHQ12xbDcNIh//rr2j0jIiILUtlBZOvWrVx88cUsX76cVatWsWXLlrfM89hjj/G2t72NM888k7POOou77roL3/crUvBCl+u4BIDabS9wWv3p/GJ56X1La/eMiIgsQGUHkTVr1nD77bfz2muv8bGPfYxbb731LfPU1dXxrW99i5deeolf//rXPPXUUzz44IOVqHfBW7LqDwBY3P8UNy1//5t2z/w4yLJERERmRVlBpK+vj2effZabb74ZgBtvvJHe3l62bdt2yHznnXceS5cuBSAajbJy5Up27tx5zNfP5XKk0+lDppPN4tPezqDdwFJ2s2iokf1dNQwkIL/tdbIvvxx0eSIiIhVVVhDp7e2ltbUV13UBsCyLzs5Oenp6jvicffv28cgjj3DNNdcc8/XXrVtHMpmcmjo6Osopb2GwLIbafw+A4Wd/xPXL/4jHzy6NKTLyyKNBViYiIlJxs9pZNZ1Oc+2113LXXXdx4YUXHnP+tWvXkkqlpqbe3t7ZLG/OWnzRDQAsGXicqztu4LEVpdU0smEDfjYbZGkiIiIVVVYQ6ejoYO/evRSLpfEtjDH09PTQ2dn5lnlHR0e5+uqruf7667nzzjun9fqRSIREInHIdDKKL7+crBXjAutVtrw8yhlnX1Y6Ed7oKKP/9E9BlyciIlIxZQWRpqYmzj//fB566CEAHn30Udrb2+nu7j5kvrGxMa6++mquvvpqPvGJT1Su2pOFGyHdfimOZdj97Ab+dMWf8s8rS7tnBr79rYCLExERqZyyd82sX7+e9evXs3z5cj772c/ywAMPALB69Wo2bNgAwOc//3meeeYZvvOd77By5UpWrlzJZz7zmcpWvsA1nPdeAM5IbyQz1kr88itIxyD/6+fIbd8ebHEiIiIVYpk5fEa1dDpNMpkklUqdfLtpxgfx//pUsr7L2qWP8qfXNvG9//RHXPcrQ+yPrqVr3f8XdIUiIiKHVc7vt0ZWnaviDXhLr6DKyhF9bQNVdDB+wxUUHBjf8EMKe/cGXaGIiMiMKYjMYaEL/h0ANzhP8MAvdnLru+/k8XNtbM9n5/2fD7g6ERGRmVMQmcuW/z5etI6326/wy2c30RDqgJtvwLMg853vUxgYCLpCERGRGVEQmcvcMM6K9wPwB95jfPnxbXz4PR/j2XNjhAo+v/niPQEXKCIiMjMKInPdyg8CcJPzBP/zF9tJTzi0/+kd+ED4u//M0B4dQSMiIvOXgshc13outK6g1RriCv9p/v+fvcaVl36IV1c1E80bnvz0nwZdoYiIyHFTEJkPLr4DgP8Q2sAjv+5lW98Y77jni+Rc6N74Bo899kDABYqIiBwfBZH54Mz3Qt0pnGnt5FLrt9z7o5dpOeVsMu//V9gGhu/7HH3jfUFXKSIiUjYFkfnAceGSvwDgjvD3+fmr/fz4xX28/aPrGK+NcuaOAv/zC7fh+V6wdYqIiJRJQWS+WPFvoKaV83mZd9hb+C/f38K4HaL9k58C4NJ/eI2vPvnfAy5SRESkPAoi84UbgUtKZzH+bPxh+tMZ/vs/vUbLH/4R5rK3k8iA8/m/58ldTwZcqIiIyPQpiMwnF34YGk9nSWE7Hwz9C//zlzvZ3DvC8r+6j2J1lEteMnzrax9l1+iuoCsVERGZFgWR+cQJwdXrALg7+gg1ZoyP/sNmirX1dPy/pV00N39/lLX/+yOM5ceCrFRERGRaFETmm2VXwGl/SKwwwl/V/pDX+8e57yevknzve6m64nJqx+EPH3qd//wvH6XgF4KuVkRE5KgUROajq/4KnDDX5n7ABe4Ovr5xB09vH6L93nuxW5pZsdPQ+OhGPvmLT+IbP+hqRUREjkhBZD6qXwqX3oVlPL6afIAwBf7zP/6WiWicjr/5HDg2H3jCp/dn3+cvf/mXOqxXRETmLAWR+eqSv4CWc6gf38a6RT9h90iGu7/7IrHzVtJ8113YBu78ns8vn36Ejz7+UXJeLuiKRURE3kJBZL5yQnD9l8F2uWH827wj1sv3f7uHh55+g7pbbiF5041U5eCT3zb89oWf8cc/+WN2j+0OumoREZFDKIjMZ63nwiV3YhmPr9Wsp8rK8pc/eInf7krR+qlPEX/nO2lI+fzXhy16X9/MTRtu4vuvfx9jTNCVi4iIAAoi89+l/w+0XUA8vZ1/6PguBc9w24PPsnu8SPvffomqiy6iYbjIX387St2eUe7eeDd//tif05PuCbpyERERBZF5zw3DTX8HkSRn932fT3Y8T/9ojlv+7hkGCtDxP75M/OJ3UD0wzn3/y+XyHXEe3/U47/3f7+ULv/kCE4WJoJdAREROYgoiC0FdF1z3BQD+/fDnef/ifrb3j/NvvvI0AwWLjvXrqfvgB7EzOT7yrRSfef507ILHV1/4Ktd+71r+z47/o901IiISCAWRheKs98LFf45VzLAufy/vaS/yev847/3bX/CbPaO0fPITtPzlPVihEKf+8EW+8ehirimeRd9EH3c9cRcf/smHeWnwpaCXQkRETjKWmcP/FU6n0ySTSVKpFIlEIuhy5j7fg2/fDK/+CL/2FO6M/SXf2+Hg2Bb/4fJubrt0Ke7O7ez5+MfJvfwyhFzS7/s9/rL7BXry+wG4dum13HH+HbTEWwJeGBERma/K+f1WEFlocmPw8Adg55OYRDv/67Qv8ulfZPF8QzIW4oNv7+TK7jrafvAthr/6VfA83PZ2Nv+7C/lr9zEmihNEnAgfOO0D3HzmzQokIiIngO8bXusb5ZkdQ7y8d5SC55OMhairCrG0sZozWhMsqa/Ctq2gS50WBZGTXX6i1DLy+j9DuIZdF32a/9Kzgp+90j81SzzscGUoxY1PfpOmntcA8N7+Nn7+nlq+5v8LvvFxLZdL2y/l90/5fS5pu4TqcPVb/pQxhmzBZzRXYCxbZCxXZDRbmsZyRcayBUKuTV1VmLqqMDVRl1jYoSrsYGExkS8ykfdIZwsHnzd5PVf0qYuHaayJsKS+ilMa4ySioRP2Ns4Gzzds7Rtlc88Im3tHeGlfmr0jY0TcMNURlyUNVZy1OMlZixOc3ZakqSaCZVXui8f3DcMTedLZIrYFEdehJuqW1sfv/B1jDOlskZGJPOlMkXS2QLbglb4c42Hqq8LUVoWOWZ8xhoGxPFv3j/LCvt30jgzSP5ol5xWxsAk7EeqicerjNdTH4tRWhUnGQiRjIaojLhP5IiMTBYYm8gyN5xkcyzEwlmX/RB+DmX6K1ihOaJxY2Kepuob2ZB3nNJ3KBW3LaU1UE3aPvAfa9w25ok/e86mJuGV9yfu+YfvAOJt7R/hN7z56U/2kc+NUh+M0xGpZVJWgoTpCXVWY+njps3/g1Q0wmi0wNF5geHK5DkzDE3kyeY+qiEtNxKU64hKPuNREXeIRh+pIiOqIQ3XUJR52qa0K07Woisbq8j4rvm8YHM+zP51lXyrLvnSWwbE8Y7nS9pfKZhnJDZHKD5Dxxok5ceJuLdWhJE3xBJ0NcTrqq+isr6KjLkZ9PFzRz+qJYIyhbzTH631jbOsfm7rcm8ri2haLqiO0JmO0JqO01kZZnIzRWhulIR6Zer4BfGMwBmIhZ1rbBEC+6PPKvjTP7hzmVzsG+dWOftLFvdjRvdiRfVhOFowNxsH4YYxXRYga2pOLWFrXTGO8nvpoLVE3BsCBP2kBiViIjroqljXFaUlEj1iPMYaCZ466jRwvBRGBYg5++FF47hul20vfzRun38a3B5fxi+1DvLBrBN+AZXze0/Ms/37LD0jmS0fQPN+2jJ+8s4Znl76MsQ4MD28RYzHh4hJMYRGFXIJcropM1qHohQADlodlFcHywH7TdasIxsX4ITAh8EMHr9tZ7NAwdmgEa+pyBMsdBazJjTCCKdTiF2qJWYtormqmI9HG8oYOTl3UTswNEXJsXMfG9w1F31D0fAqTl0XPUPBLlwceG88VSWeLpDIF0plCKQjl8mSKGTKFLEU/j+sYwiGbkG0Tci3Cjk3IsQm7By5dYk6EaChMzI0SC0WoCoWIhhyiIZtoyKHg+aQyOXpS+3hlYCfbR3ZSsPuxwwPY4UHs8CCWXcD4DsaPYYoJ/EISU0hiirXEnXq6km20VDdRG40RDbmEnTCxkEvEDRN1Q8TcCLZtYwG2ZWFZkM4U2DeaYtfoHvZO7GYwu4d0cT9Z+sBNTa4rD7AwxsbCwcYGHCxsjLHwyYOdAzuHZedK69GL4RcTk+ujDturpzbcRFOslaaaKqqieQpmgtHCEEO5Pkby/aSLA/j2MJabwrKPfroBYyzww6V17kfBj2C8CBgX7AKWncdyRrFCaSzr6OdRMsbGzzfgeo2EWYTt1WGAol+k6OcpksW3Mlh2rvS6fpSYmyQZaqAx2kpHTQdL6zrpqmvEtS18A32jGbYO7OX5vlfZnn6VgtOLE92DHRk4zN93MF4VxotNXpYmjF36m0526r21DnmffTAOGBtjHN7alc+a/IFyMb5bet1iEtdvoD7SQlt1G0vrOliSbKM6HMGyYCxbZDRbYF86y66RUXpTA/SND1C0U9huGmtyst106b1101jOOJZ1+J8H44cwhSR+oRZTLF2GTB2NsWZaauqpDkeIhcLEQg6u7WBbFrZlY9s2zuR1x7axLQvHcgjZIVw7RMgOE7JdnMlA6PkGz5R+MEvXDb5ful7wC5PrskjBFPGNj/EdQk6IRDhKTTRCTdSlOhLCsmA8V/pPT/9olh1Dw+wY7qN3ZD8ZM/ym5U8dXH47ByaE8cOTn8kwxoTAD5fWj+WBVcCyS99zxotgvBosr5pqt45EuJ5FsQaaqhZRH01iWzYFD/aPpdg9OsiO4V14bh92ZD9OZC92ZH/ptcpk/NDBz1cxPrU+/EIdplBHlAZOqWvj1KZaljXGqYuH6Uvn2DE4wq92Pc9wfoh/+Hd/zMqOhrL/9tEoiMhBr/4Yvn8HjJX6gFC/FE65lEzr23jD6eLVXD2vpSx6dw3Q/viPuGzzP5HIjwOwJ17PM0sa2bI0w2vLBshU5QNckMMzxsIUazBebPIe662X5nfvY/ILpAB2HssqlH7kjvHDNr16Sj8Q+C7GOKUvFjt7xC9027KJu1VkilmKpvwvoam/608GPOMCdulHxK7g2ZeNhWW5GI7/NS3jEHPqqXYTRFwH1wLje2RNgayXI+dlKZgsRXPs0xG4VpiGaDONsUbqIg1UOUk8z2VgYpyBiSEG871k2AvWzN8D40VL7y8WljNx2B+LiB1nUbSZqBslU5xgNJ9mvJjGp7x16lilQOiZIj4z+2o2xsYUEhgTwsKA5WM5GSwnM63nR6wIzVYdTU4t8UiclMkwaCZIFdKMFkYwzM4JNY2xJoOYS2mb9cEyh1weaXs60usY45auY464DoPmWA7Loo0st6s4c9zQOGbwrRD5aJRMLMpwNEx/yOINL09ffpyxYprxYoqcP3bMdXHwezIOGCx3HNsdnXr8mpaPs+6qD1Z0eWY1iGzdupUPfehDDAwMkEwm+fu//3vOOuust8z39a9/nc9+9rP4vs8VV1zBl7/8ZUKh8prVFUQqJDcGv30Ynv4fMPT6Wx+PJiHZAVUNeE4tA8+lSW3ag9c3eshsfiLCWEOYsaTFSMxnpMonE/LJWz4Yg2UZHGNwjcHBwgVcU/r/nI9F3rHIWxZ5G/K2Rc7yiRehMWNoyPgkMz41WUMsZwjlDMZzIObiVYXJVIdJx8MMxl32xCx6Ix69kTz7wuPk7SLGAt8GfzJr2D44k5Ptg20Ove344JjJx3xDxLeJGYtY0SLqWcR8G9eAb9kYCzzbKv0Ny8K3wLctChbkbZ+cZUqXtk9+cira4Dml7836jEPLRJj2XIiODDSl8yRSWarSOZwJA8bCdgxEfAoxyFRHGKuJMlwToS/uMmAbUngUMRQxeBYUHEPWMWRcQ9b1yLoeBdvgOaXcFctbLMqFaSpEacuHWZx1aM5B3YRHfLyANZHH8s1kRrNKzctW6dJM3nY8sAseVt6DvAeejxU2FGMO2bjLWLXLcLVDXwz2Rn2KBqoKIZIZqM1AXcaQHC8SnyjgThRgvIifN5M/JpNNyRZgGWwHLBfskI0VdjBhFz/s4DmGomPwHR/HBsf3CGd93JyHnzelqWjhF238ooXxwA5Z2GEbO+riVYXIVDmMxmzGwh6O5+PmfUIFn1DBECoY3IKP40Eh6pKJh0jFXPrisKvK0BvPs7c6x0SpJZ6IZ9E2EaMrG2Z5xqE9XaRuJEtoJIM3VsT4BsuxSjVEHEzYoRhxyEdcchGXbNhgfJ9IzieU9wnlijjZAnbewy74mKKFKb6pjd0qbUCWa7Bsg+VaWK6NCZXeIxN2yIbDjEVDpEIOfRGL3VGf3liB3bEsqYhXeglzcBtoyDm0ZFyaMxaNGUP9uEdizCM+USQy4RHKGqychcnbGP/QJn3L8XGjPk4MinGHbHWY8ZowI9UhBuIO/Y5hHEPetkqfV8vCYKY+U0zuyijdV9pei7ahaPsUrMltx/LI2x7e5Pbs2aXPtI2FbSwswDEOzmQ7Xum7xsbCwjcevjEUjUfO8ck5PgXbUHRK26PjQbRoU1cM0+A5LCraNGcNDZkCdeN5EuNZ4hN5qnLgFiyKBQvPt/EsCx8bz3ImtxMb2zfYRbA9g+UbvLBFLu4yXu2SjrsMVdkMRgwDUZ/BiE8mYuF4PtWeQ9JzaC5adIzkaRrKUDeSJToOXsahmLEx3tF3lViOP7nNlD4Xxilt+54D2SiMxW2Gq0MMVLvsjdv0xooMxAyjVZCJQHUGmidCxEbzRAsw9vYb+NoH/us0fkymb1aDyBVXXMEtt9zCrbfeyiOPPMJ/+2//jU2bNh0yz44dO3jnO9/Jb37zG5qbm7n++uu56qqr+LM/+7NZWxCZBt+HgVeh52no/RUMboORnoOtJW9iDORGXMb3RxjfHyEzGMbP62hvmRnL9UsdJCZbqkzpV6lCDJYDxptf/RTmLBucCNiuhfHBeAYvRwXXlxyWbeHWVuPWJbBsMLkcfj6HyeXx8wVM3scvmje19M7c//n9Fu783M8r9nowi0Gkr6+P7u5uhoaGcF0XYwytra1s3LiR7u7uqfnuu+8+Xn/9de6//34AfvSjH3HvvfeycePGWVsQmYFCBtJ7YGIIJgYhM3mZGwPbBdvBWA7eeJH8wDjFdJ7ieAFvLI9f8MFywLJLuyUse/L2m/5XZwDjlw4v9ooYr1i69H3saAw7kcBJ1GIna3GStdg1CezqGmwX/MG9eIP78Ab78Ab78YYGKY6M4KVG8UYn8DN5jE/pf1qlXmOlP+tYYNtYjg22hWU7peuOjeUcuO5gOQ44LpbrYrkhrHAYKxTCciebM3yvVK/vg+dhpi690qXnYYql1gLjeRjPn7xeug3gxCO4iSqcZAKnvgF3cSdOezdu5+m4Tc1YoRB+Nos3PIw3NERx/y68/b14A/vwBvshO4bJZ0rvnzGl1/U8/IKHKUxeFkt/E7/UDGtHXJyoi10VwamuwknUlP5+bS12bT1OXQOW6wJ+6T0z3uTr+5OTh+U62NEYVnUSO56AWA1+3pTWwUAf3kA/3uAAxeFhvFQaiyKW5eNUR3Cqo7h1tTiLmnAaW3Cb23GaOrASTRCrg1B06uNnjMHk85ixNH6qHz81gBkdxB8bxXgGvwimaErLZ4exa2txauqwD3xWYjHsiIvl+FiFCUxmFH90EH94AG9wAG94EC+Vxsv52JEYVqwKuyp+8LKqGss2+IP78Ab24g30URwYoDg4THE4RTGVwc+X+tNYjo2TqMKtTeA2NuK2tuEuXoLb2Y3beRpWJIrJZPDHUvipIfzRYfzRkdLt0VH8XB7LdrDj1djxOHayASvRgJ2oL92OxbBiMSzLmvxsFTGFQunHKJvF5PKYzAT+eAqTGcWMj+KPjWDGRjDjI3ipEbzhFMXUKF56Aj9bAMvGcm2wS593Ox7DSdbg1Nbh1NXjLmrCWdSC07QYp3ExTm0tTjKJVVX11g7Mnoc3PExxYABv/y6K+3aV3rP+PryhQUwugylkS33UfFPaTjCl/9kcmA7sRjCm9JBvJuc1b7o+uU37pW3aGKa+UyzLmmwtOvAdM3kba/Ki9KVT2iZK26cp+pOtVTZ22MEKh0uf7Xh88runDru2EbuuESeRxK6uLq2j6jh2OAy2Pfn9lQc/j1XMQcjFDkexolEIRfBTw6X3ZP9uvP79eMNDeOk03ugY/tg4XiaHFQphRyJYkQh2vAa3taP02enoxm1uItTUhFNfX/peOgpjTOlzkcmUtp18Hj+Xx+SyeKlUabvcvwtv/67S98jAAN7ICMX0GH62gFMVwk1WM/ZS6T+hm86LcsvDz5Xzq3FM5fx+u+W8cG9vL62trbhu6WmWZdHZ2UlPT88hQaSnp4clS5ZM3e7q6qKn59jnNsnlcuRyB/cPp9PpcsqT4xWKQcOy0nQEFqUPS1kfGClPe3vQFQTCsiysSAQijTgNjTN8tXqsJDgt4ADBHWO1MNel5Ti4ixbhLloEp58edDknLcuysMJhCIdn9Dobv7GOhs88SEP/sftlzaY51da+bt06ksnk1NTR0RF0SSIiIgtS89t+n6Jd6i8XpLKCSEdHB3v37qVYLPU4NsbQ09NDZ2fnIfN1dnbyxhtvTN3euXPnW+Y5nLVr15JKpaam3t7ecsoTERGRaVp26rmc+ewmrv7nYE/vUVYQaWpq4vzzz+ehhx4C4NFHH6W9vf2Q3TIAN954Ixs2bGDfvn0YY7j//vv5wAc+cMzXj0QiJBKJQyYRERGpPNu2careOlDlCa+j3CesX7+e9evXs3z5cj772c/ywAMPALB69Wo2bNgAwNKlS7nnnnt45zvfSXd3N42NjaxZs6aylYuIiMi8pwHNREREpKLK+f2eU51VRURE5OSiICIiIiKBURARERGRwCiIiIiISGAURERERCQwCiIiIiISGAURERERCYyCiIiIiARGQUREREQCM6fP6n5g0Nd0Oh1wJSIiIjJdB363pzN4+5wOIqOjo0DprL8iIiIyv4yOjpJMJo86z5w+14zv++zZs4eamhosy6roa6fTaTo6Oujt7V2Q57FZ6MsHC38ZtXzz30JfRi3f/Ddby2iMYXR0lMWLF2PbR+8FMqdbRGzbpr29fVb/RiKRWLAfMFj4ywcLfxm1fPPfQl9GLd/8NxvLeKyWkAPUWVVEREQCoyAiIiIigTlpg0gkEuHTn/40kUgk6FJmxUJfPlj4y6jlm/8W+jJq+ea/ubCMc7qzqoiIiCxsJ22LiIiIiARPQUREREQCoyAiIiIigVEQERERkcAoiIiIiEhgFEREREQkMCdlENm6dSsXX3wxy5cvZ9WqVWzZsiXokmYkm83y3ve+l+XLl7NixQre8573sG3bNgDe/e53c8opp7By5UpWrlzJ5z73uYCrPT5dXV2cdtppU8vx7W9/G1g463JwcHBq2VauXMny5ctxXZehoaF5uw7vuOMOurq6sCyLzZs3T91/tHU2n9bn4ZbvaNsizL/t8Ujr8EjbI8z/dXi0bRHm1zo82uexr6+Pq6++mlNPPZWzzz6bJ554Yup5R3tsVpiT0OWXX24eeOABY4wx//iP/2guvPDCYAuaoUwmY374wx8a3/eNMcZ88YtfNJdddpkxxpjLLrvMfPe73w2uuApZsmSJee65595y/0Jblwfcd9995pprrjHGzN91+Pjjj5ve3t63rLujrbP5tD4Pt3xH2xaNmX/r8kjr8EjbozHzfx3+rjdvi8bMr3V4tM/jhz/8YfPpT3/aGGPMM888Y9ra2kw+nz/mY7PhpAsi+/fvNzU1NaZQKBhjjPF93zQ3N5utW7cGXFnlbNq0ySxZssQYM782mqM53BfFQl6Xp59++tR6m+/r8M3r7mjrbL6uz6P9iL15WzRm/q7L6QaRhbgO37wtGjN/16Exh34e4/G42bt379Rjq1atMj/96U+P+dhsOOl2zfT29tLa2orrlk48bFkWnZ2d9PT0BFxZ5Xz+85/n+uuvn7r98Y9/nHPOOYf3v//9bN++PcDKZuaWW27hnHPO4Y//+I/p7+9fsOvyqaeeYnh4mGuuuWbqvoWyDo+2zhbi+vzdbREWzrr83e0RFt736+G2RZi/6/DA53FwcJBCoUBLS8vUY11dXfT09Bz1sdly0gWRhe7ee+9l27ZtrFu3DoBvfOMbvPLKKzz//PO8613vessGNV888cQTPP/88/zmN79h0aJFfOhDHwq6pFnz9a9/nVtuuWXqy3yhrMOTze9ui7Bw1uXJsj3+7rYI83cdHu7zOGfMWlvLHDVfmw6n47777jMXXHCBGR4ePuI8kUjEDAwMnLiiZsGePXtMdXX1glyXo6Ojprq62rz88stHnGe+rcOTcdfMdLZFY+bPujzarosD26Mx8/f79XDLN51t0Zj5sQ4P93msqqo64u6Xoz02G066FpGmpibOP/98HnroIQAeffRR2tvb6e7uDriymfmbv/kbHn74YX76059SW1sLQLFYZP/+/VPzPProozQ3N9PQ0BBQlcdnfHyckZGRqdsPP/ww55133oJcl9/+9rdZsWIFp59+OrBw1uEBR1tnC2V9Hm5bhIWzLo+0PcLC+n793W0R5uc6PNLn8V//63/N/fffD8CmTZvYvXs3l1122TEfmxWzFnHmsFdeecVcdNFF5tRTTzUXXHCBef7554MuaUZ6e3sNYJYuXWpWrFhhVqxYYd72treZsbExc8EFF5izzz7bnHvuueaKK64wmzdvDrrcsr3++utm5cqV5pxzzjFnn322ue6668yOHTuMMQtvXb7jHe8wf/d3fzd1ez6vw9tvv920tbUZx3FMU1OTWbZsmTHm6OtsPq3Pwy3fkbZFY+bnujzcMh5tezRm/q/DA353WzRm/q3Do30e9+3bZ97znveY7u5uc+aZZ5rHHnts6nlHe2w2WMYYM3sxR0REROTITrpdMyIiIjJ3KIiIiIhIYBREREREJDAKIiIiIhIYBREREREJjIKIiIiIBEZBRERERAKjICIiIiKBURARERGRwCiIiIiISGAURERERCQw/xfXrmtCSPRCdAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ts = jnp.linspace(0.0, 200.0, 1024)\n",
    "\n",
    "clip_eval_control = build_control(clip_opt_control, constraint_chain)[0]\n",
    "cont_eval_control = build_control(cont_opt_control, constraint_chain)[0]\n",
    "\n",
    "clip_solution = clip_environment.integrate(\n",
    "    clip_eval_control, clip_environment.init(), None, saveat=diffrax.SaveAt(ts=ts)\n",
    ")\n",
    "cont_solution = cont_environment.integrate(\n",
    "    cont_eval_control, cont_environment.init(), None, saveat=diffrax.SaveAt(ts=ts)\n",
    ")\n",
    "\n",
    "clip_cs = jax.vmap(clip_eval_control)(ts)\n",
    "cont_cs = jax.vmap(cont_eval_control)(ts)\n",
    "\n",
    "plt.figure()\n",
    "#plt.plot(ts, clip_solution.ys)\n",
    "plt.plot(ts, clip_cs)\n",
    "plt.plot(ts, cont_cs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D grid of constant drug integrals with implicit control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "environment: FibrosisEnvironment = FibrosisEnvironment()\n",
    "environment_state = environment.init()\n",
    "\n",
    "solver = solvers.DirectSolver(optimizer=optax.adam(learning_rate=3e-4))\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "control = controls.ImplicitTemporalControl(\n",
    "    implicit_fn=nn.Siren(\n",
    "        in_features=1, out_features=2, hidden_features=64, hidden_layers=2, key=subkey\n",
    "    ),\n",
    "    t_start=0.0,\n",
    "    t_end=200.0,\n",
    "    to_curve=True,\n",
    "    curve_interpolation=\"linear\",\n",
    "    curve_steps=201,\n",
    ")\n",
    "\n",
    "\n",
    "def reward_fn(solution: diffrax.Solution) -> Scalar:\n",
    "    return solution.ys[-1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "def optimize_with_integral(\n",
    "    target_integral: Array,\n",
    ") -> Tuple[Scalar, controls.AbstractControl]:\n",
    "    constraint_chain = constraints.ConstraintChain(\n",
    "        transformations=[\n",
    "            constraints.NonNegativeConstantIntegralConstraint(target=target_integral)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    optimized_reward, optimized_control = trainers.solve_optimal_control_problem(\n",
    "        num_train_steps=256,\n",
    "        environment=environment,\n",
    "        reward_fn=reward_fn,\n",
    "        constraint_chain=constraint_chain,\n",
    "        solver=solver,\n",
    "        control=control,\n",
    "        key=key,\n",
    "        pbar_interval=8,\n",
    "        integrate_kwargs=dict(\n",
    "            dt0=0.01,\n",
    "            max_steps=1000,\n",
    "            throw=False,\n",
    "            stepsize_controller=diffrax.PIDController(\n",
    "                rtol=1e-4, atol=1e-4, pcoeff=1.0, icoeff=1.0, dtmax=1.0\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return optimized_reward, optimized_control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill for loading\n",
    "\n",
    "pdgf_integral = jnp.geomspace(1e-3, 1e0, num=10)\n",
    "csf_integral = jnp.geomspace(1e-3, 1e0, num=10)\n",
    "\n",
    "pdgf_integral, csf_integral = jnp.meshgrid(pdgf_integral, csf_integral)\n",
    "\n",
    "target_integrals = []\n",
    "optimized_rewards = []\n",
    "optimized_controls = []\n",
    "for pdgf, csf in tq(zip(pdgf_integral.flatten(), csf_integral.flatten())):\n",
    "    target_integral = jnp.stack((pdgf, csf))\n",
    "    target_integrals.append(target_integral)\n",
    "    optimized_rewards.append(jnp.nan)\n",
    "    optimized_controls.append(control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdgf_integral = jnp.geomspace(1e-3, 1e0, num=10)\n",
    "csf_integral = jnp.geomspace(1e-3, 1e0, num=10)\n",
    "\n",
    "pdgf_integral, csf_integral = jnp.meshgrid(pdgf_integral, csf_integral)\n",
    "\n",
    "target_integrals = []\n",
    "optimized_rewards = []\n",
    "optimized_controls = []\n",
    "for pdgf, csf in tq(zip(pdgf_integral.flatten(), csf_integral.flatten())):\n",
    "    target_integral = jnp.stack((pdgf, csf))\n",
    "    try:\n",
    "        optimized_reward, optimized_control = optimize_with_integral(target_integral)\n",
    "    except ValueError:\n",
    "        target_integrals.append(target_integral)\n",
    "        optimized_rewards.append(jnp.nan)\n",
    "        optimized_controls.append(control)\n",
    "    else:\n",
    "        target_integrals.append(target_integral)\n",
    "        optimized_rewards.append(optimized_reward)\n",
    "        optimized_controls.append(optimized_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "def evaluate_control(\n",
    "    control: controls.AbstractControl, target_integral: Array\n",
    ") -> controls.AbstractControl:\n",
    "    return build_control(\n",
    "        control,\n",
    "        constraints.ConstraintChain(\n",
    "            transformations=[\n",
    "                constraints.NonNegativeConstantIntegralConstraint(\n",
    "                    target=target_integral\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "    )[0]\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def evaluate_trajectory(\n",
    "    control: controls.AbstractControl, target_integral: Array\n",
    ") -> diffrax.Solution:\n",
    "    return environment.integrate(\n",
    "        evaluate_control(control, target_integral),\n",
    "        environment_state,\n",
    "        None,\n",
    "        saveat=diffrax.SaveAt(dense=True),\n",
    "        max_steps=1000,\n",
    "        throw=False,\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-4, atol=1e-4, pcoeff=1.0, icoeff=1.0, dtmax=1.0\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save & Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    result_base_dir + \"/2d_grid_201steps_3e-4lr_dtmax/target_integrals.eqx\", mode=\"wb\"\n",
    ") as f:\n",
    "    eqx.tree_serialise_leaves(f, target_integrals)\n",
    "\n",
    "with open(\n",
    "    result_base_dir + \"/2d_grid_201steps_3e-4lr_dtmax/optimized_rewards.eqx\", mode=\"wb\"\n",
    ") as f:\n",
    "    eqx.tree_serialise_leaves(f, optimized_rewards)\n",
    "\n",
    "with open(\n",
    "    result_base_dir + \"/2d_grid_201steps_3e-4lr_dtmax/optimized_controls.eqx\", mode=\"wb\"\n",
    ") as f:\n",
    "    eqx.tree_serialise_leaves(f, optimized_controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    result_base_dir + \"/2d_grid_201steps_3e-4lr_dtmax/target_integrals.eqx\", mode=\"rb\"\n",
    ") as f:\n",
    "    target_integrals = eqx.tree_deserialise_leaves(f, target_integrals)\n",
    "\n",
    "with open(\n",
    "    result_base_dir + \"/2d_grid_201steps_3e-4lr_dtmax/optimized_rewards.eqx\", mode=\"rb\"\n",
    ") as f:\n",
    "    optimized_rewards = eqx.tree_deserialise_leaves(f, optimized_rewards)\n",
    "\n",
    "with open(\n",
    "    result_base_dir + \"/2d_grid_201steps_3e-4lr_dtmax/optimized_controls.eqx\", mode=\"rb\"\n",
    ") as f:\n",
    "    optimized_controls = eqx.tree_deserialise_leaves(f, optimized_controls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid_plot(n: int, figsize: Tuple[float]):\n",
    "    # Make grid of plots\n",
    "    fig, ax_grid = plt.subplots(\n",
    "        n + 1,\n",
    "        n + 1,\n",
    "        figsize=figsize,\n",
    "        gridspec_kw=dict(\n",
    "            width_ratios=[0.0] + [1.0] * n, height_ratios=[1.0] * n + [0.0]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Get gridspec\n",
    "    gs = ax_grid[0, 0].get_gridspec()\n",
    "\n",
    "    # Remove left row\n",
    "    for ax in ax_grid[:, 0]:\n",
    "        ax.remove()\n",
    "\n",
    "    # Remove bottom row\n",
    "    for ax in ax_grid[-1, 1:]:\n",
    "        ax.remove()\n",
    "\n",
    "    # Add rows back as single large axis\n",
    "    left_ax = fig.add_subplot(gs[:-1, 0])\n",
    "    bottom_ax = fig.add_subplot(gs[-1, 1:])\n",
    "\n",
    "    # Remove extra axes\n",
    "    left_ax.spines[[\"right\", \"top\", \"bottom\"]].set_visible(False)\n",
    "    left_ax.tick_params(axis=\"x\", bottom=False, labelbottom=False)\n",
    "\n",
    "    bottom_ax.spines[[\"right\", \"left\", \"top\"]].set_visible(False)\n",
    "    bottom_ax.tick_params(axis=\"y\", left=False, labelleft=False)\n",
    "\n",
    "    # Modify main grid\n",
    "    main_ax = ax_grid[:-1, 1:]\n",
    "    main_ax = np.flip(main_ax, axis=0)\n",
    "    base_ax = main_ax[0, 0]\n",
    "\n",
    "    for ax in main_ax.flatten():\n",
    "        if ax != base_ax:\n",
    "            # Share axes\n",
    "            ax.sharex(base_ax)\n",
    "            ax.sharey(base_ax)\n",
    "\n",
    "        # Remove ticks\n",
    "        ax.tick_params(\n",
    "            axis=\"both\", left=False, labelleft=False, bottom=False, labelbottom=False\n",
    "        )\n",
    "\n",
    "    # Unshare axes (deprecated)\n",
    "    \"\"\"\n",
    "    def unshare_axis(grouping, axis):\n",
    "        for sibling in grouping.get_siblings(axis):\n",
    "            grouping.remove(sibling)\n",
    "\n",
    "    def unshare_all(axis):\n",
    "        unshare_axis(axis.get_shared_x_axes(), axis)\n",
    "        unshare_axis(axis.get_shared_y_axes(), axis)\n",
    "\n",
    "    unshare_all(left_ax)\n",
    "    unshare_all(bottom_ax)\n",
    "    \"\"\"\n",
    "\n",
    "    return fig, main_ax, left_ax, bottom_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the seperatrix\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "seperatrix_array = scipy.io.loadmat(\"../data/Separatrix_array_F06_M07.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.logspace(\n",
    "    seperatrix_array[\"lims_F\"][0, 0],\n",
    "    seperatrix_array[\"lims_F\"][0, 1],\n",
    "    seperatrix_array[\"tsteps\"][0, 0],\n",
    ")\n",
    "y = np.logspace(\n",
    "    seperatrix_array[\"lims_M\"][0, 0],\n",
    "    seperatrix_array[\"lims_M\"][0, 1],\n",
    "    seperatrix_array[\"tsteps\"][0, 0],\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.xlabel(\"F\")\n",
    "plt.ylabel(\"M\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.pcolormesh(x, y, 1 - seperatrix_array[\"S\"], cmap=\"Greys\", vmin=0.0, vmax=3.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Trajectories\n",
    "\n",
    "ts = jnp.linspace(0.0, 200.0, 201)\n",
    "\n",
    "fig, main_ax, left_ax, bottom_ax = make_grid_plot(\n",
    "    10, figsize=(plot_half_width, plot_half_width)\n",
    ")\n",
    "\n",
    "left_ax.set_ylabel(\"anti-CSF\")\n",
    "bottom_ax.set_xlabel(\"anti-PDGF\")\n",
    "\n",
    "left_ax.set_yscale(\"log\")\n",
    "left_ax.set_ylim([1e-3, 1e0])\n",
    "\n",
    "bottom_ax.set_xscale(\"log\")\n",
    "bottom_ax.set_xlim([1e-3, 1e0])\n",
    "\n",
    "# main_ax[0, 0].set_xscale(\"log\")\n",
    "# main_ax[0, 0].set_yscale(\"log\")\n",
    "# main_ax[0, 0].set_xlim([1e0, 1e6])\n",
    "# main_ax[0, 0].set_ylim([1e0, 1e7])\n",
    "\n",
    "main_ax[0, 0].set_xlim([0, 6])\n",
    "main_ax[0, 0].set_ylim([0, 7])\n",
    "\n",
    "main_ax[0, 0].set_xlabel(\"F\")\n",
    "main_ax[0, 0].set_ylabel(\"M\")\n",
    "\n",
    "ax = main_ax.flatten()\n",
    "\n",
    "for i in range(100):\n",
    "    try:\n",
    "        if jnp.isnan(optimized_rewards[i]):\n",
    "            raise ValueError\n",
    "\n",
    "        sol = evaluate_trajectory(optimized_controls[i], target_integrals[i])\n",
    "        ys = jax.vmap(sol.evaluate)(ts)\n",
    "        ys = jnp.log10(ys[..., :2])\n",
    "\n",
    "        if jnp.any(jnp.isnan(ys)):\n",
    "            raise ValueError\n",
    "\n",
    "    except (ValueError, AttributeError):\n",
    "        ax[i].set_facecolor(\"red\")\n",
    "    else:\n",
    "        # ax[i].pcolormesh(\n",
    "        #    x, y, 1 - seperatrix_array[\"S\"], cmap=\"Greys\", vmin=0.0, vmax=3.0\n",
    "        # )\n",
    "        ax[i].contourf(\n",
    "            1 - seperatrix_array[\"S\"],\n",
    "            cmap=\"Greys\",\n",
    "            vmin=0.0,\n",
    "            vmax=3.0,\n",
    "            extent=(0, 6, 7, 0),\n",
    "            origin=\"upper\",\n",
    "            levels=1,\n",
    "        )\n",
    "        ax[i].plot(ys[..., 0], ys[..., 1])\n",
    "    finally:\n",
    "        ax[i].tick_params(\n",
    "            axis=\"both\",\n",
    "            which=\"both\",\n",
    "            bottom=False,\n",
    "            left=False,\n",
    "            labelbottom=False,\n",
    "            labelleft=False,\n",
    "        )\n",
    "\n",
    "plt.savefig(\n",
    "    result_base_dir + \"/2d_grid_201steps_3e-4lr_dtmax/system_trajectory_grid.png\",\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.savefig(\n",
    "    result_base_dir + \"/2d_grid_201steps_3e-4lr_dtmax/system_trajectory_grid.svg\",\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control Trajectories\n",
    "\n",
    "ts = jnp.linspace(0.0, 200.0, 201)\n",
    "\n",
    "fig, main_ax, left_ax, bottom_ax = make_grid_plot(\n",
    "    10, figsize=(plot_half_width, plot_half_width)\n",
    ")\n",
    "\n",
    "left_ax.set_ylabel(\"anti-CSF\")\n",
    "bottom_ax.set_xlabel(\"anti-PDGF\")\n",
    "\n",
    "left_ax.set_yscale(\"log\")\n",
    "left_ax.set_ylim([1e-3, 1e0])\n",
    "\n",
    "bottom_ax.set_xscale(\"log\")\n",
    "bottom_ax.set_xlim([1e-3, 1e0])\n",
    "\n",
    "main_ax[0, 0].set_xlabel(\"C\")\n",
    "main_ax[0, 0].set_ylabel(\"T\")\n",
    "\n",
    "ax = main_ax.flatten()\n",
    "\n",
    "for i in range(100):\n",
    "    try:\n",
    "        if jnp.isnan(optimized_rewards[i]):\n",
    "            raise ValueError\n",
    "\n",
    "        sol = evaluate_trajectory(optimized_controls[i], target_integrals[i])\n",
    "        ys = jax.vmap(sol.evaluate)(ts)\n",
    "        ys = jnp.log10(ys[..., :2])\n",
    "\n",
    "        if jnp.any(jnp.isnan(ys)):\n",
    "            raise ValueError\n",
    "\n",
    "        constrained_control = build_control(\n",
    "            optimized_controls[i],\n",
    "            constraints.ConstraintChain(\n",
    "                transformations=[\n",
    "                    constraints.NonNegativeConstantIntegralConstraint(\n",
    "                        target=jnp.ones(2)\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "        )[0]\n",
    "\n",
    "        cs = jax.vmap(constrained_control)(ts.reshape(-1, 1))\n",
    "\n",
    "    except (ValueError, AttributeError):\n",
    "        ax[i].set_facecolor(\"red\")\n",
    "    else:\n",
    "        ax[i].plot(ts, cs[..., 0])\n",
    "        ax[i].plot(ts, cs[..., 1])\n",
    "    finally:\n",
    "        ax[i].tick_params(\n",
    "            axis=\"both\",\n",
    "            which=\"both\",\n",
    "            bottom=False,\n",
    "            left=False,\n",
    "            labelbottom=False,\n",
    "            labelleft=False,\n",
    "        )\n",
    "\n",
    "plt.savefig(\n",
    "    result_base_dir + \"/2d_grid_201steps_3e-4lr_dtmax/control_trajectory_grid.png\",\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.savefig(\n",
    "    result_base_dir + \"/2d_grid_201steps_3e-4lr_dtmax/control_trajectory_grid.svg\",\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from adaptive import Learner2D, notebook_extension\n",
    "from IPython.display import clear_output\n",
    "\n",
    "notebook_extension()\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def final_evaluate_with_integral(\n",
    "    integral: Array, control: controls.AbstractControl\n",
    ") -> Tuple[Scalar, controls.AbstractControl]:\n",
    "    constrained_control = build_control(\n",
    "        control,\n",
    "        constraints.ConstraintChain(\n",
    "            transformations=[\n",
    "                constraints.NonNegativeConstantIntegralConstraint(target=integral)\n",
    "            ]\n",
    "        ),\n",
    "    )[0]\n",
    "\n",
    "    solution = environment.integrate(\n",
    "        constrained_control,\n",
    "        environment_state,\n",
    "        None,\n",
    "        max_steps=10000,\n",
    "        throw=True,\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-4, atol=1e-4, pcoeff=1.0, icoeff=1.0, dtmax=1.0\n",
    "        ),\n",
    "        dt0=0.01,\n",
    "    )\n",
    "\n",
    "    reward = reward_fn(solution)\n",
    "    return reward\n",
    "\n",
    "\n",
    "constant_learner = Learner2D(lambda x: 0, bounds=[(-6, 0), (-3, 3)])\n",
    "constant_learner.stack_size = 1\n",
    "\n",
    "plot_timer = time.time()\n",
    "plot_interval = 15\n",
    "adaptive_results = []\n",
    "while True:\n",
    "    points, _ = constant_learner.ask(1)\n",
    "    point = points[0]\n",
    "\n",
    "    integral = jnp.asarray(point, dtype=jnp.float64)\n",
    "    integral = 10**integral\n",
    "\n",
    "    # Optimize\n",
    "    failed_optimization = True\n",
    "    try:\n",
    "        adaptive_reward, adaptive_control = optimize_with_integral(integral)\n",
    "    except ValueError:\n",
    "        adaptive_reward = jnp.nan\n",
    "        adaptive_control = control\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    else:\n",
    "        failed_optimization = False\n",
    "\n",
    "    # Evaluate final control with higher max_steps, but error when too many steps\n",
    "    # are taken\n",
    "    failed_evaluation = True\n",
    "    if not failed_optimization:\n",
    "        try:\n",
    "            adaptive_reward = final_evaluate_with_integral(integral, adaptive_control)\n",
    "        except ValueError:\n",
    "            adaptive_reward = jnp.nan\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        else:\n",
    "            failed_evaluation = False\n",
    "\n",
    "    constant_learner.tell(point, float(adaptive_reward))\n",
    "    adaptive_results.append(\n",
    "        {\n",
    "            \"point\": point,\n",
    "            \"integral\": integral,\n",
    "            \"reward\": adaptive_reward,\n",
    "            \"control\": adaptive_control,\n",
    "            \"failed_optimization\": failed_optimization,\n",
    "            \"failed_evaluation\": failed_evaluation,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if time.time() - plot_timer >= plot_interval:\n",
    "        plot_timer = time.time()\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(constant_learner.plot(tri_alpha=0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import json\n",
    "from typing import Any\n",
    "import dataclasses\n",
    "\n",
    "\n",
    "class JaxSONEncoder(json.JSONEncoder):\n",
    "    def default(self, o: Any) -> Any:\n",
    "        if dataclasses.is_dataclass(o):\n",
    "            return {\n",
    "                \"__dataclass__\": True,\n",
    "                \"__class_name__\": o.__class__.__module__\n",
    "                + \".\"\n",
    "                + o.__class__.__qualname__,\n",
    "                \"fields\": dataclasses.asdict(o),\n",
    "            }\n",
    "\n",
    "        if isinstance(o, Array):\n",
    "            # Convert to numpy array\n",
    "            o = np.asarray(o)\n",
    "\n",
    "            # Save to memory\n",
    "            buffer = io.BytesIO()\n",
    "            jnp.save(buffer, o, allow_pickle=False)\n",
    "\n",
    "            # Convert the numpy array to a base64 encoded string\n",
    "            data = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "            # Include type annotation and return data\n",
    "            return {\"__numpy_array__\": True, \"data\": data}\n",
    "\n",
    "        # For other types, use the default encoder\n",
    "        return super().default(o)\n",
    "\n",
    "\n",
    "class JaxSONDecoder(json.JSONDecoder):\n",
    "    def __init__(self, dataclass_lookup: dict[str, Any], *args, **kwargs):\n",
    "        super().__init__(object_hook=self.object_hook, *args, **kwargs)\n",
    "\n",
    "        self.dataclass_lookup = dataclass_lookup\n",
    "\n",
    "    def object_hook(self, o: Any) -> Any:\n",
    "        if \"__dataclass__\" in o:\n",
    "            # Construct class instance with __new__\n",
    "            # This allows us to avoid calling __init__, which might be overridden\n",
    "            dataclass_class = self.dataclass_lookup[o[\"__class_name__\"]]\n",
    "            dataclass_instance = dataclass_class.__new__(dataclass_class)\n",
    "\n",
    "            # Replace currently undefined fields with saved fields\n",
    "            dataclass_instance = dataclasses.replace(dataclass_instance, **o[\"fields\"])\n",
    "            return dataclass_instance\n",
    "\n",
    "            # eqx.tree_at(lambda pytree: jax.tree_util.tree_flatten(pytree)[0], dataclass_instance, )\n",
    "\n",
    "        if \"__numpy_array__\" in o:\n",
    "            # Decode the base64 encoded data\n",
    "            data = base64.b64decode(o[\"data\"])\n",
    "\n",
    "            # Load the numpy array\n",
    "            buffer = io.BytesIO(data)\n",
    "            return jnp.load(buffer)\n",
    "\n",
    "        return o\n",
    "\n",
    "\n",
    "jax_json_encoder = JaxSONEncoder(indent=4)\n",
    "json_string = jax_json_encoder.encode(\n",
    "    nn.InterpolationCurve(t_start=0.0, t_end=1.0, steps=64, channels=2)\n",
    "    # eqx.nn.Linear(1, 2, key=jax.random.PRNGKey(1234))\n",
    ")\n",
    "\n",
    "print(json_string)\n",
    "\n",
    "jax_json_decoder = JaxSONDecoder(\n",
    "    dataclass_lookup={\n",
    "        \"optimal_control.nn.InterpolationCurve\": nn.InterpolationCurve,\n",
    "        \"equinox.nn._linear.Linear\": eqx.nn.Linear,\n",
    "    }\n",
    ")\n",
    "jax_json_decoder.decode(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_learner.save(result_base_dir + \"/2d_adaptive/learner.pickle\")\n",
    "eqx.tree_serialise_leaves(\n",
    "    result_base_dir + \"/2d_adaptive/results.eqx\", adaptive_results\n",
    ")\n",
    "\n",
    "with open(result_base_dir + \"/2d_adaptive/results.jxson\", mode=\"w\") as f:\n",
    "    json.dump(adaptive_results, f, cls=JaxSONEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptive import Learner2D, notebook_extension\n",
    "\n",
    "notebook_extension()\n",
    "\n",
    "constant_learner = Learner2D(lambda x: 0, bounds=[(-6, 0), (-3, 3)])\n",
    "constant_learner.stack_size = 1\n",
    "\n",
    "constant_learner.load(result_base_dir + \"/2d_adaptive/learner.pickle\")\n",
    "\n",
    "# with open(result_base_dir + \"/2d_adaptive/results.jxson\", mode=\"r\") as f:\n",
    "#    adaptive_results = json.load(f, cls=JaxSONDecoder, dataclass_lookup={\"optimal_control.nn.InterpolationCurve\": nn.InterpolationCurve, \"optimal_control.nn.\": controls.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "pdgf, csf, reward = constant_learner.interpolated_on_grid()\n",
    "\n",
    "plt.figure(\n",
    "    figsize=(plot_half_width * plot_shrink_factor, plot_half_width * plot_shrink_factor)\n",
    ")\n",
    "plt.imshow(\n",
    "    reward.T,\n",
    "    cmap=\"inferno\",\n",
    "    extent=(pdgf[0], pdgf[-1], csf[0], csf[-1]),\n",
    "    origin=\"lower\",\n",
    ")\n",
    "plt.xlabel(\"log10 anti-PDGF\")\n",
    "plt.ylabel(\"log10 anti-CSF\")\n",
    "plt.colorbar(fraction=0.04575, pad=0.04, label=\"Reward\")\n",
    "plt.savefig(\n",
    "    result_base_dir + \"/2d_adaptive/optimized_adaptive_grid.png\", bbox_inches=\"tight\"\n",
    ")\n",
    "plt.savefig(\n",
    "    result_base_dir + \"/2d_adaptive/optimized_adaptive_grid.svg\", bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from adaptive import Learner2D, notebook_extension\n",
    "from IPython.display import clear_output\n",
    "\n",
    "notebook_extension()\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def evaluate_with_integral(integral: Array) -> Tuple[Scalar, controls.AbstractControl]:\n",
    "    constant_control = controls.LambdaControl(lambda _, c: c, data=integral)\n",
    "\n",
    "    solution = environment.integrate(\n",
    "        constant_control,\n",
    "        environment_state,\n",
    "        None,\n",
    "        max_steps=10000,\n",
    "        throw=True,\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-4, atol=1e-4, pcoeff=1.0, icoeff=1.0, dtmax=1.0\n",
    "        ),\n",
    "        dt0=0.01,\n",
    "    )\n",
    "\n",
    "    reward = reward_fn(solution)\n",
    "    return reward\n",
    "\n",
    "\n",
    "constant_learner = Learner2D(lambda x: 0, bounds=[(-6, 0), (-3, 3)])\n",
    "constant_learner.stack_size = 1\n",
    "\n",
    "plot_timer = time.time()\n",
    "plot_interval = 15\n",
    "adaptive_results = []\n",
    "while True:\n",
    "    points, _ = constant_learner.ask(1)\n",
    "    point = points[0]\n",
    "\n",
    "    integral = jnp.asarray(point, dtype=jnp.float64)\n",
    "    integral = 10**integral\n",
    "\n",
    "    # Evaluate\n",
    "    failed_evaluation = True\n",
    "    try:\n",
    "        adaptive_reward = evaluate_with_integral(integral)\n",
    "    except ValueError:\n",
    "        adaptive_reward = jnp.nan\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    else:\n",
    "        failed_evaluation = False\n",
    "\n",
    "    constant_learner.tell(point, float(adaptive_reward))\n",
    "    adaptive_results.append(\n",
    "        {\n",
    "            \"point\": point,\n",
    "            \"integral\": integral,\n",
    "            \"reward\": adaptive_reward,\n",
    "            \"failed_evaluation\": failed_evaluation,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if time.time() - plot_timer >= plot_interval:\n",
    "        plot_timer = time.time()\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(constant_learner.plot(tri_alpha=0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_learner.save(result_base_dir + \"/2d_adaptive/constant_learner.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "\n",
    "from adaptive import Learner2D, notebook_extension\n",
    "\n",
    "notebook_extension()\n",
    "\n",
    "constant_learner = Learner2D(lambda x: 0, bounds=[(-6, 0), (-3, 3)])\n",
    "constant_learner.stack_size = 1\n",
    "\n",
    "constant_learner.load(result_base_dir + \"/2d_adaptive/constant_learner.pickle\")\n",
    "\n",
    "# Plot\n",
    "\n",
    "pdgf, csf, reward = constant_learner.interpolated_on_grid()\n",
    "\n",
    "plt.figure(\n",
    "    figsize=(plot_half_width * plot_shrink_factor, plot_half_width * plot_shrink_factor)\n",
    ")\n",
    "plt.imshow(\n",
    "    reward.T,\n",
    "    cmap=\"inferno\",\n",
    "    extent=(pdgf[0], pdgf[-1], csf[0], csf[-1]),\n",
    "    origin=\"lower\",\n",
    ")\n",
    "plt.xlabel(\"log10 anti-PDGF\")\n",
    "plt.ylabel(\"log10 anti-CSF\")\n",
    "plt.colorbar(fraction=0.04575, pad=0.04, label=\"Reward\")\n",
    "plt.savefig(\n",
    "    result_base_dir + \"/2d_adaptive/constant_adaptive_grid.png\", bbox_inches=\"tight\"\n",
    ")\n",
    "plt.savefig(\n",
    "    result_base_dir + \"/2d_adaptive/constant_adaptive_grid.svg\", bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "\n",
    "from adaptive import Learner2D, notebook_extension\n",
    "from resize_right import resize, interp_methods\n",
    "\n",
    "notebook_extension()\n",
    "\n",
    "constant_learner = Learner2D(lambda x: 0, bounds=[(-6, 0), (-3, 3)])\n",
    "constant_learner.stack_size = 1\n",
    "\n",
    "constant_learner.load(result_base_dir + \"/2d_adaptive/constant_learner.pickle\")\n",
    "\n",
    "optimal_learner = Learner2D(lambda x: 0, bounds=[(-6, 0), (-3, 3)])\n",
    "optimal_learner.stack_size = 1\n",
    "\n",
    "optimal_learner.load(result_base_dir + \"/2d_adaptive/learner.pickle\")\n",
    "\n",
    "# Plot\n",
    "\n",
    "pdgf, csf, constant_reward = constant_learner.interpolated_on_grid()\n",
    "pdgf, csf, optimal_reward = optimal_learner.interpolated_on_grid()\n",
    "\n",
    "difference_reward = optimal_reward - resize(\n",
    "    constant_reward,\n",
    "    out_shape=optimal_reward.shape,\n",
    "    interp_method=interp_methods.linear,\n",
    "    pad_mode=\"edge\",\n",
    ")\n",
    "\n",
    "plt.figure(\n",
    "    figsize=(plot_half_width * plot_shrink_factor, plot_half_width * plot_shrink_factor)\n",
    ")\n",
    "plt.imshow(\n",
    "    difference_reward.T,\n",
    "    cmap=\"inferno\",\n",
    "    extent=(pdgf[0], pdgf[-1], csf[0], csf[-1]),\n",
    "    origin=\"lower\",\n",
    ")\n",
    "plt.xlabel(\"log10 anti-PDGF\")\n",
    "plt.ylabel(\"log10 anti-CSF\")\n",
    "plt.colorbar(fraction=0.04575, pad=0.04, label=\"Advantage\")\n",
    "plt.savefig(\n",
    "    result_base_dir + \"/2d_adaptive/difference_adaptive_grid.png\", bbox_inches=\"tight\"\n",
    ")\n",
    "plt.savefig(\n",
    "    result_base_dir + \"/2d_adaptive/difference_adaptive_grid.svg\", bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D line of constant sum drug integrals with implicit control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "environment: FibrosisEnvironment = FibrosisEnvironment()\n",
    "environment_state = environment.init()\n",
    "\n",
    "solver = solvers.DirectSolver(optimizer=optax.adam(learning_rate=3e-4))\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "control = controls.ImplicitTemporalControl(\n",
    "    implicit_fn=nn.Siren(\n",
    "        in_features=1, out_features=2, hidden_features=64, hidden_layers=2, key=subkey\n",
    "    ),\n",
    "    t_start=0.0,\n",
    "    t_end=200.0,\n",
    "    to_curve=True,\n",
    "    curve_interpolation=\"linear\",\n",
    "    curve_steps=201,\n",
    ")\n",
    "\n",
    "\n",
    "def reward_fn(solution: diffrax.Solution) -> Scalar:\n",
    "    return solution.ys[-1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "def optimize_with_integral(\n",
    "    target_integral: Array,\n",
    ") -> Tuple[Scalar, controls.AbstractControl]:\n",
    "    constraint_chain = constraints.ConstraintChain(\n",
    "        transformations=[\n",
    "            constraints.NonNegativeConstantIntegralConstraint(\n",
    "                target=target_integral, constrain_sum=True\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    optimized_reward, optimized_control = trainers.solve_optimal_control_problem(\n",
    "        num_train_steps=256,\n",
    "        environment=environment,\n",
    "        reward_fn=reward_fn,\n",
    "        constraint_chain=constraint_chain,\n",
    "        solver=solver,\n",
    "        control=control,\n",
    "        key=key,\n",
    "        pbar_interval=8,\n",
    "        integrate_kwargs=dict(\n",
    "            dt0=0.01,\n",
    "            max_steps=1000,\n",
    "            throw=False,\n",
    "            stepsize_controller=diffrax.PIDController(\n",
    "                rtol=1e-4, atol=1e-4, pcoeff=1.0, icoeff=1.0, dtmax=1.0\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return optimized_reward, optimized_control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from adaptive import Learner1D, notebook_extension\n",
    "from IPython.display import clear_output\n",
    "\n",
    "notebook_extension()\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def final_evaluate_with_integral(\n",
    "    integral: Array, control: controls.AbstractControl\n",
    ") -> Tuple[Scalar, controls.AbstractControl]:\n",
    "    constrained_control = build_control(\n",
    "        control,\n",
    "        constraints.ConstraintChain(\n",
    "            transformations=[\n",
    "                constraints.NonNegativeConstantIntegralConstraint(\n",
    "                    target=integral, constrain_sum=True\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "    )[0]\n",
    "\n",
    "    solution = environment.integrate(\n",
    "        constrained_control,\n",
    "        environment_state,\n",
    "        None,\n",
    "        max_steps=10000,\n",
    "        throw=True,\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-4, atol=1e-4, pcoeff=1.0, icoeff=1.0, dtmax=1.0\n",
    "        ),\n",
    "        dt0=0.01,\n",
    "    )\n",
    "\n",
    "    reward = reward_fn(solution)\n",
    "    return reward\n",
    "\n",
    "\n",
    "constant_learner = Learner1D(lambda x: 0, bounds=(-6, 6))\n",
    "constant_learner.stack_size = 1\n",
    "\n",
    "start_time = time.time()\n",
    "max_time = 15 * 60\n",
    "\n",
    "plot_timer = time.time()\n",
    "plot_interval = 15\n",
    "adaptive_results = []\n",
    "while time.time() - start_time < max_time:\n",
    "    points, _ = constant_learner.ask(1)\n",
    "    point = points[0]\n",
    "\n",
    "    integral = jnp.asarray([point], dtype=jnp.float64)\n",
    "    integral = 10**integral\n",
    "\n",
    "    # Optimize\n",
    "    failed_optimization = True\n",
    "    try:\n",
    "        adaptive_reward, adaptive_control = optimize_with_integral(integral)\n",
    "    except ValueError:\n",
    "        adaptive_reward = jnp.nan\n",
    "        adaptive_control = control\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    else:\n",
    "        failed_optimization = False\n",
    "\n",
    "    # Evaluate final control with higher max_steps, but error when too many steps\n",
    "    # are taken\n",
    "    failed_evaluation = True\n",
    "    if not failed_optimization:\n",
    "        try:\n",
    "            adaptive_reward = final_evaluate_with_integral(integral, adaptive_control)\n",
    "        except ValueError:\n",
    "            adaptive_reward = jnp.nan\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        else:\n",
    "            failed_evaluation = False\n",
    "\n",
    "    constant_learner.tell(point, float(adaptive_reward))\n",
    "    adaptive_results.append(\n",
    "        {\n",
    "            \"point\": point,\n",
    "            \"integral\": integral,\n",
    "            \"reward\": adaptive_reward,\n",
    "            \"control\": adaptive_control,\n",
    "            \"failed_optimization\": failed_optimization,\n",
    "            \"failed_evaluation\": failed_evaluation,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if time.time() - plot_timer >= plot_interval:\n",
    "        plot_timer = time.time()\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(constant_learner.plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "\n",
    "constant_learner.save(result_base_dir + \"/1d_adaptive/optimal_learner.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "\n",
    "import time\n",
    "\n",
    "from adaptive import Learner1D, notebook_extension\n",
    "from IPython.display import clear_output\n",
    "\n",
    "notebook_extension()\n",
    "\n",
    "optimal_learner = Learner1D(lambda x: 0, bounds=(-6, 6))\n",
    "optimal_learner.stack_size = 1\n",
    "\n",
    "optimal_learner.load(result_base_dir + \"/1d_adaptive/optimal_learner.pickle\")\n",
    "\n",
    "# Plot\n",
    "\n",
    "points = optimal_learner.to_numpy()\n",
    "argsort = np.argsort(points[..., 0])\n",
    "points = points[argsort]\n",
    "\n",
    "plt.figure(\n",
    "    figsize=(plot_half_width * plot_shrink_factor, plot_half_width * plot_shrink_factor)\n",
    ")\n",
    "plt.xlabel(\"log10(PDGF + CSFG)\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.plot(*points.T)\n",
    "plt.xlim([-3, 1])\n",
    "plt.savefig(\n",
    "    result_base_dir + \"/1d_adaptive/optimal_adaptive_interval.png\", bbox_inches=\"tight\"\n",
    ")\n",
    "plt.savefig(\n",
    "    result_base_dir + \"/1d_adaptive/optimal_adaptive_interval.svg\", bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from adaptive import Learner1D, notebook_extension\n",
    "from IPython.display import clear_output\n",
    "\n",
    "notebook_extension()\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def evaluate_with_integral(integral: Array) -> Tuple[Scalar, controls.AbstractControl]:\n",
    "    constant_control = controls.LambdaControl(\n",
    "        lambda _, c: c, data=jnp.repeat(integral, 2) / 2\n",
    "    )\n",
    "\n",
    "    solution = environment.integrate(\n",
    "        constant_control,\n",
    "        environment_state,\n",
    "        None,\n",
    "        max_steps=10000,\n",
    "        throw=True,\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-4, atol=1e-4, pcoeff=1.0, icoeff=1.0, dtmax=1.0\n",
    "        ),\n",
    "        dt0=0.01,\n",
    "    )\n",
    "\n",
    "    reward = reward_fn(solution)\n",
    "    return reward\n",
    "\n",
    "\n",
    "evaluate_with_integral(jnp.asarray([1.0]))  # Force compile\n",
    "\n",
    "constant_learner = Learner1D(lambda x: 0, bounds=(-6, 6))\n",
    "constant_learner.stack_size = 1\n",
    "\n",
    "start_time = time.time()\n",
    "max_time = 15\n",
    "\n",
    "plot_timer = time.time()\n",
    "plot_interval = 15\n",
    "adaptive_results = []\n",
    "while time.time() - start_time < max_time:\n",
    "    points, _ = constant_learner.ask(1)\n",
    "    point = points[0]\n",
    "\n",
    "    integral = jnp.asarray([point], dtype=jnp.float64)\n",
    "    integral = 10**integral\n",
    "\n",
    "    # Evaluate\n",
    "    failed_evaluation = True\n",
    "    if not failed_optimization:\n",
    "        try:\n",
    "            adaptive_reward = evaluate_with_integral(integral)\n",
    "        except ValueError:\n",
    "            adaptive_reward = jnp.nan\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        else:\n",
    "            failed_evaluation = False\n",
    "\n",
    "    constant_learner.tell(point, float(adaptive_reward))\n",
    "    adaptive_results.append(\n",
    "        {\n",
    "            \"point\": point,\n",
    "            \"integral\": integral,\n",
    "            \"reward\": adaptive_reward,\n",
    "            \"failed_evaluation\": failed_evaluation,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if time.time() - plot_timer >= plot_interval:\n",
    "        plot_timer = time.time()\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(constant_learner.plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "\n",
    "constant_learner.save(result_base_dir + \"/1d_adaptive/constant_learner.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "\n",
    "from adaptive import Learner1D, notebook_extension\n",
    "from IPython.display import clear_output\n",
    "\n",
    "notebook_extension()\n",
    "\n",
    "constant_learner = Learner1D(lambda x: 0, bounds=(-6, 6))\n",
    "constant_learner.stack_size = 1\n",
    "\n",
    "constant_learner.load(result_base_dir + \"/1d_adaptive/constant_learner.pickle\")\n",
    "\n",
    "# Plot\n",
    "\n",
    "points = constant_learner.to_numpy()\n",
    "argsort = np.argsort(points[..., 0])\n",
    "points = points[argsort]\n",
    "\n",
    "plt.figure(\n",
    "    figsize=(plot_half_width * plot_shrink_factor, plot_half_width * plot_shrink_factor)\n",
    ")\n",
    "plt.xlabel(\"log10(PDGF + CSFG)\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.plot(*points.T)\n",
    "plt.xlim([-3, 1])\n",
    "plt.savefig(\n",
    "    result_base_dir + \"/1d_adaptive/constant_adaptive_interval.png\", bbox_inches=\"tight\"\n",
    ")\n",
    "plt.savefig(\n",
    "    result_base_dir + \"/1d_adaptive/constant_adaptive_interval.svg\", bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "\n",
    "from adaptive import Learner1D, notebook_extension\n",
    "from IPython.display import clear_output\n",
    "\n",
    "notebook_extension()\n",
    "\n",
    "constant_learner = Learner1D(lambda x: 0, bounds=(-6, 6))\n",
    "constant_learner.stack_size = 1\n",
    "\n",
    "constant_learner.load(result_base_dir + \"/1d_adaptive/constant_learner.pickle\")\n",
    "\n",
    "optimal_learner = Learner1D(lambda x: 0, bounds=(-6, 6))\n",
    "optimal_learner.stack_size = 1\n",
    "\n",
    "optimal_learner.load(result_base_dir + \"/1d_adaptive/optimal_learner.pickle\")\n",
    "\n",
    "# Plot\n",
    "\n",
    "constant_points = constant_learner.to_numpy()\n",
    "optimal_points = optimal_learner.to_numpy()\n",
    "\n",
    "x = np.linspace(-3, 1, 256)\n",
    "points = np.interp(x, optimal_points[..., 0], optimal_points[..., 1]) - np.interp(\n",
    "    x, constant_points[..., 0], constant_points[..., 1]\n",
    ")\n",
    "\n",
    "plt.figure(\n",
    "    figsize=(plot_half_width * plot_shrink_factor, plot_half_width * plot_shrink_factor)\n",
    ")\n",
    "plt.xlabel(\"log10(PDGF + CSFG)\")\n",
    "plt.ylabel(\"Advantage\")\n",
    "plt.plot(x, points)\n",
    "plt.xlim([-3, 1])\n",
    "plt.savefig(\n",
    "    result_base_dir + \"/1d_adaptive/difference_adaptive_interval.png\",\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.savefig(\n",
    "    result_base_dir + \"/1d_adaptive/difference_adaptive_interval.svg\",\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39-optimal-control-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
