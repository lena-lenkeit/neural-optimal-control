{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import Tuple\n",
    "\n",
    "import diffrax\n",
    "import equinox as eqx\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optax\n",
    "from jaxtyping import Array, PyTree, Scalar\n",
    "from tqdm.auto import tqdm as tq\n",
    "\n",
    "import optimal_control.constraints as constraints\n",
    "import optimal_control.controls as controls\n",
    "import optimal_control.environments.examples as examples\n",
    "import optimal_control.nn as nn\n",
    "import optimal_control.solvers as solvers\n",
    "import optimal_control.trainers as trainers\n",
    "from optimal_control.environments.examples.fibrosis2 import (\n",
    "    FibrosisEnvironment,\n",
    "    FibrosisState,\n",
    ")\n",
    "from optimal_control.solvers.base import build_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a4_inches = (8.3, 11.7)\n",
    "plot_full_width = a4_inches[0]\n",
    "plot_half_width = a4_inches[0] / 2\n",
    "plot_third_width = a4_inches[0] / 3\n",
    "plot_quarter_width = a4_inches[0] / 4\n",
    "\n",
    "result_base_dir = \"../thesis-results/fibrosis\"\n",
    "plot_style = \"seaborn-paper\"\n",
    "\n",
    "plot_styles = [\"seaborn-v0_8-paper\", \"seaborn-v0_8-talk\"]\n",
    "plot_style_names = [\"\", \"_talk\"]\n",
    "\n",
    "plot_shrink_factor = 0.9\n",
    "\n",
    "plt.style.use(plot_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(save_postfix: str, save_prefix: str = None):\n",
    "    if save_prefix is not None:\n",
    "        plt.savefig(result_base_dir + save_prefix + save_postfix + \".png\", bbox_inches=\"tight\")\n",
    "        plt.savefig(result_base_dir + save_prefix + save_postfix + \".svg\", bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def styles(plot_fn):\n",
    "    for style, name in zip(plot_styles, plot_style_names):\n",
    "        with plt.style.context(style):\n",
    "            plot_fn(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(path: str, **kwargs):\n",
    "    with open(result_base_dir + path, mode=\"wb\") as f:\n",
    "        pickle.dump(kwargs, f)\n",
    "\n",
    "\n",
    "def load(path: str):\n",
    "    with open(result_base_dir + path, mode=\"rb\") as f:\n",
    "        return pickle.load(f).values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find optimal PI settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = FibrosisEnvironment()\n",
    "state = environment.init()\n",
    "\n",
    "constraint_chain = constraints.ConstraintChain(\n",
    "    transformations=[\n",
    "        constraints.NonNegativeConstantIntegralConstraint(\n",
    "            target=jnp.asarray([0.01, 0.01])\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "control = controls.InterpolationCurveControl(\n",
    "    nn.InterpolationCurve(\n",
    "        method=\"linear\",\n",
    "        nodes=(jax.random.uniform(jax.random.PRNGKey(1234), (16, 2)) + 1) * 0.01,\n",
    "        t_start=0.0 - 1,\n",
    "        t_end=200.0 + 1,\n",
    "        steps=16,\n",
    "        channels=2,\n",
    "    )\n",
    ")\n",
    "\n",
    "constrained_control = build_control(control, constraint_chain)[0]\n",
    "\"\"\"\n",
    "\n",
    "constrained_control = controls.LambdaControl(lambda _: jnp.full(2, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def with_coeff(\n",
    "    pcoeff: Scalar, icoeff: Scalar, rtol: Scalar, atol: Scalar, dtmax: Scalar\n",
    ") -> int:\n",
    "    solution: diffrax.Solution = environment.integrate(\n",
    "        constrained_control,\n",
    "        state,\n",
    "        None,\n",
    "        throw=False,\n",
    "        max_steps=10000,\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=rtol, atol=atol, pcoeff=pcoeff, icoeff=icoeff, dtmax=dtmax\n",
    "        ),\n",
    "    )\n",
    "    return solution.stats, solution.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcoeff = jnp.linspace(0.0, 1.0, 64)\n",
    "icoeff = jnp.linspace(0.0, 1.0, 64)\n",
    "\n",
    "pcoeff, icoeff = jnp.meshgrid(pcoeff, icoeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_stats = []\n",
    "coeff_results = []\n",
    "for p, i in tq(\n",
    "    zip(pcoeff.flatten(), icoeff.flatten()), total=pcoeff.flatten().shape[0]\n",
    "):\n",
    "    stats, adaptive_results = with_coeff(p, i, 1e-4, 1e-4, 1.0)\n",
    "\n",
    "    coeff_stats.append(stats)\n",
    "    coeff_results.append(adaptive_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_nodtmax_stats = []\n",
    "coeff_nodtmax_results = []\n",
    "for p, i in tq(\n",
    "    zip(pcoeff.flatten(), icoeff.flatten()), total=pcoeff.flatten().shape[0]\n",
    "):\n",
    "    stats, adaptive_results = with_coeff(p, i, 1e-4, 1e-4, None)\n",
    "\n",
    "    coeff_nodtmax_stats.append(stats)\n",
    "    coeff_nodtmax_results.append(adaptive_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_min_idx = np.argmin([stats[\"num_steps\"] for stats in coeff_stats])\n",
    "coeff_stats[coeff_min_idx], pcoeff.flatten()[coeff_min_idx], icoeff.flatten()[\n",
    "    coeff_min_idx\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atol = jnp.geomspace(1e-1, 1e-8, 64)\n",
    "rtol = jnp.geomspace(1e-1, 1e-8, 64)\n",
    "\n",
    "atol, rtol = jnp.meshgrid(atol, rtol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol_stats = []\n",
    "tol_results = []\n",
    "for a, r in tq(zip(atol.flatten(), rtol.flatten()), total=atol.flatten().shape[0]):\n",
    "    stats, adaptive_results = with_coeff(1.0, 1.0, r, a, 1.0)\n",
    "\n",
    "    tol_stats.append(stats)\n",
    "    tol_results.append(adaptive_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol_nodtmax_stats = []\n",
    "tol_nodtmax_results = []\n",
    "for a, r in tq(zip(atol.flatten(), rtol.flatten()), total=atol.flatten().shape[0]):\n",
    "    stats, adaptive_results = with_coeff(1.0, 1.0, r, a, None)\n",
    "\n",
    "    tol_nodtmax_stats.append(stats)\n",
    "    tol_nodtmax_results.append(adaptive_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol_min_idx = np.argmin([stats[\"num_steps\"] for stats in tol_stats])\n",
    "tol_stats[tol_min_idx], rtol.flatten()[tol_min_idx], atol.flatten()[tol_min_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(\n",
    "    \"/pid_callibration/pcoeff_icoeff_sweep.pickle\",\n",
    "    coeff_stats=coeff_stats,\n",
    "    coeff_results=coeff_results,\n",
    ")\n",
    "\n",
    "save(\n",
    "    \"/pid_callibration/atol_rtol_sweep.pickle\",\n",
    "    tol_stats=tol_stats,\n",
    "    tol_results=tol_results,\n",
    ")\n",
    "\n",
    "save(\n",
    "    \"/pid_callibration/pcoeff_icoeff_nodtmax_sweep.pickle\",\n",
    "    coeff_nodtmax_stats=coeff_nodtmax_stats,\n",
    "    coeff_nodtmax_results=coeff_results,\n",
    ")\n",
    "\n",
    "save(\n",
    "    \"/pid_callibration/atol_rtol_nodtmax_sweep.pickle\",\n",
    "    tol_nodtmax_stats=tol_nodtmax_stats,\n",
    "    tol_nodtmax_results=tol_nodtmax_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_stats, coeff_results = load(\"/pid_callibration/pcoeff_icoeff_sweep.pickle\")\n",
    "tol_stats, tol_results = load(\"/pid_callibration/atol_rtol_sweep.pickle\")\n",
    "\n",
    "coeff_nodtmax_stats, coeff_nodtmax_results = load(\n",
    "    \"/pid_callibration/pcoeff_icoeff_nodtmax_sweep.pickle\"\n",
    ")\n",
    "tol_nodtmax_stats, tol_nodtmax_results = load(\n",
    "    \"/pid_callibration/atol_rtol_nodtmax_sweep.pickle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fudge_factor = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coeff(coeff_stats: dict, fig_path: str):\n",
    "    plt.figure(figsize=(plot_half_width * fudge_factor, plot_half_width * fudge_factor))\n",
    "\n",
    "    plt.xlabel(\"Proportional Coeff.\")\n",
    "    plt.ylabel(\"Integral Coeff.\")\n",
    "\n",
    "    cmap = matplotlib.colormaps[\"viridis\"]\n",
    "    cmap.set_bad(color=\"red\")\n",
    "\n",
    "    plt.imshow(\n",
    "        np.reshape(\n",
    "            [\n",
    "                stats[\"num_steps\"]\n",
    "                if stats[\"num_steps\"] < stats[\"max_steps\"]\n",
    "                else np.NaN\n",
    "                for stats in coeff_stats\n",
    "            ],\n",
    "            (64, 64),\n",
    "        ),\n",
    "        cmap=cmap,\n",
    "        norm=\"log\",\n",
    "        origin=\"lower\",\n",
    "        interpolation=\"nearest\",\n",
    "        extent=(\n",
    "            pcoeff.flatten()[0],\n",
    "            pcoeff.flatten()[-1],\n",
    "            icoeff.flatten()[0],\n",
    "            icoeff.flatten()[-1],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    cbar = plt.colorbar(label=\"Num. Integration Steps\", fraction=0.04575, pad=0.04)\n",
    "    plt.scatter([0.99], [0.99], c=\"white\", marker=\"X\")\n",
    "\n",
    "    plt.savefig(result_base_dir + fig_path + \".png\", bbox_inches=\"tight\")\n",
    "    plt.savefig(result_base_dir + fig_path + \".svg\", bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_coeff(coeff_stats, \"/pid_callibration/pcoeff_icoeff_sweep\")\n",
    "plot_coeff(coeff_nodtmax_stats, \"/pid_callibration/pcoeff_icoeff_nodtmax_sweep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tol(tol_stats: dict, fig_path: str):\n",
    "    plt.figure(figsize=(plot_half_width * fudge_factor, plot_half_width * fudge_factor))\n",
    "\n",
    "    plt.xlabel(\"Absolute Tolerance\")\n",
    "    plt.ylabel(\"Relative Tolerance\")\n",
    "\n",
    "    cmap = matplotlib.colormaps[\"viridis\"]\n",
    "    cmap.set_bad(color=\"red\")\n",
    "\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "\n",
    "    plt.pcolormesh(\n",
    "        atol,\n",
    "        rtol,\n",
    "        np.reshape(\n",
    "            [\n",
    "                stats[\"num_steps\"]\n",
    "                if stats[\"num_steps\"] < stats[\"max_steps\"]\n",
    "                else np.NaN\n",
    "                for stats in tol_stats\n",
    "            ],\n",
    "            (64, 64),\n",
    "        ),\n",
    "        cmap=cmap,\n",
    "        norm=\"log\",\n",
    "    )\n",
    "\n",
    "    cbar = plt.colorbar(label=\"Num. Integration Steps\", fraction=0.049, pad=0.04)\n",
    "    plt.scatter([1e-4], [1e-4], c=\"white\", marker=\"X\")\n",
    "\n",
    "    plt.savefig(result_base_dir + fig_path + \".png\", bbox_inches=\"tight\")\n",
    "    plt.savefig(result_base_dir + fig_path + \".svg\", bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_tol(tol_stats, \"/pid_callibration/rtol_atol_sweep\")\n",
    "plot_tol(tol_nodtmax_stats, \"/pid_callibration/rtol_atol_nodtmax_sweep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InterpolationCurve Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimal_control.environments.examples.fibrosis2 import (\n",
    "    FibrosisEnvironment,\n",
    "    FibrosisState,\n",
    ")\n",
    "\n",
    "environment = FibrosisEnvironment()\n",
    "environment_state = environment.init()\n",
    "\n",
    "constraint_chain = constraints.ConstraintChain(\n",
    "    transformations=[\n",
    "        constraints.NonNegativeConstantIntegralConstraint(\n",
    "            # target=jnp.asarray([0.01, 0.01])\n",
    "            target=jnp.asarray([0.1]),\n",
    "            constrain_sum=True,\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def reward_fn(solution: diffrax.Solution) -> Scalar:\n",
    "    return solution.ys[-1, -1]\n",
    "    # return -jnp.mean(jnp.log(jnp.clip(solution.ys[..., :2], a_min=1e2)))\n",
    "\n",
    "\n",
    "control = controls.InterpolationCurveControl(\n",
    "    nn.InterpolationCurve(\n",
    "        method=\"linear\",\n",
    "        # nodes=jax.random.normal(jax.random.PRNGKey(1234), (16, 2)),\n",
    "        t_start=0.0,\n",
    "        t_end=200.0,\n",
    "        steps=201,\n",
    "        channels=2,\n",
    "    )\n",
    ")\n",
    "solver = solvers.DirectSolver(\n",
    "    optimizer=optax.adam(learning_rate=1e-3), ignore_nans=False\n",
    ")\n",
    "\n",
    "key = jax.random.PRNGKey(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_reward, optimized_control = trainers.solve_optimal_control_problem(\n",
    "    num_train_steps=256,\n",
    "    environment=environment,\n",
    "    reward_fn=reward_fn,\n",
    "    constraint_chain=constraint_chain,\n",
    "    solver=solver,\n",
    "    control=control,\n",
    "    key=key,\n",
    "    pbar_interval=8,\n",
    "    integrate_kwargs=dict(\n",
    "        max_steps=1000,\n",
    "        throw=True,\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-4, atol=1e-4, pcoeff=1.0, icoeff=1.0, dtmax=1.0\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constrained_control = build_control(optimized_control, constraint_chain)[0]\n",
    "\n",
    "ts = jnp.linspace(-10.0, 210.0, 1024)\n",
    "ys = jax.vmap(constrained_control)(ts)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ts, ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = jnp.linspace(0.0, 200.0, 1024)\n",
    "\n",
    "constrained_control = build_control(optimized_control, constraint_chain)[0]\n",
    "solution = environment.integrate(\n",
    "    constrained_control, environment.init(), None, saveat=diffrax.SaveAt(ts=ts)\n",
    ")\n",
    "\n",
    "cs = jax.vmap(constrained_control)(ts)\n",
    "ys = solution.ys\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ts, cs)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(ts, ys[..., :4])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ts, ys[..., 5])\n",
    "plt.show()\n",
    "\n",
    "print(ys[-1, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implicit SIREN -> Interpolation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimal_control.environments.examples.fibrosis2 import (\n",
    "    FibrosisEnvironment,\n",
    "    FibrosisState,\n",
    ")\n",
    "\n",
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "environment = FibrosisEnvironment()\n",
    "\n",
    "constraint_chain = constraints.ConstraintChain(\n",
    "    transformations=[\n",
    "        constraints.NonNegativeConstantIntegralConstraint(\n",
    "            # target=jnp.asarray([0.1, 0.1])\n",
    "            target=jnp.asarray([0.1]),\n",
    "            constrain_sum=False,\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def reward_fn(solution: diffrax.Solution) -> Scalar:\n",
    "    return solution.ys[-1, -1]\n",
    "    # return -jnp.mean(jnp.log(jnp.clip(solution.ys[..., :2], a_min=1e2)))\n",
    "\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "control = controls.ImplicitTemporalControl(\n",
    "    implicit_fn=nn.Siren(\n",
    "        in_features=1, out_features=2, hidden_features=64, hidden_layers=2, key=subkey\n",
    "    ),\n",
    "    t_start=0.0,\n",
    "    t_end=200.0,\n",
    "    to_curve=True,\n",
    "    curve_interpolation=\"linear\",\n",
    "    # curve_times=jnp.linspace(0.0, 200.0, 16)\n",
    "    curve_steps=201,\n",
    ")\n",
    "\n",
    "solver = solvers.DirectSolver(\n",
    "    optimizer=optax.adam(learning_rate=1e-4), ignore_nans=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_reward, optimized_control = trainers.solve_optimal_control_problem(\n",
    "    num_train_steps=1024,\n",
    "    environment=environment,\n",
    "    reward_fn=reward_fn,\n",
    "    constraint_chain=constraint_chain,\n",
    "    solver=solver,\n",
    "    control=control,\n",
    "    key=key,\n",
    "    pbar_interval=8,\n",
    "    integrate_kwargs=dict(\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-4, atol=1e-4, pcoeff=1.0, icoeff=1.0\n",
    "        )\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = jnp.linspace(0.0, 200.0, 1024)\n",
    "\n",
    "constrained_control = build_control(optimized_control, constraint_chain)[0]\n",
    "solution = environment.integrate(\n",
    "    constrained_control, environment.init(), None, saveat=diffrax.SaveAt(ts=ts)\n",
    ")\n",
    "\n",
    "cs = jax.vmap(constrained_control)(ts)\n",
    "ys = solution.ys\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ts, cs)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(ts, ys[..., :4])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ts, ys[..., 5])\n",
    "plt.show()\n",
    "\n",
    "print(ys[-1, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison: Clipped vs. non-clipped reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimal_control.environments.examples.fibrosis2 import (\n",
    "    FibrosisEnvironment,\n",
    "    FibrosisState,\n",
    ")\n",
    "\n",
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "constraint_chain = constraints.ConstraintChain(\n",
    "    transformations=[\n",
    "        constraints.NonNegativeConstantIntegralConstraint(\n",
    "            target=jnp.asarray([0.1, 0.1]),\n",
    "            constrain_sum=False,\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def reward_fn(solution: diffrax.Solution) -> Scalar:\n",
    "    return solution.ys[-1, -1]\n",
    "\n",
    "\n",
    "def clipped_inst_reward(t: Scalar, fy: PyTree, gy: PyTree, u: PyTree, args: PyTree):\n",
    "    fibrosis_penalty = jnp.sum(jnp.log(jnp.clip(fy[..., :2], a_min=1e2)), axis=-1)\n",
    "    return -jnp.atleast_1d(fibrosis_penalty)\n",
    "\n",
    "\n",
    "def cont_inst_reward(t: Scalar, fy: PyTree, gy: PyTree, u: PyTree, args: PyTree):\n",
    "    fibrosis_penalty = jnp.sum(jnp.log(fy[..., :2]), axis=-1)\n",
    "    return -jnp.atleast_1d(fibrosis_penalty)\n",
    "\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "control = controls.ImplicitTemporalControl(\n",
    "    implicit_fn=nn.Siren(\n",
    "        in_features=1, out_features=2, hidden_features=64, hidden_layers=2, key=subkey\n",
    "    ),\n",
    "    t_start=0.0,\n",
    "    t_end=200.0,\n",
    "    to_curve=True,\n",
    "    curve_interpolation=\"linear\",\n",
    "    curve_steps=201,\n",
    ")\n",
    "\n",
    "solver = solvers.DirectSolver(\n",
    "    optimizer=optax.adam(learning_rate=3e-4), ignore_nans=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_environment = FibrosisEnvironment(reward_fn=clipped_inst_reward)\n",
    "clip_opt_reward, clip_opt_control = trainers.solve_optimal_control_problem(\n",
    "    num_train_steps=256,\n",
    "    environment=clip_environment,\n",
    "    reward_fn=reward_fn,\n",
    "    constraint_chain=constraint_chain,\n",
    "    solver=solver,\n",
    "    control=control,\n",
    "    key=key,\n",
    "    pbar_interval=8,\n",
    "    integrate_kwargs=dict(\n",
    "        dt0=0.01,\n",
    "        max_steps=1000,\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-4, atol=1e-4, pcoeff=1.0, icoeff=1.0, dtmax=1.0\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_environment = FibrosisEnvironment(reward_fn=cont_inst_reward)\n",
    "cont_opt_reward, cont_opt_control = trainers.solve_optimal_control_problem(\n",
    "    num_train_steps=256,\n",
    "    environment=cont_environment,\n",
    "    reward_fn=reward_fn,\n",
    "    constraint_chain=constraint_chain,\n",
    "    solver=solver,\n",
    "    control=control,\n",
    "    key=key,\n",
    "    pbar_interval=8,\n",
    "    integrate_kwargs=dict(\n",
    "        dt0=0.01,\n",
    "        max_steps=1000,\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-4, atol=1e-4, pcoeff=1.0, icoeff=1.0, dtmax=1.0\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = jnp.linspace(0.0, 200.0, 1024)\n",
    "\n",
    "clip_eval_control = build_control(clip_opt_control, constraint_chain)[0]\n",
    "cont_eval_control = build_control(cont_opt_control, constraint_chain)[0]\n",
    "\n",
    "clip_solution = clip_environment.integrate(\n",
    "    clip_eval_control, clip_environment.init(), None, saveat=diffrax.SaveAt(ts=ts)\n",
    ")\n",
    "cont_solution = cont_environment.integrate(\n",
    "    cont_eval_control, cont_environment.init(), None, saveat=diffrax.SaveAt(ts=ts)\n",
    ")\n",
    "\n",
    "clip_cs = jax.vmap(clip_eval_control)(ts)\n",
    "cont_cs = jax.vmap(cont_eval_control)(ts)\n",
    "\n",
    "plt.figure()\n",
    "#plt.plot(ts, clip_solution.ys)\n",
    "plt.plot(ts, clip_cs)\n",
    "plt.plot(ts, cont_cs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D grid of constant drug integrals with implicit control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "environment: FibrosisEnvironment = FibrosisEnvironment()\n",
    "environment_state = environment.init()\n",
    "\n",
    "solver = solvers.DirectSolver(optimizer=optax.adam(learning_rate=3e-4))\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "control = controls.ImplicitTemporalControl(\n",
    "    implicit_fn=nn.Siren(\n",
    "        in_features=1, out_features=2, hidden_features=64, hidden_layers=2, key=subkey\n",
    "    ),\n",
    "    t_start=0.0,\n",
    "    t_end=200.0,\n",
    "    to_curve=True,\n",
    "    curve_interpolation=\"linear\",\n",
    "    curve_steps=201,\n",
    ")\n",
    "\n",
    "\n",
    "def reward_fn(solution: diffrax.Solution) -> Scalar:\n",
    "    return solution.ys[-1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "def optimize_with_integral(\n",
    "    target_integral: Array,\n",
    ") -> Tuple[Scalar, controls.AbstractControl]:\n",
    "    constraint_chain = constraints.ConstraintChain(\n",
    "        transformations=[\n",
    "            constraints.NonNegativeConstantIntegralConstraint(target=target_integral)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    optimized_reward, optimized_control = trainers.solve_optimal_control_problem(\n",
    "        num_train_steps=256,\n",
    "        environment=environment,\n",
    "        reward_fn=reward_fn,\n",
    "        constraint_chain=constraint_chain,\n",
    "        solver=solver,\n",
    "        control=control,\n",
    "        key=key,\n",
    "        pbar_interval=8,\n",
    "        integrate_kwargs=dict(\n",
    "            dt0=0.01,\n",
    "            max_steps=1000,\n",
    "            throw=False,\n",
    "            stepsize_controller=diffrax.PIDController(\n",
    "                rtol=1e-4, atol=1e-4, pcoeff=1.0, icoeff=1.0, dtmax=1.0\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return optimized_reward, optimized_control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill for loading\n",
    "\n",
    "pdgf_integral = jnp.geomspace(1e-3, 1e0, num=10)\n",
    "csf_integral = jnp.geomspace(1e-3, 1e0, num=10)\n",
    "\n",
    "pdgf_integral, csf_integral = jnp.meshgrid(pdgf_integral, csf_integral)\n",
    "\n",
    "target_integrals = []\n",
    "optimized_rewards = []\n",
    "optimized_controls = []\n",
    "for pdgf, csf in tq(zip(pdgf_integral.flatten(), csf_integral.flatten())):\n",
    "    target_integral = jnp.stack((pdgf, csf))\n",
    "    target_integrals.append(target_integral)\n",
    "    optimized_rewards.append(jnp.nan)\n",
    "    optimized_controls.append(control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdgf_integral = jnp.geomspace(1e-3, 1e0, num=10)\n",
    "csf_integral = jnp.geomspace(1e-3, 1e0, num=10)\n",
    "\n",
    "pdgf_integral, csf_integral = jnp.meshgrid(pdgf_integral, csf_integral)\n",
    "\n",
    "target_integrals = []\n",
    "optimized_rewards = []\n",
    "optimized_controls = []\n",
    "for pdgf, csf in tq(zip(pdgf_integral.flatten(), csf_integral.flatten())):\n",
    "    target_integral = jnp.stack((pdgf, csf))\n",
    "    try:\n",
    "        optimized_reward, optimized_control = optimize_with_integral(target_integral)\n",
    "    except ValueError:\n",
    "        target_integrals.append(target_integral)\n",
    "        optimized_rewards.append(jnp.nan)\n",
    "        optimized_controls.append(control)\n",
    "    else:\n",
    "        target_integrals.append(target_integral)\n",
    "        optimized_rewards.append(optimized_reward)\n",
    "        optimized_controls.append(optimized_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "def evaluate_control(\n",
    "    control: controls.AbstractControl, target_integral: Array\n",
    ") -> controls.AbstractControl:\n",
    "    return build_control(\n",
    "        control,\n",
    "        constraints.ConstraintChain(\n",
    "            transformations=[\n",
    "                constraints.NonNegativeConstantIntegralConstraint(\n",
    "                    target=target_integral\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "    )[0]\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def evaluate_trajectory(\n",
    "    control: controls.AbstractControl, target_integral: Array\n",
    ") -> diffrax.Solution:\n",
    "    return environment.integrate(\n",
    "        evaluate_control(control, target_integral),\n",
    "        environment_state,\n",
    "        None,\n",
    "        saveat=diffrax.SaveAt(dense=True),\n",
    "        max_steps=1000,\n",
    "        throw=False,\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-4, atol=1e-4, pcoeff=1.0, icoeff=1.0, dtmax=1.0\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save & Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    result_base_dir + \"/2d_grid_201steps_3e-4lr_dtmax/target_integrals.eqx\", mode=\"wb\"\n",
    ") as f:\n",
    "    eqx.tree_serialise_leaves(f, target_integrals)\n",
    "\n",
    "with open(\n",
    "    result_base_dir + \"/2d_grid_201steps_3e-4lr_dtmax/optimized_rewards.eqx\", mode=\"wb\"\n",
    ") as f:\n",
    "    eqx.tree_serialise_leaves(f, optimized_rewards)\n",
    "\n",
    "with open(\n",
    "    result_base_dir + \"/2d_grid_201steps_3e-4lr_dtmax/optimized_controls.eqx\", mode=\"wb\"\n",
    ") as f:\n",
    "    eqx.tree_serialise_leaves(f, optimized_controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    result_base_dir + \"/2d_grid_201steps_3e-4lr_dtmax/target_integrals.eqx\", mode=\"rb\"\n",
    ") as f:\n",
    "    target_integrals = eqx.tree_deserialise_leaves(f, target_integrals)\n",
    "\n",
    "with open(\n",
    "    result_base_dir + \"/2d_grid_201steps_3e-4lr_dtmax/optimized_rewards.eqx\", mode=\"rb\"\n",
    ") as f:\n",
    "    optimized_rewards = eqx.tree_deserialise_leaves(f, optimized_rewards)\n",
    "\n",
    "with open(\n",
    "    result_base_dir + \"/2d_grid_201steps_3e-4lr_dtmax/optimized_controls.eqx\", mode=\"rb\"\n",
    ") as f:\n",
    "    optimized_controls = eqx.tree_deserialise_leaves(f, optimized_controls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid_plot(n: int, figsize: Tuple[float]):\n",
    "    # Make grid of plots\n",
    "    fig, ax_grid = plt.subplots(\n",
    "        n + 1,\n",
    "        n + 1,\n",
    "        figsize=figsize,\n",
    "        gridspec_kw=dict(\n",
    "            width_ratios=[0.0] + [1.0] * n, height_ratios=[1.0] * n + [0.0]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Get gridspec\n",
    "    gs = ax_grid[0, 0].get_gridspec()\n",
    "\n",
    "    # Remove left row\n",
    "    for ax in ax_grid[:, 0]:\n",
    "        ax.remove()\n",
    "\n",
    "    # Remove bottom row\n",
    "    for ax in ax_grid[-1, 1:]:\n",
    "        ax.remove()\n",
    "\n",
    "    # Add rows back as single large axis\n",
    "    left_ax = fig.add_subplot(gs[:-1, 0])\n",
    "    bottom_ax = fig.add_subplot(gs[-1, 1:])\n",
    "\n",
    "    # Remove extra axes\n",
    "    left_ax.spines[[\"right\", \"top\", \"bottom\"]].set_visible(False)\n",
    "    left_ax.tick_params(axis=\"x\", bottom=False, labelbottom=False)\n",
    "\n",
    "    bottom_ax.spines[[\"right\", \"left\", \"top\"]].set_visible(False)\n",
    "    bottom_ax.tick_params(axis=\"y\", left=False, labelleft=False)\n",
    "\n",
    "    # Modify main grid\n",
    "    main_ax = ax_grid[:-1, 1:]\n",
    "    main_ax = np.flip(main_ax, axis=0)\n",
    "    base_ax = main_ax[0, 0]\n",
    "\n",
    "    for ax in main_ax.flatten():\n",
    "        if ax != base_ax:\n",
    "            # Share axes\n",
    "            ax.sharex(base_ax)\n",
    "            ax.sharey(base_ax)\n",
    "\n",
    "        # Remove ticks\n",
    "        ax.tick_params(\n",
    "            axis=\"both\", left=False, labelleft=False, bottom=False, labelbottom=False\n",
    "        )\n",
    "\n",
    "    # Unshare axes (deprecated)\n",
    "    \"\"\"\n",
    "    def unshare_axis(grouping, axis):\n",
    "        for sibling in grouping.get_siblings(axis):\n",
    "            grouping.remove(sibling)\n",
    "\n",
    "    def unshare_all(axis):\n",
    "        unshare_axis(axis.get_shared_x_axes(), axis)\n",
    "        unshare_axis(axis.get_shared_y_axes(), axis)\n",
    "\n",
    "    unshare_all(left_ax)\n",
    "    unshare_all(bottom_ax)\n",
    "    \"\"\"\n",
    "\n",
    "    return fig, main_ax, left_ax, bottom_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the seperatrix\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "seperatrix_array = scipy.io.loadmat(\"../data/Separatrix_array_F06_M07.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.logspace(\n",
    "    seperatrix_array[\"lims_F\"][0, 0],\n",
    "    seperatrix_array[\"lims_F\"][0, 1],\n",
    "    seperatrix_array[\"tsteps\"][0, 0],\n",
    ")\n",
    "y = np.logspace(\n",
    "    seperatrix_array[\"lims_M\"][0, 0],\n",
    "    seperatrix_array[\"lims_M\"][0, 1],\n",
    "    seperatrix_array[\"tsteps\"][0, 0],\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.xlabel(\"F\")\n",
    "plt.ylabel(\"M\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.pcolormesh(x, y, 1 - seperatrix_array[\"S\"], cmap=\"Greys\", vmin=0.0, vmax=3.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Trajectories\n",
    "\n",
    "\n",
    "def plot(style_name):\n",
    "    ts = jnp.linspace(0.0, 200.0, 201)\n",
    "\n",
    "    fig, main_ax, left_ax, bottom_ax = make_grid_plot(\n",
    "        10, figsize=(plot_half_width, plot_half_width)\n",
    "    )\n",
    "\n",
    "    left_ax.set_ylabel(\"anti-CSF\")\n",
    "    bottom_ax.set_xlabel(\"anti-PDGF\")\n",
    "\n",
    "    left_ax.set_yscale(\"log\")\n",
    "    left_ax.set_ylim([1e-3, 1e0])\n",
    "\n",
    "    bottom_ax.set_xscale(\"log\")\n",
    "    bottom_ax.set_xlim([1e-3, 1e0])\n",
    "\n",
    "    # main_ax[0, 0].set_xscale(\"log\")\n",
    "    # main_ax[0, 0].set_yscale(\"log\")\n",
    "    # main_ax[0, 0].set_xlim([1e0, 1e6])\n",
    "    # main_ax[0, 0].set_ylim([1e0, 1e7])\n",
    "\n",
    "    main_ax[0, 0].set_xlim([0, 6])\n",
    "    main_ax[0, 0].set_ylim([0, 7])\n",
    "\n",
    "    main_ax[0, 0].set_xlabel(\"F\")\n",
    "    main_ax[0, 0].set_ylabel(\"M\")\n",
    "\n",
    "    ax = main_ax.flatten()\n",
    "\n",
    "    for i in range(100):\n",
    "        try:\n",
    "            if jnp.isnan(optimized_rewards[i]):\n",
    "                raise ValueError\n",
    "\n",
    "            sol = evaluate_trajectory(optimized_controls[i], target_integrals[i])\n",
    "            ys = jax.vmap(sol.evaluate)(ts)\n",
    "            ys = jnp.log10(ys[..., :2])\n",
    "\n",
    "            if jnp.any(jnp.isnan(ys)):\n",
    "                raise ValueError\n",
    "\n",
    "        except (ValueError, AttributeError):\n",
    "            ax[i].set_facecolor(\"red\")\n",
    "        else:\n",
    "            # ax[i].pcolormesh(\n",
    "            #    x, y, 1 - seperatrix_array[\"S\"], cmap=\"Greys\", vmin=0.0, vmax=3.0\n",
    "            # )\n",
    "            ax[i].contourf(\n",
    "                1 - seperatrix_array[\"S\"],\n",
    "                cmap=\"Greys\",\n",
    "                vmin=0.0,\n",
    "                vmax=3.0,\n",
    "                extent=(0, 6, 7, 0),\n",
    "                origin=\"upper\",\n",
    "                levels=1,\n",
    "            )\n",
    "            ax[i].plot(ys[..., 0], ys[..., 1])\n",
    "        finally:\n",
    "            ax[i].tick_params(\n",
    "                axis=\"both\",\n",
    "                which=\"both\",\n",
    "                bottom=False,\n",
    "                left=False,\n",
    "                labelbottom=False,\n",
    "                labelleft=False,\n",
    "            )\n",
    "\n",
    "    \"\"\"\n",
    "    plt.savefig(\n",
    "        result_base_dir + \"/2d_grid_201steps_3e-4lr_dtmax/system_trajectory_grid.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.savefig(\n",
    "        result_base_dir + \"/2d_grid_201steps_3e-4lr_dtmax/system_trajectory_grid.svg\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "\n",
    "    show(\n",
    "        \"\",\n",
    "        save_prefix=\"/2d_grid_201steps_3e-4lr_dtmax/system_trajectory_grid\"\n",
    "        + style_name,\n",
    "    )\n",
    "\n",
    "\n",
    "styles(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control Trajectories\n",
    "\n",
    "def plot(style_name):\n",
    "    ts = jnp.linspace(0.0, 200.0, 201)\n",
    "\n",
    "    fig, main_ax, left_ax, bottom_ax = make_grid_plot(\n",
    "        10, figsize=(plot_half_width, plot_half_width)\n",
    "    )\n",
    "\n",
    "    left_ax.set_ylabel(\"anti-CSF\")\n",
    "    bottom_ax.set_xlabel(\"anti-PDGF\")\n",
    "\n",
    "    left_ax.set_yscale(\"log\")\n",
    "    left_ax.set_ylim([1e-3, 1e0])\n",
    "\n",
    "    bottom_ax.set_xscale(\"log\")\n",
    "    bottom_ax.set_xlim([1e-3, 1e0])\n",
    "\n",
    "    main_ax[0, 0].set_xlabel(\"T\")\n",
    "    main_ax[0, 0].set_ylabel(\"C\")\n",
    "\n",
    "    ax = main_ax.flatten()\n",
    "\n",
    "    for i in range(100):\n",
    "        try:\n",
    "            if jnp.isnan(optimized_rewards[i]):\n",
    "                raise ValueError\n",
    "\n",
    "            sol = evaluate_trajectory(optimized_controls[i], target_integrals[i])\n",
    "            ys = jax.vmap(sol.evaluate)(ts)\n",
    "            ys = jnp.log10(ys[..., :2])\n",
    "\n",
    "            if jnp.any(jnp.isnan(ys)):\n",
    "                raise ValueError\n",
    "\n",
    "            constrained_control = build_control(\n",
    "                optimized_controls[i],\n",
    "                constraints.ConstraintChain(\n",
    "                    transformations=[\n",
    "                        constraints.NonNegativeConstantIntegralConstraint(\n",
    "                            target=jnp.ones(2)\n",
    "                        )\n",
    "                    ]\n",
    "                ),\n",
    "            )[0]\n",
    "\n",
    "            cs = jax.vmap(constrained_control)(ts.reshape(-1, 1))\n",
    "\n",
    "        except (ValueError, AttributeError):\n",
    "            ax[i].set_facecolor(\"red\")\n",
    "        else:\n",
    "            ax[i].plot(ts, cs[..., 0])\n",
    "            ax[i].plot(ts, cs[..., 1])\n",
    "        finally:\n",
    "            ax[i].tick_params(\n",
    "                axis=\"both\",\n",
    "                which=\"both\",\n",
    "                bottom=False,\n",
    "                left=False,\n",
    "                labelbottom=False,\n",
    "                labelleft=False,\n",
    "            )\n",
    "\n",
    "    \"\"\"\n",
    "    plt.savefig(\n",
    "        result_base_dir + \"/2d_grid_201steps_3e-4lr_dtmax/control_trajectory_grid.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.savefig(\n",
    "        result_base_dir + \"/2d_grid_201steps_3e-4lr_dtmax/control_trajectory_grid.svg\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "\n",
    "    show(\n",
    "        \"\",\n",
    "        save_prefix=\"/2d_grid_201steps_3e-4lr_dtmax/control_trajectory_grid\"\n",
    "        + style_name,\n",
    "    )\n",
    "\n",
    "styles(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from adaptive import Learner2D, notebook_extension\n",
    "from IPython.display import clear_output\n",
    "\n",
    "notebook_extension()\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def final_evaluate_with_integral(\n",
    "    integral: Array, control: controls.AbstractControl\n",
    ") -> Tuple[Scalar, controls.AbstractControl]:\n",
    "    constrained_control = build_control(\n",
    "        control,\n",
    "        constraints.ConstraintChain(\n",
    "            transformations=[\n",
    "                constraints.NonNegativeConstantIntegralConstraint(target=integral)\n",
    "            ]\n",
    "        ),\n",
    "    )[0]\n",
    "\n",
    "    solution = environment.integrate(\n",
    "        constrained_control,\n",
    "        environment_state,\n",
    "        None,\n",
    "        max_steps=10000,\n",
    "        throw=True,\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-4, atol=1e-4, pcoeff=1.0, icoeff=1.0, dtmax=1.0\n",
    "        ),\n",
    "        dt0=0.01,\n",
    "    )\n",
    "\n",
    "    reward = reward_fn(solution)\n",
    "    return reward\n",
    "\n",
    "\n",
    "constant_learner = Learner2D(lambda x: 0, bounds=[(-6, 0), (-3, 3)])\n",
    "constant_learner.stack_size = 1\n",
    "\n",
    "plot_timer = time.time()\n",
    "plot_interval = 15\n",
    "adaptive_results = []\n",
    "while True:\n",
    "    points, _ = constant_learner.ask(1)\n",
    "    point = points[0]\n",
    "\n",
    "    integral = jnp.asarray(point, dtype=jnp.float64)\n",
    "    integral = 10**integral\n",
    "\n",
    "    # Optimize\n",
    "    failed_optimization = True\n",
    "    try:\n",
    "        adaptive_reward, adaptive_control = optimize_with_integral(integral)\n",
    "    except ValueError:\n",
    "        adaptive_reward = jnp.nan\n",
    "        adaptive_control = control\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    else:\n",
    "        failed_optimization = False\n",
    "\n",
    "    # Evaluate final control with higher max_steps, but error when too many steps\n",
    "    # are taken\n",
    "    failed_evaluation = True\n",
    "    if not failed_optimization:\n",
    "        try:\n",
    "            adaptive_reward = final_evaluate_with_integral(integral, adaptive_control)\n",
    "        except ValueError:\n",
    "            adaptive_reward = jnp.nan\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        else:\n",
    "            failed_evaluation = False\n",
    "\n",
    "    constant_learner.tell(point, float(adaptive_reward))\n",
    "    adaptive_results.append(\n",
    "        {\n",
    "            \"point\": point,\n",
    "            \"integral\": integral,\n",
    "            \"reward\": adaptive_reward,\n",
    "            \"control\": adaptive_control,\n",
    "            \"failed_optimization\": failed_optimization,\n",
    "            \"failed_evaluation\": failed_evaluation,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if time.time() - plot_timer >= plot_interval:\n",
    "        plot_timer = time.time()\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(constant_learner.plot(tri_alpha=0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import json\n",
    "from typing import Any\n",
    "import dataclasses\n",
    "\n",
    "\n",
    "class JaxSONEncoder(json.JSONEncoder):\n",
    "    def default(self, o: Any) -> Any:\n",
    "        if dataclasses.is_dataclass(o):\n",
    "            return {\n",
    "                \"__dataclass__\": True,\n",
    "                \"__class_name__\": o.__class__.__module__\n",
    "                + \".\"\n",
    "                + o.__class__.__qualname__,\n",
    "                \"fields\": dataclasses.asdict(o),\n",
    "            }\n",
    "\n",
    "        if isinstance(o, Array):\n",
    "            # Convert to numpy array\n",
    "            o = np.asarray(o)\n",
    "\n",
    "            # Save to memory\n",
    "            buffer = io.BytesIO()\n",
    "            jnp.save(buffer, o, allow_pickle=False)\n",
    "\n",
    "            # Convert the numpy array to a base64 encoded string\n",
    "            data = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "            # Include type annotation and return data\n",
    "            return {\"__numpy_array__\": True, \"data\": data}\n",
    "\n",
    "        # For other types, use the default encoder\n",
    "        return super().default(o)\n",
    "\n",
    "\n",
    "class JaxSONDecoder(json.JSONDecoder):\n",
    "    def __init__(self, dataclass_lookup: dict[str, Any], *args, **kwargs):\n",
    "        super().__init__(object_hook=self.object_hook, *args, **kwargs)\n",
    "\n",
    "        self.dataclass_lookup = dataclass_lookup\n",
    "\n",
    "    def object_hook(self, o: Any) -> Any:\n",
    "        if \"__dataclass__\" in o:\n",
    "            # Construct class instance with __new__\n",
    "            # This allows us to avoid calling __init__, which might be overridden\n",
    "            dataclass_class = self.dataclass_lookup[o[\"__class_name__\"]]\n",
    "            dataclass_instance = dataclass_class.__new__(dataclass_class)\n",
    "\n",
    "            # Replace currently undefined fields with saved fields\n",
    "            dataclass_instance = dataclasses.replace(dataclass_instance, **o[\"fields\"])\n",
    "            return dataclass_instance\n",
    "\n",
    "            # eqx.tree_at(lambda pytree: jax.tree_util.tree_flatten(pytree)[0], dataclass_instance, )\n",
    "\n",
    "        if \"__numpy_array__\" in o:\n",
    "            # Decode the base64 encoded data\n",
    "            data = base64.b64decode(o[\"data\"])\n",
    "\n",
    "            # Load the numpy array\n",
    "            buffer = io.BytesIO(data)\n",
    "            return jnp.load(buffer)\n",
    "\n",
    "        return o\n",
    "\n",
    "\n",
    "jax_json_encoder = JaxSONEncoder(indent=4)\n",
    "json_string = jax_json_encoder.encode(\n",
    "    nn.InterpolationCurve(t_start=0.0, t_end=1.0, steps=64, channels=2)\n",
    "    # eqx.nn.Linear(1, 2, key=jax.random.PRNGKey(1234))\n",
    ")\n",
    "\n",
    "print(json_string)\n",
    "\n",
    "jax_json_decoder = JaxSONDecoder(\n",
    "    dataclass_lookup={\n",
    "        \"optimal_control.nn.InterpolationCurve\": nn.InterpolationCurve,\n",
    "        \"equinox.nn._linear.Linear\": eqx.nn.Linear,\n",
    "    }\n",
    ")\n",
    "jax_json_decoder.decode(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_learner.save(result_base_dir + \"/2d_adaptive/learner.pickle\")\n",
    "eqx.tree_serialise_leaves(\n",
    "    result_base_dir + \"/2d_adaptive/results.eqx\", adaptive_results\n",
    ")\n",
    "\n",
    "with open(result_base_dir + \"/2d_adaptive/results.jxson\", mode=\"w\") as f:\n",
    "    json.dump(adaptive_results, f, cls=JaxSONEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptive import Learner2D, notebook_extension\n",
    "\n",
    "notebook_extension()\n",
    "\n",
    "constant_learner = Learner2D(lambda x: 0, bounds=[(-6, 0), (-3, 3)])\n",
    "constant_learner.stack_size = 1\n",
    "\n",
    "constant_learner.load(result_base_dir + \"/2d_adaptive/learner.pickle\")\n",
    "\n",
    "# with open(result_base_dir + \"/2d_adaptive/results.jxson\", mode=\"r\") as f:\n",
    "#    adaptive_results = json.load(f, cls=JaxSONDecoder, dataclass_lookup={\"optimal_control.nn.InterpolationCurve\": nn.InterpolationCurve, \"optimal_control.nn.\": controls.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "pdgf, csf, reward = constant_learner.interpolated_on_grid()\n",
    "\n",
    "def plot(style_name):\n",
    "    plt.figure(\n",
    "        figsize=(plot_half_width * plot_shrink_factor, plot_half_width * plot_shrink_factor)\n",
    "    )\n",
    "    plt.imshow(\n",
    "        reward.T,\n",
    "        cmap=\"magma\",\n",
    "        extent=(pdgf[0], pdgf[-1], csf[0], csf[-1]),\n",
    "        origin=\"lower\",\n",
    "    )\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_formatter(\n",
    "        plt.FuncFormatter(lambda x, pos: \"$10^{%i}$\" % int(x))\n",
    "    )\n",
    "    ax.yaxis.set_major_formatter(\n",
    "        plt.FuncFormatter(lambda x, pos: \"$10^{%i}$\" % int(x))\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"anti-PDGF [a.u.]\")\n",
    "    plt.ylabel(\"anti-CSF [a.u.]\")\n",
    "    plt.colorbar(fraction=0.04575, pad=0.04, label=\"Reward\")\n",
    "    \"\"\"\n",
    "    plt.savefig(\n",
    "        result_base_dir + \"/2d_adaptive/optimized_adaptive_grid.png\", bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.savefig(\n",
    "        result_base_dir + \"/2d_adaptive/optimized_adaptive_grid.svg\", bbox_inches=\"tight\"\n",
    "    )\n",
    "    \"\"\"\n",
    "    #plt.show()\n",
    "\n",
    "    show(style_name, save_prefix=\"/2d_adaptive/optimized_adaptive_grid\")\n",
    "\n",
    "styles(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from adaptive import Learner2D, notebook_extension\n",
    "from IPython.display import clear_output\n",
    "\n",
    "notebook_extension()\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def evaluate_with_integral(integral: Array) -> Tuple[Scalar, controls.AbstractControl]:\n",
    "    constant_control = controls.LambdaControl(lambda _, c: c, data=integral)\n",
    "\n",
    "    solution = environment.integrate(\n",
    "        constant_control,\n",
    "        environment_state,\n",
    "        None,\n",
    "        max_steps=10000,\n",
    "        throw=True,\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-4, atol=1e-4, pcoeff=1.0, icoeff=1.0, dtmax=1.0\n",
    "        ),\n",
    "        dt0=0.01,\n",
    "    )\n",
    "\n",
    "    reward = reward_fn(solution)\n",
    "    return reward\n",
    "\n",
    "\n",
    "constant_learner = Learner2D(lambda x: 0, bounds=[(-6, 0), (-3, 3)])\n",
    "constant_learner.stack_size = 1\n",
    "\n",
    "plot_timer = time.time()\n",
    "plot_interval = 15\n",
    "adaptive_results = []\n",
    "while True:\n",
    "    points, _ = constant_learner.ask(1)\n",
    "    point = points[0]\n",
    "\n",
    "    integral = jnp.asarray(point, dtype=jnp.float64)\n",
    "    integral = 10**integral\n",
    "\n",
    "    # Evaluate\n",
    "    failed_evaluation = True\n",
    "    try:\n",
    "        adaptive_reward = evaluate_with_integral(integral)\n",
    "    except ValueError:\n",
    "        adaptive_reward = jnp.nan\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    else:\n",
    "        failed_evaluation = False\n",
    "\n",
    "    constant_learner.tell(point, float(adaptive_reward))\n",
    "    adaptive_results.append(\n",
    "        {\n",
    "            \"point\": point,\n",
    "            \"integral\": integral,\n",
    "            \"reward\": adaptive_reward,\n",
    "            \"failed_evaluation\": failed_evaluation,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if time.time() - plot_timer >= plot_interval:\n",
    "        plot_timer = time.time()\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(constant_learner.plot(tri_alpha=0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_learner.save(result_base_dir + \"/2d_adaptive/constant_learner.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "\n",
    "from adaptive import Learner2D, notebook_extension\n",
    "\n",
    "notebook_extension()\n",
    "\n",
    "constant_learner = Learner2D(lambda x: 0, bounds=[(-6, 0), (-3, 3)])\n",
    "constant_learner.stack_size = 1\n",
    "\n",
    "constant_learner.load(result_base_dir + \"/2d_adaptive/constant_learner.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "def plot(style_name):\n",
    "    pdgf, csf, reward = constant_learner.interpolated_on_grid()\n",
    "\n",
    "    plt.figure(\n",
    "        figsize=(plot_half_width * plot_shrink_factor, plot_half_width * plot_shrink_factor)\n",
    "    )\n",
    "    plt.imshow(\n",
    "        reward.T,\n",
    "        cmap=\"magma\",\n",
    "        extent=(pdgf[0], pdgf[-1], csf[0], csf[-1]),\n",
    "        origin=\"lower\",\n",
    "    )\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, pos: \"$10^{%i}$\" % int(x)))\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, pos: \"$10^{%i}$\" % int(x)))\n",
    "\n",
    "    plt.xlabel(\"anti-PDGF [a.u.]\")\n",
    "    plt.ylabel(\"anti-CSF [a.u.]\")\n",
    "\n",
    "    plt.colorbar(fraction=0.04575, pad=0.04, label=\"Reward\")\n",
    "    \"\"\"\n",
    "    plt.savefig(\n",
    "        result_base_dir + \"/2d_adaptive/constant_adaptive_grid.png\", bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.savefig(\n",
    "        result_base_dir + \"/2d_adaptive/constant_adaptive_grid.svg\", bbox_inches=\"tight\"\n",
    "    )\n",
    "    \"\"\"\n",
    "    \n",
    "    show(style_name, save_prefix=\"/2d_adaptive/constant_adaptive_grid\")\n",
    "\n",
    "styles(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "\n",
    "from adaptive import Learner2D, notebook_extension\n",
    "from resize_right import resize, interp_methods\n",
    "\n",
    "notebook_extension()\n",
    "\n",
    "constant_learner = Learner2D(lambda x: 0, bounds=[(-6, 0), (-3, 3)])\n",
    "constant_learner.stack_size = 1\n",
    "\n",
    "constant_learner.load(result_base_dir + \"/2d_adaptive/constant_learner.pickle\")\n",
    "\n",
    "optimal_learner = Learner2D(lambda x: 0, bounds=[(-6, 0), (-3, 3)])\n",
    "optimal_learner.stack_size = 1\n",
    "\n",
    "optimal_learner.load(result_base_dir + \"/2d_adaptive/learner.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "def plot(style_name):\n",
    "    pdgf, csf, constant_reward = constant_learner.interpolated_on_grid()\n",
    "    pdgf, csf, optimal_reward = optimal_learner.interpolated_on_grid()\n",
    "\n",
    "    difference_reward = optimal_reward - resize(\n",
    "        constant_reward,\n",
    "        out_shape=optimal_reward.shape,\n",
    "        interp_method=interp_methods.linear,\n",
    "        pad_mode=\"edge\",\n",
    "    )\n",
    "\n",
    "    plt.figure(\n",
    "        figsize=(plot_half_width * plot_shrink_factor, plot_half_width * plot_shrink_factor)\n",
    "    )\n",
    "    plt.imshow(\n",
    "        difference_reward.T,\n",
    "        cmap=\"magma\",\n",
    "        extent=(pdgf[0], pdgf[-1], csf[0], csf[-1]),\n",
    "        origin=\"lower\",\n",
    "    )\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_formatter(\n",
    "        plt.FuncFormatter(lambda x, pos: \"$10^{%i}$\" % int(x))\n",
    "    )\n",
    "    ax.yaxis.set_major_formatter(\n",
    "        plt.FuncFormatter(lambda x, pos: \"$10^{%i}$\" % int(x))\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"anti-PDGF [a.u.]\")\n",
    "    plt.ylabel(\"anti-CSF [a.u.]\")\n",
    "    plt.colorbar(fraction=0.04575, pad=0.04, label=\"Advantage\")\n",
    "\n",
    "    \"\"\"\n",
    "    plt.savefig(\n",
    "        result_base_dir + \"/2d_adaptive/difference_adaptive_grid.png\", bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.savefig(\n",
    "        result_base_dir + \"/2d_adaptive/difference_adaptive_grid.svg\", bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "\n",
    "    show(style_name, \"/2d_adaptive/difference_adaptive_grid\")\n",
    "\n",
    "styles(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D line of constant sum drug integrals with implicit control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "environment: FibrosisEnvironment = FibrosisEnvironment()\n",
    "environment_state = environment.init()\n",
    "\n",
    "solver = solvers.DirectSolver(optimizer=optax.adam(learning_rate=3e-4))\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "control = controls.ImplicitTemporalControl(\n",
    "    implicit_fn=nn.Siren(\n",
    "        in_features=1, out_features=2, hidden_features=64, hidden_layers=2, key=subkey\n",
    "    ),\n",
    "    t_start=0.0,\n",
    "    t_end=200.0,\n",
    "    to_curve=True,\n",
    "    curve_interpolation=\"linear\",\n",
    "    curve_steps=201,\n",
    ")\n",
    "\n",
    "\n",
    "def reward_fn(solution: diffrax.Solution) -> Scalar:\n",
    "    return solution.ys[-1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "def optimize_with_integral(\n",
    "    target_integral: Array,\n",
    ") -> Tuple[Scalar, controls.AbstractControl]:\n",
    "    constraint_chain = constraints.ConstraintChain(\n",
    "        transformations=[\n",
    "            constraints.NonNegativeConstantIntegralConstraint(\n",
    "                target=target_integral, constrain_sum=True\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    optimized_reward, optimized_control = trainers.solve_optimal_control_problem(\n",
    "        num_train_steps=256,\n",
    "        environment=environment,\n",
    "        reward_fn=reward_fn,\n",
    "        constraint_chain=constraint_chain,\n",
    "        solver=solver,\n",
    "        control=control,\n",
    "        key=key,\n",
    "        pbar_interval=8,\n",
    "        integrate_kwargs=dict(\n",
    "            dt0=0.01,\n",
    "            max_steps=1000,\n",
    "            throw=False,\n",
    "            stepsize_controller=diffrax.PIDController(\n",
    "                rtol=1e-4, atol=1e-4, pcoeff=1.0, icoeff=1.0, dtmax=1.0\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return optimized_reward, optimized_control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from adaptive import Learner1D, notebook_extension\n",
    "from IPython.display import clear_output\n",
    "\n",
    "notebook_extension()\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def final_evaluate_with_integral(\n",
    "    integral: Array, control: controls.AbstractControl\n",
    ") -> Tuple[Scalar, controls.AbstractControl]:\n",
    "    constrained_control = build_control(\n",
    "        control,\n",
    "        constraints.ConstraintChain(\n",
    "            transformations=[\n",
    "                constraints.NonNegativeConstantIntegralConstraint(\n",
    "                    target=integral, constrain_sum=True\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "    )[0]\n",
    "\n",
    "    solution = environment.integrate(\n",
    "        constrained_control,\n",
    "        environment_state,\n",
    "        None,\n",
    "        max_steps=10000,\n",
    "        throw=True,\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-4, atol=1e-4, pcoeff=1.0, icoeff=1.0, dtmax=1.0\n",
    "        ),\n",
    "        dt0=0.01,\n",
    "    )\n",
    "\n",
    "    reward = reward_fn(solution)\n",
    "    return reward\n",
    "\n",
    "\n",
    "constant_learner = Learner1D(lambda x: 0, bounds=(-6, 6))\n",
    "constant_learner.stack_size = 1\n",
    "\n",
    "start_time = time.time()\n",
    "max_time = 15 * 60\n",
    "\n",
    "plot_timer = time.time()\n",
    "plot_interval = 15\n",
    "adaptive_results = []\n",
    "while time.time() - start_time < max_time:\n",
    "    points, _ = constant_learner.ask(1)\n",
    "    point = points[0]\n",
    "\n",
    "    integral = jnp.asarray([point], dtype=jnp.float64)\n",
    "    integral = 10**integral\n",
    "\n",
    "    # Optimize\n",
    "    failed_optimization = True\n",
    "    try:\n",
    "        adaptive_reward, adaptive_control = optimize_with_integral(integral)\n",
    "    except ValueError:\n",
    "        adaptive_reward = jnp.nan\n",
    "        adaptive_control = control\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    else:\n",
    "        failed_optimization = False\n",
    "\n",
    "    # Evaluate final control with higher max_steps, but error when too many steps\n",
    "    # are taken\n",
    "    failed_evaluation = True\n",
    "    if not failed_optimization:\n",
    "        try:\n",
    "            adaptive_reward = final_evaluate_with_integral(integral, adaptive_control)\n",
    "        except ValueError:\n",
    "            adaptive_reward = jnp.nan\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        else:\n",
    "            failed_evaluation = False\n",
    "\n",
    "    constant_learner.tell(point, float(adaptive_reward))\n",
    "    adaptive_results.append(\n",
    "        {\n",
    "            \"point\": point,\n",
    "            \"integral\": integral,\n",
    "            \"reward\": adaptive_reward,\n",
    "            \"control\": adaptive_control,\n",
    "            \"failed_optimization\": failed_optimization,\n",
    "            \"failed_evaluation\": failed_evaluation,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if time.time() - plot_timer >= plot_interval:\n",
    "        plot_timer = time.time()\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(constant_learner.plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "\n",
    "constant_learner.save(result_base_dir + \"/1d_adaptive/optimal_learner.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "\n",
    "import time\n",
    "\n",
    "from adaptive import Learner1D, notebook_extension\n",
    "from IPython.display import clear_output\n",
    "\n",
    "notebook_extension()\n",
    "\n",
    "optimal_learner = Learner1D(lambda x: 0, bounds=(-6, 6))\n",
    "optimal_learner.stack_size = 1\n",
    "\n",
    "optimal_learner.load(result_base_dir + \"/1d_adaptive/optimal_learner.pickle\")\n",
    "\n",
    "# Plot\n",
    "\n",
    "points = optimal_learner.to_numpy()\n",
    "argsort = np.argsort(points[..., 0])\n",
    "points = points[argsort]\n",
    "\n",
    "plt.figure(\n",
    "    figsize=(plot_half_width * plot_shrink_factor, plot_half_width * plot_shrink_factor)\n",
    ")\n",
    "plt.xlabel(\"log10(PDGF + CSFG)\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.plot(*points.T)\n",
    "plt.xlim([-3, 1])\n",
    "plt.savefig(\n",
    "    result_base_dir + \"/1d_adaptive/optimal_adaptive_interval.png\", bbox_inches=\"tight\"\n",
    ")\n",
    "plt.savefig(\n",
    "    result_base_dir + \"/1d_adaptive/optimal_adaptive_interval.svg\", bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from adaptive import Learner1D, notebook_extension\n",
    "from IPython.display import clear_output\n",
    "\n",
    "notebook_extension()\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def evaluate_with_integral(integral: Array) -> Tuple[Scalar, controls.AbstractControl]:\n",
    "    constant_control = controls.LambdaControl(\n",
    "        lambda _, c: c, data=jnp.repeat(integral, 2) / 2\n",
    "    )\n",
    "\n",
    "    solution = environment.integrate(\n",
    "        constant_control,\n",
    "        environment_state,\n",
    "        None,\n",
    "        max_steps=10000,\n",
    "        throw=True,\n",
    "        stepsize_controller=diffrax.PIDController(\n",
    "            rtol=1e-4, atol=1e-4, pcoeff=1.0, icoeff=1.0, dtmax=1.0\n",
    "        ),\n",
    "        dt0=0.01,\n",
    "    )\n",
    "\n",
    "    reward = reward_fn(solution)\n",
    "    return reward\n",
    "\n",
    "\n",
    "evaluate_with_integral(jnp.asarray([1.0]))  # Force compile\n",
    "\n",
    "constant_learner = Learner1D(lambda x: 0, bounds=(-6, 6))\n",
    "constant_learner.stack_size = 1\n",
    "\n",
    "start_time = time.time()\n",
    "max_time = 15\n",
    "\n",
    "plot_timer = time.time()\n",
    "plot_interval = 15\n",
    "adaptive_results = []\n",
    "while time.time() - start_time < max_time:\n",
    "    points, _ = constant_learner.ask(1)\n",
    "    point = points[0]\n",
    "\n",
    "    integral = jnp.asarray([point], dtype=jnp.float64)\n",
    "    integral = 10**integral\n",
    "\n",
    "    # Evaluate\n",
    "    failed_evaluation = True\n",
    "    if not failed_optimization:\n",
    "        try:\n",
    "            adaptive_reward = evaluate_with_integral(integral)\n",
    "        except ValueError:\n",
    "            adaptive_reward = jnp.nan\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        else:\n",
    "            failed_evaluation = False\n",
    "\n",
    "    constant_learner.tell(point, float(adaptive_reward))\n",
    "    adaptive_results.append(\n",
    "        {\n",
    "            \"point\": point,\n",
    "            \"integral\": integral,\n",
    "            \"reward\": adaptive_reward,\n",
    "            \"failed_evaluation\": failed_evaluation,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if time.time() - plot_timer >= plot_interval:\n",
    "        plot_timer = time.time()\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(constant_learner.plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "\n",
    "constant_learner.save(result_base_dir + \"/1d_adaptive/constant_learner.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "\n",
    "from adaptive import Learner1D, notebook_extension\n",
    "from IPython.display import clear_output\n",
    "\n",
    "notebook_extension()\n",
    "\n",
    "constant_learner = Learner1D(lambda x: 0, bounds=(-6, 6))\n",
    "constant_learner.stack_size = 1\n",
    "\n",
    "constant_learner.load(result_base_dir + \"/1d_adaptive/constant_learner.pickle\")\n",
    "\n",
    "# Plot\n",
    "\n",
    "points = constant_learner.to_numpy()\n",
    "argsort = np.argsort(points[..., 0])\n",
    "points = points[argsort]\n",
    "\n",
    "plt.figure(\n",
    "    figsize=(plot_half_width * plot_shrink_factor, plot_half_width * plot_shrink_factor)\n",
    ")\n",
    "plt.xlabel(\"log10(PDGF + CSFG)\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.plot(*points.T)\n",
    "plt.xlim([-3, 1])\n",
    "plt.savefig(\n",
    "    result_base_dir + \"/1d_adaptive/constant_adaptive_interval.png\", bbox_inches=\"tight\"\n",
    ")\n",
    "plt.savefig(\n",
    "    result_base_dir + \"/1d_adaptive/constant_adaptive_interval.svg\", bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "\n",
    "from adaptive import Learner1D, notebook_extension\n",
    "from IPython.display import clear_output\n",
    "\n",
    "notebook_extension()\n",
    "\n",
    "constant_learner = Learner1D(lambda x: 0, bounds=(-6, 6))\n",
    "constant_learner.stack_size = 1\n",
    "\n",
    "constant_learner.load(result_base_dir + \"/1d_adaptive/constant_learner.pickle\")\n",
    "\n",
    "optimal_learner = Learner1D(lambda x: 0, bounds=(-6, 6))\n",
    "optimal_learner.stack_size = 1\n",
    "\n",
    "optimal_learner.load(result_base_dir + \"/1d_adaptive/optimal_learner.pickle\")\n",
    "\n",
    "# Plot\n",
    "\n",
    "constant_points = constant_learner.to_numpy()\n",
    "optimal_points = optimal_learner.to_numpy()\n",
    "\n",
    "x = np.linspace(-3, 1, 256)\n",
    "points = np.interp(x, optimal_points[..., 0], optimal_points[..., 1]) - np.interp(\n",
    "    x, constant_points[..., 0], constant_points[..., 1]\n",
    ")\n",
    "\n",
    "plt.figure(\n",
    "    figsize=(plot_half_width * plot_shrink_factor, plot_half_width * plot_shrink_factor)\n",
    ")\n",
    "plt.xlabel(\"log10(PDGF + CSFG)\")\n",
    "plt.ylabel(\"Advantage\")\n",
    "plt.plot(x, points)\n",
    "plt.xlim([-3, 1])\n",
    "plt.savefig(\n",
    "    result_base_dir + \"/1d_adaptive/difference_adaptive_interval.png\",\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.savefig(\n",
    "    result_base_dir + \"/1d_adaptive/difference_adaptive_interval.svg\",\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39-optimal-control-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
